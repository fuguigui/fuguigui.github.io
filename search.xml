<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Weekly Summary</title>
      <link href="/y2020w46-summary/"/>
      <url>/y2020w46-summary/</url>
      
        <content type="html"><![CDATA[<p>上一周基调是平平日常的，发生的一件大事：和国内某互联网的HR谈了薪资，总体是心动的，有一些小犹豫，但真要做出最后决定还取决于其他事情的发展。</p><h1 id="计划回顾"><a href="#计划回顾" class="headerlink" title="计划回顾"></a>计划回顾</h1><p>上周计划的完成情况：</p><p>Life：80%. Incomplete tasks:</p><ul><li>Deutsch Vokabel: Everyday</li><li>Deutsch lernen: 2 episodes</li></ul><p>为啥没完成呢？德语的任务太笼统了，木有计划性可言（我指的是任务内容木有计划性，时间上是有了计划性）。不代表我没有学习德语哇，周日把之前没有学完的A2-B1词汇教材拿出来了，准备按照这个教材走。</p><p>Mathematical Optimization: 80%. Incomplete tasks:</p><ul><li>Video: 2020-11-12 (11.12)</li><li>总结之前所学的内容（11.13）</li></ul><p>为啥没有完成呢？</p><ul><li>Video因为执行进度慢了一拍，11-12的video在11-13准备去看，但是还没有更新出来。</li><li>总结这项工作，为时尚早。我去补exercise了。准备在补exercise的过程中做总结和读script的工作</li></ul><p>Thesis:</p><ul><li>Coding: 66%. Incomplete task: hodgenet的模型pytorch重写</li><li>reading &amp; task: 40%. Incomplete task: topological,  1810.03068, 2010.15010</li></ul><p>码代码的任务，会在执行过程中产生很多的新需求，其实蛮难把握的。</p><p>读paper时，有些paper还处在比较陌生的阶段，读得慢。有些需要加快速度，直奔精华了。希望在这些paper读过一遍之后，再进行一次专题阅读。比如：只看paper中提出的现有方法的issue，只看他们解决的问题，只看他们使用的数据集，只看他们的创新点等。</p><h1 id="收获"><a href="#收获" class="headerlink" title="收获"></a>收获</h1><ul><li>尝试了超市买的油酥皮，直接烤派，和牛角包一个口感。不过问题是差了些奶香</li><li>跑步上了一次Honger山</li><li>周日骑车去湖边晒太阳。看到爸爸妈妈带着孩子，情侣把手放到同一个口袋里，人们在湖边喂鸟，好幸福的场景。和心爱的人一起忽略时间的感觉好让人羡慕。一瞬间，我竟然假想起来，如果我是苏黎世的市政工作人员，我也不希望lockdown。</li><li>和老公一起看了一部电影《半个喜剧》。喜欢任素汐～</li><li>和girls每周一起看《演员请就位》。脸盲如我，终于识别出了丁程鑫和何昶希</li><li>剪出了大半个月前撸妆视频，视频原厂一个多小时，剪到五分多钟，剪辑过程用了三个小时。</li><li>买了一瓶香氛：ipuro cedar wood（雪松木）。Top note: Orange, Lemon, Heart note: Cedar wood, rosemary（迷迭香），ylang yang（依兰）, Base note: Sandalwood（檀香）, vanilla（香草）, ebony（黑檀树）。摆在窗台前，工作时隐约能闻到它的香味，好舒服。</li><li>苏黎世的暖秋快过去了，冬天要来啦</li><li>重新开始德语词汇的记忆</li></ul><h1 id="下周计划"><a href="#下周计划" class="headerlink" title="下周计划"></a>下周计划</h1><h2 id="Life"><a href="#Life" class="headerlink" title="Life"></a>Life</h2><ul><li><input disabled="" type="checkbox"> 继续好好睡觉，每天八小时打卡</li><li><input disabled="" type="checkbox"> 整理出待剪辑的vlog list，并把香蕉糊的这一期剪出来～</li><li><input disabled="" type="checkbox"> 缺氧：解决电路过载问题</li><li><input disabled="" type="checkbox"> This is us：看两集</li><li><input disabled="" type="checkbox"> 中午和室友一起看rick and morty，season 4: episode 3, 4,5</li><li><input disabled="" type="checkbox"> 权力的游戏：第七季一二集</li><li><input disabled="" type="checkbox"> deutsch: <ul><li><input disabled="" type="checkbox"> 词汇计划</li><li><input disabled="" type="checkbox"> 工作日早上进行15分钟听力吼不吼</li></ul></li><li><input disabled="" type="checkbox"> Piano：<ul><li><input disabled="" type="checkbox"> 遇见</li><li><input disabled="" type="checkbox"> 另一首曲子</li></ul></li><li><input disabled="" type="checkbox"> 练一张毛笔字</li><li><input disabled="" type="checkbox"> 读书：美丽之问</li></ul><h2 id="Mathematical-Optimization"><a href="#Mathematical-Optimization" class="headerlink" title="Mathematical Optimization"></a>Mathematical Optimization</h2><ul><li><input disabled="" type="checkbox"> Video 11-12 (11-16)</li><li><input disabled="" type="checkbox"> Course 11-16(11-16)</li><li><input disabled="" type="checkbox"> Script: page: 18-34 (11.17)</li><li><input disabled="" type="checkbox"> script: page: 34-46, problem set 2 (11.18)</li><li><input disabled="" type="checkbox"> Course: 11-19 (11.19)</li><li><input disabled="" type="checkbox"> script: page: 46-71 , problem set 3 (11.20)</li></ul><h2 id="Thesis"><a href="#Thesis" class="headerlink" title="Thesis"></a>Thesis</h2><ul><li><input disabled="" type="checkbox"> HodgeNet RNN + SNN data</li><li><input disabled="" type="checkbox"> SNN + HodgeNet Data</li><li><input disabled="" type="checkbox"> SIGN paper</li><li><input disabled="" type="checkbox"> 做SNN的时间空间资源占用分析</li><li><input disabled="" type="checkbox"> Compare reading: NHP VS Simplicial closure.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> life </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>罗马罗马</title>
      <link href="/luo-ma-luo-ma/"/>
      <url>/luo-ma-luo-ma/</url>
      
        <content type="html"><![CDATA[<p>一</p><p>万事开头难。前后准备了一个多月，也无法提笔写下第一篇。总觉得，自己不论是文笔上还是内容上都没有准备好，还需要看更多的书，积累更多的素材，才能雕琢出理想中的作品。过度的完美主义，阻止了行动的启动。还好，偶然读到村上春树的《远方的鼓声》，那是他在中年时期旅居欧洲的文集，在字里行间竟有种找到知音的感觉，哈哈，称之为膜拜更合适。我的千丝万缕的心绪，被一个不同时代不同文化背景的人，用轻柔的笔触诉说出来。是种多么奇妙又惊喜的体验！遂下定决心，无论如何，提笔为敬。</p><p>二</p><p>原本计划中的第一篇要记述在瑞士的生活琐事，大纲反复拟写了几遍，相关书籍视频也学习了些，却总归少了味激情，难以成形。村上的第一篇以罗马起，读着读着唤起了我对罗马强烈的情感。之前苦苦寻之不得的激情，也突然充盈于心，何不也以此为始？</p><p>三</p><p>初见罗马，是在五月末的一天。原本计划坐一夜的火车，从威尼斯直达罗马，然而在威尼斯时，被这座小城迷了眼，竟忘记了买车票这档子事。待反应过来，票已售罄。不得不临时购买白天换乘两次的车票，提前了一个晚上到了罗马。</p><p>对罗马的渴望在心底深埋了多年，笼罩着一层神圣的光环。若问我对欧洲大陆最早的认知，无非是神话中的希腊，和光辉传奇的罗马帝国。</p><p>而今，距离常年的渴望只有几座城的距离，忐忑和紧张愈发强烈。</p><p>再一天，就是心心念念的罗马啊。</p><p>整日的舟车劳顿，面对这份激情，都显得微不足道了。</p><p>一大早上就从威尼斯出发，只来得及在火车站附近随便买个碱水面包和三明治，当一天的伙食。火车抵达博洛尼亚后，我本应换乘另一班去佛罗伦萨。我对意大利语丝毫不知，身边也没个同伴。看电子屏找不到火车的位置，去求助一个矮矮的老大爷引导员。我俩无法找到共通的语言，互相打手势比划。他看看车票，摇摇头两手交叉比了个大叉，又指指站外，划个圈，好像是告诉我错了错了，不在这里，要出去再转弯。意大利语的调子可真是抑扬顿挫啊，我想。车在哪儿没闹明白，但这趟火车似乎不在火车站里？我也不知哪来的胆量，估摸着大爷指的方向，就走出了车站。沿途遇上三三俩俩从车站出来拖行李箱的人，私以为是同行人，便跟着他们一起走。拐了个弯，他们停下来等，我也停下来。十几分钟后，居然还真等到了，是一辆车窗上临时贴着这班火车号的巴士。嘿，还有这档子事。</p><p>巴士在亚平宁山脉间攀爬，山路蜿蜒陡峭，司机师傅开得又快又稳。虽说才是五月，正午的阳光已强烈得晃眼，仿佛自带聒噪的蝉鸣背景音。我很庆幸自己躲在车里，不仅阴凉，还可以懒懒地窝在座位里啃三明治。现在是防疫即将松懈地时候，大家戴着口罩也不耽误吃东西。巴士的摇晃和五月开始萌芽的暑气，让我感到昏昏沉沉。一个瞌睡的功夫，巴士已穿过了山脉，抵达佛罗伦萨。</p><p>两年前和元元一起来过一次佛罗伦萨，光看车站名，就感觉很亲切。Firenze，翡冷翠，徐志摩曾如此诗意地呼唤她。</p><p>这一次，我独自一人，在Firenze的小车站换乘。这里距离市中心应该有些距离，站里站外都没什么人，视野范围内也没有出现佛罗伦萨标志性的圣母百花大教堂。不过，四周的建筑物倒是清一色黄色调的，是佛罗伦萨那股年代久远的味儿了。</p><p>火车来了，直抵意大利的心脏——罗马。在Termini火车站下车时，明明无人迎接，我却忍不住痴痴地笑。</p><p>罗马啊，罗马。我终于走进了这座史书中的城市。</p><p>四</p><p>欧洲的城市大多规模不大，特别是历史悠久的地方。我常不自觉地把其他国家的首都拿来和北京做对比，却发现二者不在一个量级。也是，帝都常住人口就有两千一百多万，比瑞士整个国家的人都多出了好几倍，怎能相提并论？且不论规模，首都的面貌也各不一样。</p><p>罗马就是一个有很多让人跌破眼镜的首都。</p><p>从车站出来，隐隐想要快走离开这儿。不宽的街道上挤满了出租车，一群旅客出站就会有一群司机涌上来，大声叫嚷着招揽生意。绕开这条出租车街，我逃进了一条僻静的小巷，好巧不巧碰到一老哥蹲在那儿方便，吓得我又逃回了大街。就这样，我拉着个行李箱，在大街小巷中脚步匆匆，逃也似的去到了在火车站不远处预定的房间。</p><p>在房间里，定了定神后，为刚刚的不安全感笑了起来。晚饭稍微吃了点沙拉，积攒了一天的疲惫从脚底冒到头顶，先睡吧。明天才是正式和罗马见面的日子呢。</p>]]></content>
      
      
      <categories>
          
          <category> Literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Travel </tag>
            
            <tag> Europe </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Proto和thrift</title>
      <link href="/proto/"/>
      <url>/proto/</url>
      
        <content type="html"><![CDATA[<p>工作之后，接触了一个概念叫做RPC（remote procedure call），远程服务调用。对于大型工程来说，很多功能的实现都是通过RPC来实现的，从某种角度RPC可以类比为函数调用，但是从本地变成了远程。这就涉及到通信的技术。先写个帖子分享我对于Thrift和Protobuf的理解和使用。</p><h1 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h1><p>事情要从RPC通信说起。</p><p>一个正常的RPC过程可以分为以下几个步骤：</p><p><img src="./Proto/RPC.jpg" alt="RPC"></p><ol><li>本地的调用者（caller）client调用本地的client stub</li><li>client stub将参数打包成一个消息，然后发送这个消息。打包过程叫做marshalling</li><li>client所在的系统将消息通过网络传输发送给服务端server</li><li>server将收到的包传给server stub</li><li>server stub解析包，得到参数。解包过程也被叫做unmarshalling</li><li>server stub调用服务过程。返回的结果按照相反的步骤传给client。</li></ol><p>这里涉及到的重要组成：</p><ul><li>client客户端：服务的调用方。</li><li>server服务端：服务的真正提供者。这个Server并不是提供RPC服务器IP、端口监听的模块，而是远程服务方法的具体实现，其中的代码是最普通和业务相关的代码，甚至其接口实现类本身都不知道将被某一个RPC远程客户端调用。</li><li>Stub/Proxy：RPC框架中的“代理层”：负责处理打包/解析消息格式，网络传输协议，服务地址信息等。</li><li>Network Service：底层传输：可以是TCP或HTTP。</li></ul><p>为了实现RPC：有几个问题需要解决：</p><ul><li>函数调用时，数据结构的约定问题：客户端和服务端实现调用的接口须一致。</li><li>数据传输时，序列化和反序列化问题。</li><li>网络通信问题。</li></ul><p>后两者是网络传输信息中的问题。</p><h1 id="序列化和反序列化"><a href="#序列化和反序列化" class="headerlink" title="序列化和反序列化"></a>序列化和反序列化</h1><p>Protobuf就是专门解决序列化和反序列化的问题的。Thrift也提供了这个功能，但它同时兼具RPC远程通信的功能，这一点是Protobuf不具备的。这里集中介绍序列化和反序列化。</p><p>序列化：就是将对象转化成字节序列的过程。</p><p>反序列化：就是将字节序列转化成对象的过程。</p><p>因为网络传输数据时，无法直接传输对象。所以，所有可在网络上传输的对象都必须是可序列化的。</p><h1 id="Protobuf"><a href="#Protobuf" class="headerlink" title="Protobuf"></a>Protobuf</h1><p>Protocol Buffers时Google开发的一种轻便高效的结构化数据存储格式，可以用于序列化。</p><p>优点：</p><ul><li>性能好：Protobuf以高效的二进制方式存储，比XML小3到10倍，速度快20到100倍</li><li>代码生成机制：根据数据文件自动生成结构体定义和相关方法的文件。比如A系统去调用B系统，因为A</li></ul><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="www.cnblogs.com/xiangxiaolin/p/12712720.html">Protobuf通信协议</a></p><p><a href="https://developer.51cto.com/art/201906/597963.htm">51CTO</a></p><p><a href="www.eet-china.com/mp/a63366.html">长文图解Google的protobuf思考、设计、应用</a></p>]]></content>
      
      
      <categories>
          
          <category> Sharing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo环境配置</title>
      <link href="/hexo1/"/>
      <url>/hexo1/</url>
      
        <content type="html"><![CDATA[<p>这一系列分享如何使用Hexo搭建个人博客网站。</p><p>俗话说“跑程序一小时，配环境一整天”。</p><p>第一步就是要配置环境。这有一个<a href="https://hexo.io/zh-cn/docs/">官方教程</a>，供参考。其实只要环境配置好了，后续的操作都非常简单。</p><h1 id="工具总览"><a href="#工具总览" class="headerlink" title="工具总览"></a>工具总览</h1><p>我们使用以下的工具来维护博客：</p><ul><li>Typora</li><li>Git</li><li>Node.js, npm</li><li>hexo</li></ul><h1 id="详细配置"><a href="#详细配置" class="headerlink" title="详细配置"></a>详细配置</h1><h2 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h2><p>Git是用来管理/存储代码和部署网页的地方。</p><p>需要对git进行的操作</p><ul><li><p>安装git</p></li><li><p>配置git账户</p></li><li><p>从github上下载仓库，并日后进行维护。</p></li></ul><h3 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h3><p>如何安装git，去网上搜索有很多现成的教程，这里就不赘述了。可参考<a href="https://www.liaoxuefeng.com/wiki/896043488029600/896067074338496">廖雪峰git安装教程</a></p><h3 id="配置git账户"><a href="#配置git账户" class="headerlink" title="配置git账户"></a>配置git账户</h3><ol><li>在本地生成密钥，把密钥添加到远端。这一步是为了将本地机器和远程账户进行链接。可以参考<a href="https://www.jianshu.com/p/6e1de95828a8">简书git基本配置</a></li></ol><p>疑难解答：</p><ul><li><p><input checked="" disabled="" type="checkbox">  .ssh/config文件是什么</p><p><a href="https://www.cnblogs.com/foohack/p/10027083.html">https://www.cnblogs.com/foohack/p/10027083.html</a></p></li><li><p><input checked="" disabled="" type="checkbox">  多个账户配置。注：如果电脑上有多个账户，且没有配置全局账户，以后的操作应该是对于每一个repo都要单独配置账户。</p></li></ul><p><a href="https://www.jianshu.com/p/fbbf6efb50ba">https://www.jianshu.com/p/fbbf6efb50ba</a></p><h3 id="GitHub-Pages连接"><a href="#GitHub-Pages连接" class="headerlink" title="GitHub Pages连接"></a>GitHub Pages连接</h3><p>若没有GitHub Pages，则需：</p><ol><li>在github上新建一个Github Pages仓库</li><li>配置仓库链接</li></ol><p>若已建立GitHub Pages，则只需：</p><ol><li>配置仓库链接</li></ol><h4 id="创建新GitHub-Pages（可选）"><a href="#创建新GitHub-Pages（可选）" class="headerlink" title="创建新GitHub Pages（可选）"></a>创建新GitHub Pages（可选）</h4><p>参考<a href="https://zhuanlan.zhihu.com/p/60578464">知乎：hexo和git配置</a></p><h4 id="配置仓库链接"><a href="#配置仓库链接" class="headerlink" title="配置仓库链接"></a>配置仓库链接</h4><p>如何将远程仓库下载到本地，并且配置用户？ <a href="https://www.cnblogs.com/yshang/p/11230209.html">cnblogs：将远程仓库下载到本地</a></p><ol><li><p>在本地新建一个文件夹</p></li><li><p>将本地仓库初始化<code>git init</code></p></li><li><p>将相应的代码从远程下载下来 <code>git clone git@github.com:gitacount/blogname.github.io.git</code></p></li><li><p>进入这个仓库的目录下，输入以下代码</p><p><code>git config --unset user.name</code></p><p><code>git config --unset user.email</code></p><p><code>git config user.name "GitAccount"</code></p><p><code>git config user.email gitemail@***.***</code></p></li></ol><p><span class="github-emoji"><span>🌟</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> 对于GitHub Pages的仓库配置有个小技巧，就是<strong>使用两个分支</strong>，一个分支用于存储hexo渲染好的静态页面，也就是直接展示给读者的html等文件；另一个分支用于存储源代码，也就是hexo渲染前的文件，这样便于在多台机器上更新博客，或者更换机器后，直接从git上拉取下来就好。</p><p>详细教程请参考<a href="https://haoshuai6.github.io/2016-10-28-hexo-github.html">haoshuai6: hexo两个分支</a></p><h2 id="Typora"><a href="#Typora" class="headerlink" title="Typora"></a>Typora</h2><p>我喜欢使用这个markdown文本编辑器。</p><p>Typora比一般markdown编辑器好的地方是：即时展现。也就是它的界面展现给你的就是已经渲染好效果的版本，而不是原始版本的所有字符输入。</p><p>原始版本是什么样呢？在键盘上按下<code>Ctrl+/</code>就能看见了。再按一次<code>Ctrl + /</code>就可以返回展示界面。    </p><p>Typora的左侧可以把文章的结构展现出来，而且Typora可以很方便地把markdown导出为pdf或者html等多种结构。在左上角菜单栏里有一个导出（Export）。</p><h3 id="Markdown"><a href="#Markdown" class="headerlink" title="Markdown"></a>Markdown</h3><p>markdown类型的文本后缀是.md，是一种文本标记语言。常见于代码仓库的readme文件。长处在于减少排版工作，支持方便输入数学公式，代码，引用，表情包等日常需求。</p><ul><li><a href="https://www.jianshu.com/p/335db5716248">简书：Markdown基础教程</a></li><li><a href="https://www.webfx.com/tools/emoji-cheat-sheet/">emoji-cheat-sheet</a></li></ul><p>类似的文件类型还有.rst。</p><ul><li><p><a href="https://www.cnblogs.com/youxin/p/3597229.html">cnblogs: markdown vs rst</a></p></li><li><p><a href="https://www.jianshu.com/p/1885d5570b37">简书: rst introduction</a></p></li></ul><p>hexo可以直接将markdown类型的文本转化为html类型，用做网页。</p><h2 id="Node-js和npm"><a href="#Node-js和npm" class="headerlink" title="Node.js和npm"></a>Node.js和npm</h2><p>node.js的简单解释是一种javascript的运行环境，能够使得javascript脱离浏览器运行。</p><p>npm(<strong>n</strong>odejs <strong>p</strong>ackage <strong>m</strong>anager)简单说就是nodejs内置的包管理器。可以理解为anaconda之于python的地位。将npm类比为anaconda，nodejs类比为python</p><h3 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h3><p><a href="https://www.runoob.com/nodejs/nodejs-install-setup.html">runoob: nodejs安装配置windows/Linux/Mac</a></p><h2 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h2><p><a href="https://hexo.io/zh-cn/docs/">hexo</a>是一个博客框架，能将markdown格式的文件解析生成静态网页。</p><p>hexo据说是一个二次元的台湾小哥写的。这里是<a href="https://zespia.tw/blog/2012/10/11/hexo-debut/">Hexo诞生的介绍</a>。小哥是在玩前端的时候，对现有的博客框架很不满意，于是就自己写了一个。。。。（大佬就是任性，遇到不喜欢的东西就自己写一个。。。类似的故事还有git，linux，latex，matlab等等。我深深地被小哥任性的初衷吸引了，非常种草这个框架。）</p><p>安装参考官方文档。</p><p>之后就可以去选择自己喜欢的主题，进行写作和装饰啦。</p><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><ol><li><a href="https://hexo.io/zh-cn/docs/">Hexo官方安装教程</a></li><li><a href="https://www.liaoxuefeng.com/wiki/896043488029600/896067074338496">廖雪峰git安装教程</a></li><li><a href="https://www.jianshu.com/p/6e1de95828a8">简书git基本配置</a></li><li><a href="https://www.cnblogs.com/foohack/p/10027083.html">cnblogs: ssh</a></li><li><a href="https://www.jianshu.com/p/fbbf6efb50ba">简书：Git多账户配置</a></li><li><a href="https://zhuanlan.zhihu.com/p/60578464">知乎：hexo和git配置</a></li><li><a href="https://haoshuai6.github.io/2016-10-28-hexo-github.html">haoshuai6: hexo两个分支</a></li><li><a href="https://www.jianshu.com/p/335db5716248">简书：Markdown基础教程</a></li><li><a href="https://www.webfx.com/tools/emoji-cheat-sheet/">emoji-cheat-sheet</a></li><li><a href="https://www.cnblogs.com/youxin/p/3597229.html">cnblogs: markdown vs rst</a></li><li><a href="https://www.jianshu.com/p/1885d5570b37">简书: rst introduction</a></li><li><a href="https://www.runoob.com/nodejs/nodejs-install-setup.html">runoob: nodejs安装配置windows/Linux/Mac</a></li><li><a href="https://hexo.io/zh-cn/docs/">hexo官方介绍</a></li><li><a href="https://zespia.tw/blog/2012/10/11/hexo-debut/">Hexo的诞生</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Sharing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Git </tag>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Blog TODO</title>
      <link href="/todo/"/>
      <url>/todo/</url>
      
        <content type="html"><![CDATA[<h1 id="Bugs"><a href="#Bugs" class="headerlink" title="Bugs"></a>Bugs</h1><ul><li><input disabled="" type="checkbox"> view count is wrong</li></ul><h1 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h1><ul><li>multiple languages: automatically translate</li></ul><h2 id="功能排查"><a href="#功能排查" class="headerlink" title="功能排查"></a>功能排查</h2><ul><li><p><input disabled="" type="checkbox">  移除git repo的子目录里的git</p></li><li><p><input disabled="" type="checkbox">  足迹地图<a href="https://zhuanlan.zhihu.com/p/338156645">https://zhuanlan.zhihu.com/p/338156645</a></p></li><li><p><input disabled="" type="checkbox">  bilibili视频<a href="https://zhuanlan.zhihu.com/p/194208325">https://zhuanlan.zhihu.com/p/194208325</a></p></li><li><p><input disabled="" type="checkbox">  大规模修改post链接</p></li><li><p><input disabled="" type="checkbox">  如何进行自适应的中英文调整？ <a href="https://tstrs.me/1448.html">https://tstrs.me/1448.html</a></p><pre class=" language-bash"><code class="language-bash"><span class="token function">cd</span> /root/hexo <span class="token operator">&amp;&amp;</span> hexo clean <span class="token operator">&amp;&amp;</span> hexo g <span class="token operator">&amp;&amp;</span><span class="token function">cd</span> /root/hexoen <span class="token operator">&amp;&amp;</span> hexo clean <span class="token operator">&amp;&amp;</span> hexo g <span class="token operator">&amp;&amp;</span> <span class="token function">cd</span> /root/hexo <span class="token operator">&amp;&amp;</span><span class="token function">cp</span> -r /root/hexoen/public/. /root/hexo/public/en/ <span class="token operator">&amp;&amp;</span> hexo d</code></pre></li></ul><h2 id="外观"><a href="#外观" class="headerlink" title="外观"></a>外观</h2><h1 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h1><ul><li><input disabled="" type="checkbox"> 更新myprojects</li><li><input disabled="" type="checkbox"> 自我介绍更新</li><li><input disabled="" type="checkbox"> 添加好友：<a href="https://tstrs.me/en/about/">https://tstrs.me/en/about/</a> 这个人，启发了我创作英文版的</li></ul><h1 id="Clean"><a href="#Clean" class="headerlink" title="Clean"></a>Clean</h1><ul><li><input disabled="" type="checkbox"> math formula in posts<ul><li><input disabled="" type="checkbox"> from CIL-7CNN</li></ul></li><li><input disabled="" type="checkbox"> images missing in posts<ul><li><input disabled="" type="checkbox"> CIL1-LA: ./imgs/2pca_1.png)</li><li><input disabled="" type="checkbox"> CIL2-MA: ./imgs/2nn_4.png, ./imgs/2nn_1.png) , ./imgs/2nn_2.png) ./imgs/2nn_3.png</li></ul></li><li><input disabled="" type="checkbox"> how to insert images</li><li><input disabled="" type="checkbox"> images for covers</li><li><input disabled="" type="checkbox"> post reference</li></ul><h1 id="More-contents"><a href="#More-contents" class="headerlink" title="More contents"></a>More contents</h1><ul><li><input disabled="" type="checkbox"> traveling</li><li><input disabled="" type="checkbox"> food</li><li><input disabled="" type="checkbox"> thoughts</li><li><input disabled="" type="checkbox"> Links: for the other blog</li><li><input disabled="" type="checkbox"> Recommendations</li><li><input disabled="" type="checkbox"> maps</li><li><input disabled="" type="checkbox"> summer journal</li></ul>]]></content>
      
      
      <categories>
          
          <category> misc </category>
          
      </categories>
      
      
        <tags>
            
            <tag> blog </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Google上岸算法刷题计划表</title>
      <link href="/20220501-shu-ju-jie-gou/"/>
      <url>/20220501-shu-ju-jie-gou/</url>
      
        <content type="html"><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><ul><li><p><strong>重点散列表</strong>：总结各种巧妙的应用，以及利用了散列表什么样的特点</p></li><li><p><input checked="" disabled="" type="checkbox">  栈和队列的使用，python包的使用</p></li><li><p><input checked="" disabled="" type="checkbox">  堆系统性学习</p></li><li><p><input checked="" disabled="" type="checkbox">  排序算法总结 （05/16）</p><ul><li><input checked="" disabled="" type="checkbox"> 排序算法，经典算法的要点在于什么？</li><li><input checked="" disabled="" type="checkbox"> 排序算法刷题</li></ul></li><li><p><input checked="" disabled="" type="checkbox">  搜索/二分搜索（05/20）</p></li><li><p><input checked="" disabled="" type="checkbox">  树：实现下，前中后序遍历 （05/21-05/28）</p><ul><li><input checked="" disabled="" type="checkbox"> 广搜深搜总结错题集 </li><li><input checked="" disabled="" type="checkbox"> 线段树</li><li><input checked="" disabled="" type="checkbox"> dfs+memo</li></ul></li><li><p><input checked="" disabled="" type="checkbox">  图：实现 </p><ul><li><input checked="" disabled="" type="checkbox"> topology sort</li></ul></li><li><p><input checked="" disabled="" type="checkbox">  递归/动态规划，区分不同，以及重点题目总结 </p></li><li><p><input checked="" disabled="" type="checkbox">  链表和数组 </p></li><li><p><input checked="" disabled="" type="checkbox">  双指针</p></li><li><p><input checked="" disabled="" type="checkbox">  贪心</p></li><li><p><input checked="" disabled="" type="checkbox">  内存作为新知识点进行学习</p></li><li><p><input checked="" disabled="" type="checkbox">  位操作的应用实例</p></li><li><p><input checked="" disabled="" type="checkbox">  专项总结：这个topic的典型应用场景有哪些？模板是什么？精选例题+每道题可以怎样follow up？</p><ul><li><input checked="" disabled="" type="checkbox"> 不同场景降低时间复杂度的方法有哪些 </li></ul></li><li><p><input checked="" disabled="" type="checkbox">  谷歌专项刷题：先说不做，把所有该说的都说完，想follow up，和behaviro的准备同时进行，穿插着来</p></li><li><p><input checked="" disabled="" type="checkbox">  labuladong每个专题刷典型题</p></li></ul><p>务必掌握它们的具体用法、实现方法、应用场景以及时间和空间复杂度</p><p>各种数据结构：重要的一点是使用：适用于什么场景，时间空间复杂度是什么？典型的应用有哪些。一定要弄清楚什么情况下该使用什么数据结构。</p><table><thead><tr><th>数据结构</th><th>算法</th><th>其他</th></tr></thead><tbody><tr><td>链表：双指针</td><td>广度优先搜索</td><td>位操作</td></tr><tr><td>树、二叉树、单词查找树，segment tree</td><td>深度优先搜索</td><td>内存（堆和栈）</td></tr><tr><td>栈和队列</td><td>二分查找</td><td>LRUCache、LFUCache</td></tr><tr><td>堆</td><td>排序：快排，归并，桶</td><td>大o时间和空间</td></tr><tr><td>向量/数组列表/字符串</td><td>分治法</td><td>并查集</td></tr><tr><td>散列表</td><td>滑动窗口</td><td>面向对象设计</td></tr><tr><td>图</td><td>贪心算法</td><td>系统设计与可扩展性</td></tr><tr><td></td><td>动态规划、递归</td><td>线程与锁</td></tr></tbody></table><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><p><a href="https://books.halfrost.com/leetcode/ChapterTwo/Stack/">LeetCode Cookbook</a>（数据结构+算法）</p></li><li><p><a href="https://github.com/changgyhub/leetcode_101">GitHub - LeetCode 101</a>（侧重于算法）</p></li><li><p><a href="https://mp.weixin.qq.com/s?__biz=MzU4NDE3MTEyMA==&amp;mid=2247488290&amp;idx=1&amp;sn=a9c525e36211710e0ff480e3300e346b&amp;chksm=fd9cb83dcaeb312b004aff26e5448bf7f77a318efab4637c33f52edd2c9e4d8b4cc3b4a63e2c&amp;cur_album_id=1751702161341628417&amp;scene=189#wechat_redirect">宫水三叶</a></p></li><li><p><a href="https://dowalle.gitbook.io/algo/algorithm/4-tu-lun/1-ji-ben-zhi-shi">dowalle</a></p></li><li><p><a href="https://labuladong.github.io/algo/3/23/71/">labuladong</a></p></li><li><p>程序员面试金典（数据结构+算法）</p></li></ul><h1 id="笔记链接"><a href="#笔记链接" class="headerlink" title="笔记链接"></a>笔记链接</h1><h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><p><a href="https://github.com/fuguigui/leetcode-notes/blob/master/%E6%95%A3%E5%88%97%E8%A1%A8Hash.ipynb">散列表</a></p><p><a href="https://github.com/fuguigui/leetcode-notes/blob/master/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97%EF%BC%88%E4%B8%80%EF%BC%9A%E6%A0%88%EF%BC%89.ipynb">栈和队列（一：栈）</a></p><p><a href="https://github.com/fuguigui/leetcode-notes/blob/master/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97%EF%BC%88%E4%BA%8C%EF%BC%9A%E9%98%9F%E5%88%97%EF%BC%89.ipynb">栈和队列（二：队列）</a></p><p><a href="https://github.com/fuguigui/leetcode-notes/blob/master/%E5%A0%86.ipynb">堆</a></p><p><a href="2022-05-16%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95.md">排序算法理论</a></p><p><a href="https://github.com/fuguigui/leetcode-notes/blob/master/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95.ipynb">排序算法力扣</a></p><p><a href="https://github.com/fuguigui/leetcode-notes/blob/master/%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2.ipynb">二分搜索</a></p><p><a href="https://github.com/fuguigui/leetcode-notes/blob/master/%E6%A0%91%E5%92%8C%E5%9B%BE%EF%BC%88%E4%B8%80%EF%BC%9A%E6%A0%91%EF%BC%89.ipynb">树和图（一：树）</a></p><p><a href="https://github.com/fuguigui/leetcode-notes/blob/master/%E6%A0%91%E5%92%8C%E5%9B%BE%EF%BC%88%E4%BA%8C%EF%BC%9A%E6%A0%91%E7%9A%84%E8%BF%9B%E9%98%B6%EF%BC%89.ipynb">树和图（二：树的进阶）</a></p><p><a href="https://github.com/fuguigui/leetcode-notes/blob/master/%E6%A0%91%E5%92%8C%E5%9B%BE%EF%BC%88%E4%B8%89%EF%BC%9A%E5%9B%BE%EF%BC%89.ipynb">树和图（三：图）</a></p><p><a href="https://github.com/fuguigui/leetcode-notes/blob/master/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92.ipynb">动态规划</a></p><h2 id="专题"><a href="#专题" class="headerlink" title="专题"></a>专题</h2><p><a href="https://github.com/fuguigui/leetcode-notes/blob/master/%E4%B8%93%E9%A2%98BFS%E5%92%8CDFS.ipynb">专题BFS和DFS</a></p><h2 id="综合"><a href="#综合" class="headerlink" title="综合"></a>综合</h2><h1 id="坑"><a href="#坑" class="headerlink" title="坑"></a>坑</h1><p>python的字典复制，有几种方法，复制程度不一样</p><p><a href="https://blog.csdn.net/u010895119/article/details/79418434">Python dictionary字典的复制方法_小桔帽的博客-CSDN博客_python复制字典</a></p><ul><li><p><code>dict1=dict2</code>，这个只是换个名字而已，并不能叫复制，对<code>dict1</code>做的操作，都会出现在<code>dict2</code>上</p></li><li><p><code>dict1=dict2.copy()</code>，这个是浅复制：复制后对原dict的内部子对象(方括号[]内元素)进行操作时，由浅复制得到的dict<strong>会</strong>受该操作影响</p><ul><li><p><code>dict1[a]=3</code>不会影响到<code>dict2[a]</code>的值</p></li><li><p><code>dict1[a].append(3)</code>会影响到<code>dict2[a]</code>的值</p></li></ul></li><li><p><code>dict1=deepcopy(dict2)</code>，这个是深复制：复制后对原dict的内部子对象(方括号[]内元素)进行操作时，由深复制得到的dict<strong>不会</strong>受该操作影响</p><ul><li><p><code>dict1[a]=3</code>不会影响到<code>dict2[a]</code>的值</p></li><li><p><code>dict1[a].append(3)</code>不会影响到<code>dict2[a]</code>的值</p></li></ul></li><li><p><input checked="" disabled="" type="checkbox">  python的sortedlist怎么使用？</p></li></ul><p>一个demo</p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> sortedcontainers <span class="token keyword">import</span> SortedList<span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">countSmaller</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> List<span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">:</span>        n <span class="token operator">=</span> len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span>        res <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> n        sl <span class="token operator">=</span> SortedList<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token number">-1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 反向遍历</span>            cnt <span class="token operator">=</span> sl<span class="token punctuation">.</span>bisect_left<span class="token punctuation">(</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># 找到右边比当前值小的元素个数</span>            res<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> cnt                    <span class="token comment" spellcheck="true"># 记入答案</span>            sl<span class="token punctuation">.</span>add<span class="token punctuation">(</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>                 <span class="token comment" spellcheck="true"># 将当前值加入有序数组中</span>        <span class="token keyword">return</span> res</code></pre>]]></content>
      
      
      <categories>
          
          <category> Sharing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Algorithm </tag>
            
            <tag> Coding </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>排序算法</title>
      <link href="/2022-05-16-pai-xu-suan-fa-md/"/>
      <url>/2022-05-16-pai-xu-suan-fa-md/</url>
      
        <content type="html"><![CDATA[<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><a href="https://www.runoob.com/w3cnote/ten-sorting-algorithm.html">1.0 十大经典排序算法 | 菜鸟教程</a></p><p><a href="https://zhuanlan.zhihu.com/p/42586566">知乎-十大经典排序算法</a></p><p><img src="sort1.png"></p><p><img src="sort2.png"></p><table><thead><tr><th>sorting algorithm</th><th>English Name</th><th>how</th><th>general rule</th><th>best case</th><th>worst case</th></tr></thead><tbody><tr><td><a href="https://www.runoob.com/w3cnote/bubble-sort.html">冒泡排序 </a></td><td>bubble sort</td><td>比较相邻两个元素，如果逆序就交换；接着比较下一对相邻两个元素。循环两次，外层循环结尾不断缩短。</td><td>只是作为一种知识来了解，很少有实际应用？？？<br><strong>适合小数据</strong></td><td>O(n)<br>ordered</td><td>O(n^2)<br>anti-ordered</td></tr><tr><td>选择排序</td><td>selection sort</td><td>选择当前最小的元素，放到已经排序好的末尾</td><td>选择排序是一种简单直观的排序算法，无论什么数据进去都是 O(n²) 的时间复杂度。所以用到它的时候，<strong>数据规模越小越好</strong>。唯一的好处可能就是不占用额外的内存空间了吧。</td><td>O(n^2)都一样</td><td>O(n^2)都一样</td></tr><tr><td>插入排序</td><td>insertion sort</td><td>扑克牌打法：对于未排序数据，在已排序序列从后向前扫描，找到相应位置并插入。</td><td>插入排序由于O( n2 )的复杂度，<strong>在数组较大的时候不适用。但是，在数据比较少的时候，是一个不错的选择</strong>，一般做为快速排序的扩充。例如，在STL的sort算法和stdlib的qsort算法中，都将插入排序<strong>作为快速排序的补充</strong>，用于少量元素的排序。又如，在JDK 7 java.util.Arrays所用的sort方法的实现中，当待排数组长度小于47时，会使用插入排序。</td><td>O(n)<br>ordered</td><td>O(n^2)<br>anti-ordered</td></tr><tr><td>堆排序</td><td>heapsort</td><td>使用堆这个数据结构来排序</td><td>堆排序在建立堆和调整堆的过程中会产生比较大的开销，在元素少的时候并不适用。但是，<strong>在元素比较多</strong>的情况下，还是不错的一个选择。尤其是在解决诸如“前n大的数”一类问题时，几乎是首选算法。</td><td>O(nlogn)都一样</td><td>O(nlogn)都一样</td></tr><tr><td>快排</td><td>quicksort</td><td>分治法，选择一个基准，把小于这个基准的放在左边，大于这个基准的放在右边</td><td>快速排序对于<strong>大数据的优秀排序性能</strong>和相同复杂度算法中相对简单的实现使它注定得到比其他算法更多的宠爱。<br>快速排序在大多数情况下都是适用的，尤其在数据量大的时候性能优越性更加明显。但是在必要的时候，需要考虑下优化以提高其在最坏情况下的性能。</td><td>O(n)<br>当顺序的时候</td><td>O(n^2)<br>当逆序的时候</td></tr><tr><td>归并排序</td><td>merge sort</td><td>分治思想<br>将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。</td><td>归并排序<strong>在数据量比较大</strong>的时候也有较为出色的表现（效率上），但是，其<strong>空间复杂度O(n)</strong> 使得在数据量特别大的时候（例如，1千万数据）几乎不可接受。而且，考虑到有的机器内存本身就比较小，因此，采用归并排序一定要注意。</td><td>O(nlogn)都一样</td><td>O(nlogn)都一样</td></tr><tr><td>计数排序</td><td>Bucket Sort/ Bin sort</td><td>核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序</td><td>要求输入的数据必须是有确定范围的整数。</td><td>O(n+k)都一样</td><td>O(n+k)都一样</td></tr><tr><td>基数排序</td><td>Radix Sort</td><td>将整数按位数切割成不同的数字，然后按每个位数分别比较。</td><td>基数排序要求较高，元素必须是整数，整数时长度10W以上，最大值100W以下效率较好，但是基数排序比其他排序好在可以适用字符串，或者其他需要根据多个条件进行排序的场景，例如日期，先排序日，再排序月，最后排序年 ，其它排序算法可是做不了的。</td><td>O(n*k)都一样</td><td>O(n*k)都一样</td></tr></tbody></table><ul><li><input checked="" disabled="" type="checkbox"> python内置的sort使用的是什么</li></ul><p><a href="https://blog.csdn.net/u010883226/article/details/84403263">Python里sort（）的排序算法–Timsort简介_山水无间道的博客-CSDN博客_python sort排序算法</a>Tim排序，是一种合并排序和插入排序的结合体。</p><ul><li><p>在排序长度<strong>低于64</strong>的时候采取：插入排序 。</p></li><li><p><strong>高于64</strong>的时候采取一种改良的归并排序。查找升序和降序的部分（Run），进行反转/合并</p></li><li><p><input checked="" disabled="" type="checkbox">  选择排序为什么是不稳定的？</p></li></ul><p><a href="https://blog.csdn.net/xiaolangmin/article/details/88538446">理解选择排序的不稳定性_小黄鸭zm的博客-CSDN博客_选择排序为什么不稳定</a></p><p>假设nums[0] == nums[1] &gt; nums[2] </p><p>交换之后是nums[2], nums[1], nums[0]。原来下标为0和1的顺序被破坏了</p><h1 id="排序算法之间的比较"><a href="#排序算法之间的比较" class="headerlink" title="排序算法之间的比较"></a>排序算法之间的比较</h1><p>应用最广泛的是快排</p><p>快速排序的最坏运行情况是 O(n²)，比如说顺序/逆序数列的快排。但它的平摊期望时间是 O(nlogn)。对绝大多数顺序性较弱的随机数列而言，快速排序总是优于归并排序。</p><p>为什么不是归并排序？</p><ul><li><p>快排O(nlogn) 记号中隐含的常数因子很小，比复杂度稳定等于 O(nlogn) 的归并排序要小很多。</p></li><li><p>归并排序在任何情况下的时间复杂度都是O(nlogn)，但是归并排序不是原地排序的，需要借助<strong>额外的存储空间</strong>。</p></li><li><p>归并排序的空间复杂度为什么是O(n)，而不是O(nlogn)？因为递归代码的<code>空间复杂度</code>并不能像<code>时间复杂度</code>那样累加，尽管每次合并操作都需要申请额外的内存空间，但在合并完成之后，临时开辟的内存空间就被释放掉了。在任意时刻，CPU 只会有一个函数在执行，也就只会有一个临时的内存空间在使用。<code>临时内存空间最大也不会超过 n 个数据的大小，所以空间复杂度是 O(n)</code>。<a href="https://blog.csdn.net/u010711495/article/details/117378617">归并排序的空间复杂度_鸭梨山大哎的博客-CSDN博客_归并排序空间复杂度</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Sharing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Algorithm </tag>
            
            <tag> Coding </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weekly summary</title>
      <link href="/y2022w1-summary/"/>
      <url>/y2022w1-summary/</url>
      
        <content type="html"><![CDATA[<p>2022年的第一周。</p><p>今天最大的愿望是好好经营自己的生活，善待自己了解自己。</p><p>这一周结束了一段维持四年的关系。有很多的不舍，但是我不能用爱情来掩盖不合适。逐渐明白了一个道理，不是有爱情就一定会幸福，恋爱不等于婚姻。当个人能量在一段爱情中不断被消耗时，需要及时止损。没有任何的对不起。我不会再向过去一样幼稚，试图丢掉这段时间的信物，以为能借此丢掉回忆。反之，我很感激这一段经历，在双方的青春里留下了一段美丽的过往。我会好好珍惜，从中汲取面对未来的勇气。</p><p>谢谢你，元元。祝各自幸福。</p><p>新的一周，职业上面临着业务调整。入职以来在做的产品，很可能会被别的组收走。我没啥遗憾，这本就是一个熟悉工作技能的机会，于我，目的已经达到了。接下来，就认真欢迎新的工作内容吧！</p><p>本周见到了小启凡，七哥，和元元最后一次视频，和姐姐打了将近三个小时的电话。开始逛起了Github，有些内容哟。</p><p>平淡度日，冷暖自知。</p><h1 id="计划回顾"><a href="#计划回顾" class="headerlink" title="计划回顾"></a>计划回顾</h1><p>工作技能</p><ul><li><p><input checked="" disabled="" type="checkbox">  总结了工作中遇到的有意思的算法</p></li><li><p><input checked="" disabled="" type="checkbox">  《改变未来的九大算法》，听书到第十章：什么是可计算？</p><p>养生/健身：</p></li><li><p><input checked="" disabled="" type="checkbox">  周三：T25 Gamma Pyramid, House</p></li><li><p><input checked="" disabled="" type="checkbox">  周五：复习舞蹈，Urban</p></li><li><p><input checked="" disabled="" type="checkbox">  周六周日：Hiphop集训课</p><p>影视</p></li><li><p><input checked="" disabled="" type="checkbox">  《本杰明巴顿奇事》</p></li><li><p><input checked="" disabled="" type="checkbox">  《婚姻故事》</p><p>写作</p></li><li><p><input checked="" disabled="" type="checkbox">  罗马：台伯河畔</p><p>读书</p></li><li><p><input checked="" disabled="" type="checkbox">  林徽因的故事</p><p>德语：</p></li><li><p><input checked="" disabled="" type="checkbox">  B1 Vokabel mit Top Thema</p></li></ul><h1 id="下周计划"><a href="#下周计划" class="headerlink" title="下周计划"></a>下周计划</h1><p>工作技能</p><ul><li><input disabled="" type="checkbox"> 《黑客与画家》阅读一章</li></ul><p>养生/健身</p><ul><li><input disabled="" type="checkbox"> 坚持饮食减重计划，本周的目标是减少400g</li><li><input disabled="" type="checkbox"> 周一：T25 gamma上半身阻力</li><li><input disabled="" type="checkbox"> 周二：Bodycombat</li><li><input disabled="" type="checkbox"> 周三：House</li><li><input disabled="" type="checkbox"> 周四：复习Hiphop和House</li><li><input disabled="" type="checkbox"> 周五：Urban</li><li><input disabled="" type="checkbox"> 周六：Locking</li><li><input disabled="" type="checkbox"> 周日：House + Locking</li></ul><p>影视</p><ul><li><input disabled="" type="checkbox"> 《七宗罪》（最近是大卫分奇的粉）</li></ul><p>写作</p><ul><li><input disabled="" type="checkbox"> 罗马：第一顿午饭</li></ul><p>读书</p><ul><li><input disabled="" type="checkbox"> 林徽因看完</li><li><input disabled="" type="checkbox"> 优雅的艺术</li></ul>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Life </tag>
            
            <tag> Work </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>该长大了</title>
      <link href="/gai-chang-da-liao/"/>
      <url>/gai-chang-da-liao/</url>
      
        <content type="html"><![CDATA[<p>2022年刚到的那一刻，脑子像被棒槌突然敲了一下。</p><p>我该长大了，在25岁的尾巴上。</p><p>这几天一直在思考自己过去几年的生活，得出的核心结论是：自我是混乱的。我没能准确定位自己想要什么，一直在不停地忙碌，却没有明确的方向。职业上差强人意，情感上一塌糊涂。在两团混乱间，还是先拣小的来理吧。</p><p>职业上差强人意。现在的工作内容，我整体上是满意的。但多多少少有些不甘心。为什么？没有大的title，没有令人满意的时薪，没有大的创造性输出，一直是个打工仔。我想要什么？我想去Google，为什么？工资高，名字响亮，可以去别的国家体验不一样的生活。那就不是打工仔了吗？那就会有更大的创造性了吗？不会，但是会更早地实现经济自由。OK，所以我最终的需求里，更重要的到底是创造性还是经济自由？这两者其实并不矛盾，说到底都是自由，自己支配时间和劳动的自由。我很着急实现这样的自由吗？不见得。虽然马上26岁了，但平心而论，自己的职业技能又有多高呢？我值得我理想中的薪资吗？我的能力和我的愿望匹配吗？</p><p>没有。那就先努力提升自己的能力啊，而不是预先烦恼该选择什么样的工作。等话语权到了自己的手上，再去谈条件。我未来想要什么样的生活？我想要去瑞士生活，贴近大自然和平静。瑞士哪里好？中国的互联网现代化等很多方面，其实远超瑞士。但是瑞士人有闲，有对自我追求的自由。“闲”，应该成为衡量生活的一个标尺吧。</p><p>情感上，从何说起呢？近来最深刻的认知是，“要好好爱自己”。</p><p>说起来是很简单的一句话。我也是最近才深刻地认识到，其实，我一直以来都没认为自己是值得好好疼爱的。这种认知来自于原生家庭。我不是被爸爸宠大的，而是苦大的，导致我内心里认为，吃苦比撒娇更美。这一点，在整个社会的衡量体系里，或许是被认可鼓励的。但是，从女人自身的角度，绝不是。当我静下心来，观察周围人的情感生活时，才发现人世间的幸与不幸竟有天壤之别。互相滋养的爱情是多么令人渴求，而多少人又陷入了无休止的双婚姻损耗中。去年这一年，经历了很多人事变故。同学的妈妈意外去世，疼爱我的舅妈情况恶化，妈妈的身体也出了诸多毛病。有多少是个人原因，又有多少是生活的消磨。</p><p>老话说，女孩要富养。这不是说，养女孩就是要培养一个个娇气的小公主。而是，让女孩不要太轻易被别人的示好所感动，要聪明，要知道如何考察一个人。</p><p>你是什么样的人，决定了你会遇到什么样的人。</p><p>此言甚是。我遇到的感情很好地契合了我的气质。而当我逐渐发现，自我损耗不断进行时，不是对方的错，而是自我的定位问题。如果我不改变自己的认知，就永远跳不出自我消耗的怪圈。</p><p>醒醒吧，该长大了。</p><p>2022，最大的愿望，是爱自己，从重塑自己开始。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Weekly summary</title>
      <link href="/y2021wd2-summary/"/>
      <url>/y2021wd2-summary/</url>
      
        <content type="html"><![CDATA[<h1 id="计划回顾"><a href="#计划回顾" class="headerlink" title="计划回顾"></a>计划回顾</h1><ul><li><input disabled="" type="checkbox"> 工作技能<ul><li><input disabled="" type="checkbox"> 继续总结《秒懂设计模式》（没做）</li><li><input checked="" disabled="" type="checkbox"> 周二C++学习继续</li><li><input checked="" disabled="" type="checkbox"> 《黑客与画家》看完两章</li></ul>养生/健身：<ul><li><input disabled="" type="checkbox"> 控制住核桃的食用量哦，每天不超过6颗好吧（超过了。。。嘤）</li><li><input checked="" disabled="" type="checkbox"> 周一：复习舞蹈</li><li><input checked="" disabled="" type="checkbox"> 周二：body combat</li><li><input checked="" disabled="" type="checkbox"> 周四：T25 gamma4</li><li><input checked="" disabled="" type="checkbox"> 周五：T25 gamma 5</li><li><input checked="" disabled="" type="checkbox"> 周日：House-&gt;改成了一节Hiphop和Locking</li></ul>影视<ul><li><input checked="" disabled="" type="checkbox"> 《社交网络》-〉改成了东方列车谋杀案</li></ul>写作：<ul><li><input checked="" disabled="" type="checkbox"> 在罗马的第一天</li></ul>德语：<ul><li><input checked="" disabled="" type="checkbox"> 第五篇</li><li><input checked="" disabled="" type="checkbox"> 第六篇</li></ul></li></ul><h1 id="收获"><a href="#收获" class="headerlink" title="收获"></a>收获</h1><p>本周没有大的事件。在工作上，所做的产品在接下来的一年可能面临着重大定位变革，所以最近在忙于总结性的工作。挺享受这样的过程的，一直忙碌反而没时间从大局上看看自己都干了什么，停下来总结下，反而有利于自己对工作的整体把握。</p><p>早起，真的觉得一天都变长了。可以干很多的事情。清了清自己的喜马拉雅，发现一个收藏了很久的听书节目《改变世界的九大算法》，内容很棒，我居然一直没听，差点错过。周六是圣诞节，约了几个小伙伴来家里玩耍，新室友也在这一天搬了进来，相处得很愉快。豆包最近在姨妈期，很是敏感，不再是原来的小可爱了。</p><p>这周看了《东方列车谋杀案》，一个典型的剧本杀式电影，我觉得比较有意思的一点是，车上来自欧洲不同国家的人说话的口音。</p><p>又快到年底了，我最喜欢的整理和立flag时间又到啦！回顾了下自己这几个月跳的舞，发现上的街舞课没有想象中的多，但是进步是很明显滴！这一点让我非常开心。要把自己学习街舞的过程记录下来哇～</p><h1 id="下周计划"><a href="#下周计划" class="headerlink" title="下周计划"></a>下周计划</h1><p>工作技能</p><ul><li><input disabled="" type="checkbox"> 继续总结《秒懂设计模式》</li><li><input disabled="" type="checkbox"> 《黑客与画家》看完第五章《另一条路》和第六章《如何创造财富》</li></ul><p>养生/健身：</p><ul><li><input disabled="" type="checkbox"> 控制住核桃的食用量哦，每天不超过6颗好吧</li><li><input disabled="" type="checkbox"> 周一：T25 gamma上半身阻力训练</li><li><input disabled="" type="checkbox"> 周二：T25gamma极限循环+body combat</li><li><input disabled="" type="checkbox"> 周三：T25gamma速度训练3.0House</li><li><input disabled="" type="checkbox"> 周四：Locking学习</li><li><input disabled="" type="checkbox"> 周五：T25 gamma金字塔训练</li></ul><p>影视</p><ul><li><input disabled="" type="checkbox"> 《搏击俱乐部》</li></ul><p>写作：</p><ul><li><input disabled="" type="checkbox"> 在罗马的第一天继续</li></ul><p>德语：</p><ul><li><input disabled="" type="checkbox"> 第七篇</li><li><input disabled="" type="checkbox"> 第八篇</li></ul>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Life </tag>
            
            <tag> Work </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weekly summary</title>
      <link href="/y2021wd3-summary/"/>
      <url>/y2021wd3-summary/</url>
      
        <content type="html"><![CDATA[<h1 id="计划回顾"><a href="#计划回顾" class="headerlink" title="计划回顾"></a>计划回顾</h1><p>工作技能</p><ul><li><input checked="" disabled="" type="checkbox"> 总结《秒懂设计模式》这本书（总结了一部分）</li><li><input disabled="" type="checkbox"> 安排新一轮的阅读/学习计划：<ul><li>中午/空闲的时候阅读：《黑客与画家》，《Vim实用技巧》</li><li>C++每周二晚上专项学习：《C++ Primer》，《C++语言的设计和演化》</li><li>每周四晚上专项学习：《程序员面试金典》，《程序员修炼之道：从 小工到专家》，《编程珠玑》</li></ul></li></ul><p>养生/健身：</p><ul><li><input checked="" disabled="" type="checkbox"> 下一周都在10点半前睡觉叭</li><li><input checked="" disabled="" type="checkbox"> 不要暴饮暴食，要清淡饮食哦</li><li><input checked="" disabled="" type="checkbox"> 周三：T25 gamma1</li><li><input checked="" disabled="" type="checkbox"> 周五：T25 gamma2</li></ul><p>影视</p><ul><li><input checked="" disabled="" type="checkbox"> 消失的爱人</li></ul><p>写作：</p><ul><li><input checked="" disabled="" type="checkbox"> 继续在去罗马的路上，争取抵达罗马。</li></ul><p>德语：</p><ul><li><input checked="" disabled="" type="checkbox"> Tief Ahmet und Hoch Bezena（没有完成）</li><li><input checked="" disabled="" type="checkbox"> 第四篇哦</li></ul><h1 id="收获"><a href="#收获" class="headerlink" title="收获"></a>收获</h1><p>上周给自己规划的内容，基本上都做完了呢。周二中午去参加公司的一个读书会，《沸腾十年》，讲的是互联网发展史。作者提出了一个看待这段历史以及展望未来的理论：五新，新技术，新需求，新媒介，新供给，新XX（忘记了，好像是闭环）。受到的启发，要有发现需求的眼光，以及要靠自己的独立思辨能力来发现需求，在对新需求的预判上，大佬也会犯错。借着这个读书会，又种草了一本饮食方面的书：《盐糖脂》，讲述现代食品工业对人的利用，读着读着，我觉得食品工业像是一个大骗局，也原谅了自己有时对垃圾食品的暴饮暴食，因为这就是他们想要的哇！工业巨头做了大量实验，想让人们达到停不下来的效果，我会这么做是情有可原的。更警醒我，要尽可能远离这场骗局。我对食物的认识又进了一步。</p><p>工作上，临近年底，发现自己在做的产品，有了大的改动，和之前预定的方向不一样。第一下，我觉得自己的很多工作“白”做了，有点愤怒。再一想，我在这个过程中，对整体的框架更熟悉了，做的每一个改动都是新的体验，也达到了预想的效果，对工程的认识得到了强化。进一步，意识到了产品经理以及产品规划的重要性，自己也开始主动思考产品的走向，这一进步我很满意。最后，主动找到了对应的产品经理聊我的想法，这个聊天让我更理解了他们所做的改动，也对产品大的走向有了认知，最初的愤怒也化解了。产品之外，在架构上进行迁移的工作，也有些收获。一是对推荐系统中精排模型的流程更为熟悉，二是掌握了一定在迁移中进行debug的方法，如何打log，如何尽快定位到自己的bug，进度略慢于预期，要加油哇！</p><p>生活上，这周和小郭姐去复兴门吃了一家新加坡餐厅星怡会，意外地惊喜，很喜欢，价格也可以接受，还想再去。早上听德语也快养成习惯了，跟着录音读几遍，比一味地听，进步得更明显，哇咔咔，继续加油！</p><p>马上有新室友要来了，是个喜欢狗狗的小姐姐，希望豆包和她友好相处。本来以为周末还能去收养一只新狗狗，结果被鸽了。</p><h1 id="下周计划"><a href="#下周计划" class="headerlink" title="下周计划"></a>下周计划</h1><p>工作技能</p><ul><li><input disabled="" type="checkbox"> 继续总结《秒懂设计模式》</li><li><input disabled="" type="checkbox"> 周二C++学习继续</li><li><input disabled="" type="checkbox"> 《黑客与画家》看完两章</li></ul><p>养生/健身：</p><ul><li><input disabled="" type="checkbox"> 控制住核桃的食用量哦，每天不超过6颗好吧</li><li><input disabled="" type="checkbox"> 周一：复习舞蹈</li><li><input disabled="" type="checkbox"> 周二：body combat</li><li><input disabled="" type="checkbox"> 周四：T25 gamma4</li><li><input disabled="" type="checkbox"> 周五：T25 gamma 5</li><li><input disabled="" type="checkbox"> 周日：House</li></ul><p>影视</p><ul><li><input disabled="" type="checkbox"> 《社交网络》</li></ul><p>写作：</p><ul><li><input disabled="" type="checkbox"> 在罗马的第一天</li></ul><p>德语：</p><ul><li><input disabled="" type="checkbox"> 第五篇</li><li><input disabled="" type="checkbox"> 第六篇</li></ul>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Life </tag>
            
            <tag> Work </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weekly summary</title>
      <link href="/y2021wd4-summary/"/>
      <url>/y2021wd4-summary/</url>
      
        <content type="html"><![CDATA[<h1 id="计划回顾"><a href="#计划回顾" class="headerlink" title="计划回顾"></a>计划回顾</h1><ul><li><input checked="" disabled="" type="checkbox"> 博客更新技术贴：proto和thrift（正在整理中）</li><li><input disabled="" type="checkbox"> 德语三篇（66%）<ul><li><input checked="" disabled="" type="checkbox"> KlimaSchutz-Index</li><li><input checked="" disabled="" type="checkbox"> Sternsinger helfen Kinder in Not</li><li><input disabled="" type="checkbox"> Tief Ahmet und Hoch Bezena（没有完成）</li></ul></li><li><input checked="" disabled="" type="checkbox"> 写作：（100%）<ul><li><input checked="" disabled="" type="checkbox"> 意大利初印象</li></ul></li><li><input disabled="" type="checkbox"> 阅读总结：<ul><li><input disabled="" type="checkbox"> 《厨房里的哲学家》</li><li><input disabled="" type="checkbox"> 《远方的鼓声》</li></ul></li><li><input checked="" disabled="" type="checkbox"> 影视：<ul><li><input checked="" disabled="" type="checkbox"> 消失的爱人（看了薄暮之光和我是谁，没有绝对安全的系统）</li><li><input checked="" disabled="" type="checkbox"> 国王排名第八集</li></ul></li><li><input checked="" disabled="" type="checkbox"> 健身：（80%）<ul><li><input checked="" disabled="" type="checkbox"> T25 beta 4</li><li><input checked="" disabled="" type="checkbox"> T25 beta 3+7</li><li><input checked="" disabled="" type="checkbox"> T25 gamma 1（改为了urban）</li><li><input checked="" disabled="" type="checkbox"> T25 gamma 2（改为了locking）</li><li><input disabled="" type="checkbox"> T25 gamma 3（亲戚来了，暂停）</li></ul></li></ul><h1 id="收获"><a href="#收获" class="headerlink" title="收获"></a>收获</h1><p>重新在生活里引入计划之后，心情舒畅了好多！那种无所事事的懒散驱散了，感觉每天又有很多收获呢。</p><p>因为整个人的积极性被带动了起来，在计划之外，又做了很多bonus的事。譬如周三早上花了30分钟跑了5公里多，利用中午的时间，把一本看了两个多月的书给看完了，对于工作的帮助很大。日常锻炼之外的街舞课也让人很愉悦。每天晚上遛豆包的时候，开始听《时间移民》，脑洞又丰富了一些。睡前读物变成了《品味四讲》，不得不说，这是本让人很安静享受的书。上Locking课的时候，收获了一个新的认知：Locking的pose一定要尽可能的停住，拉满节拍。Locking学了两个脚步和一个double的变换。老师教诲，街舞好多套路是single,single, double。昨天看了《我是谁：没有绝对安全的系统》，有被黑客吸引到。今天又在逛b站的时候，看了个《未来食物》，知道了有种叫做“分子料理”的很fancy的烹饪手法（其实，棉花糖就是一种啦），但是我大概率还是会喜欢原生态的食物。</p><p>豆包刚满六个月，就来姨妈了。虽然还是个小闹腾，但已经是大姑娘了，以后遛她的时候，还要开始提防小公狗们，哎呀呀，满满的老父亲心态。</p><p>这周在工作上，尝试了一个新的东西：从零调用别人的服务。目前还没有调通，对远程服务多了些认识，又能学到新东西了。今天突然想给自己的基金管理写一个爬虫，每天去爬数据，每周给我生成dashboard，帮我总结盈亏。因为现在的基金在多个平台上，管理起来比较麻烦。以后有空的时候拿出来做一做。</p><h1 id="下周计划"><a href="#下周计划" class="headerlink" title="下周计划"></a>下周计划</h1><p>工作技能</p><ul><li><input disabled="" type="checkbox"> 总结《秒懂设计模式》这本书</li><li><input disabled="" type="checkbox"> 安排新一轮的阅读/学习计划：书单《程序员面试金典》，《程序员修炼之道：从 小工到专家》，《编程珠玑》，《C++语言的设计和演化》，《Vim实用技巧》、《黑客与画家》，《C++ Primer》</li></ul><p>养生/健身：</p><ul><li><input disabled="" type="checkbox"> 下一周都在10点半前睡觉叭</li><li><input disabled="" type="checkbox"> 不要暴饮暴食，要清淡饮食哦</li><li><input disabled="" type="checkbox"> 周三：T25 gamma1</li><li><input disabled="" type="checkbox"> 周五：T25 gamma2</li></ul><p>影视</p><ul><li><input disabled="" type="checkbox"> 消失的爱人</li></ul><p>写作：</p><ul><li><input disabled="" type="checkbox"> 继续在去罗马的路上，争取抵达罗马。</li></ul><p>德语：</p><ul><li><input disabled="" type="checkbox"> Tief Ahmet und Hoch Bezena（没有完成）</li><li><input disabled="" type="checkbox"> 第四篇哦</li></ul>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Life </tag>
            
            <tag> Work </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weekly summary</title>
      <link href="/y2021wd5-summary/"/>
      <url>/y2021wd5-summary/</url>
      
        <content type="html"><![CDATA[<p>算下来，开始工作已经14周了，更新博客也停止14周了。按照学生时代的日历计算，14周相当于一个学期。这个学期初有很多的雄心壮志，一个学期过去也大多不了了之。我对自己许诺的工作阶段的生活状态，和当前自己真实的生活状态对比，还有相当大的差距。我为自己找的借口是“需要时间来适应”。这么长时间，也该适应够了。开始践行，就从更新博客开始吧。</p><p>那么，我对自己许诺的工作阶段的生活状态是什么呢？</p><p>理想目标上，是锻炼身体要坚持，专业学习不能停，生活内容要丰富，日常心态要平和。</p><p>空泛的目标落实到行动上应当是，</p><table><thead><tr><th>目标</th><th>行动</th></tr></thead><tbody><tr><td>锻炼</td><td>日常锻炼和兴趣爱好。工作日每天都要有半个小时+的锻炼时间，现在是T25进行中，要穿插安排瑜伽时间。兴趣爱好是街舞，每周至少三次街舞课。</td></tr><tr><td>专业学习</td><td>工作中遇到的新技能/新疑惑要及时解决。不能光工作而忘记了反思。</td></tr><tr><td>生活内容</td><td>剧本杀，影视剧，语言学习，阅读，狗子。</td></tr><tr><td>心态</td><td>周日属于自己的安静时刻。要自律。不急躁。</td></tr></tbody></table><p>然而，这14周，我并没有按照理想状态在行动。反思反思。</p><p>最容易破防的是自律，主要体现在饮食上。我常常会吃得很多。</p><p>为什么？资源过多。于我，过多的资源就是一种负担，心理上的负担，总是惦记着那些资源，觉得不用就是亏了。人啊，在资源有限时表现出的自制力，在资源无限时，容易崩溃。节制的敌人怕不是免费。公司的每天免费供应的零食和三餐，每天都在挑战我的自制力。每次发现好吃的，我身上总会经历这么一段对抗。自制力说，“别吃了，适可而止。再吃就是负担了。”贪婪的嘴巴说，“可是它好好吃啊。不吃就亏了。”亏了？亏着谁了？免费的东西总想多拿是不是？结局就是，要么吃得很多，累着了肠胃，撑到难受这种情况也发生过几次；要么把食物打包囤起来，坏掉了，进了垃圾桶。前者变成了自己身体上的负担，后者变成了垃圾桶的负担，浪费了粮食，又成了心理上的负担。且不论最后的负担，就这对抗本身，已经是挺费神的一件事了。</p><p>我必须学着为自己减负。</p><p>How?</p><p>或许我应该尝试把快乐的感觉，建立在享受适当分量的过程中，而不是霸占了额外分量的负担中。具体一点，拿吃饭来说，在吃每一口的时候，专注地去体会它给我带来的快乐，先把自己的快乐值充满。而非，分神去想，我要更多，更多，快乐值留着舍不得充，等着用额外的食物来充。这固然还是个理想状态。最硬的操作应该是，断掉无限资源的来源。我喜欢囤额外的零食是吧，那就扔掉桌子上存零食的袋子，让零食没有地方可以放。把家里囤的食物都清理掉，不要再拿不要再买。我不是一贯关心环保吗？多吃一份零食，它整个生产过程，包装袋，垃圾回收都额外给环境带来了多少负担哇？饿的时候吃些水果，最起码能节省些垃圾处理的环境负担。</p><p>下一个要反思的点是习惯养成。14周了，并没有养成多少很好的routine。大多时候想的是，“接下来我要怎样怎样”。“接下来”这个时刻似乎一直没等到，然而一回顾，发现已经过去14周了，吓一跳。所以，就从现在开始吧？没有养成良好的习惯，一个是因为计划没想清楚，二个是因为动力没充够。（也有我想做的事情太多的锅）现在就来针对这两方面解决解决。我想养成的习惯是什么？计划是什么？动力是什么？</p><ul><li><p>每天学习德语或者日语。</p><ul><li>德语的话，找到了dw的Top Thema系列，正好符合我这个阶段的水平（附一个19年的b站链接<a href="https://www.bilibili.com/video/BV1Ut411F7p1%EF%BC%89%E3%80%82%E6%AF%8F%E4%B8%80%E8%8A%82%E6%98%AF%E4%B8%80%E4%B8%AA%E4%B8%89%E5%88%86%E9%92%9F%E5%B7%A6%E5%8F%B3%E7%9A%84%E9%9F%B3%E9%A2%91%EF%BC%8C%E9%85%8D%E5%A5%97%E7%BB%83%E4%B9%A0%E5%92%8Cscript%E3%80%82%E6%88%91%E7%9A%84%E8%AE%A1%E5%88%92%E6%98%AF%EF%BC%8C%E6%AF%8F%E5%91%A8%E8%BF%9B%E8%A1%8C%E4%B8%89%E8%8A%82%E3%80%82%E6%AF%8F%E4%B8%80%E8%8A%82%E7%9A%84%E9%9F%B3%E9%A2%91%EF%BC%8C%E5%9C%A8%E5%81%9A%E7%BB%83%E4%B9%A0%E6%97%B6%E5%BA%94%E8%AF%A5%E4%BC%9A%E5%90%AC%E5%88%B0%E4%B8%89%E9%81%8D%EF%BC%8C%E5%AF%B9%E7%9D%80script%E5%90%AC%E4%B8%80%E9%81%8D%E3%80%82%E8%84%B1%E7%A6%BBscript%E6%85%A2%E9%80%9F%E5%90%AC%E4%B8%80%E9%81%8D%EF%BC%8C%E8%B7%9F%E8%AF%BB2-3%E9%81%8D%EF%BC%8C%E8%80%97%E6%97%B6%E5%A4%A7%E6%A6%82%E5%9C%A8%E5%8D%8A%E5%B0%8F%E6%97%B6%E3%80%82%E8%BF%99%E8%8A%82%E7%9A%84%E5%8D%95%E8%AF%8D%E6%97%A9%E4%B8%8A%E5%AD%A6%E4%B9%A0%E4%B8%80%E9%81%8D%EF%BC%8C%E4%B8%AD%E5%8D%88%E5%A4%8D%E4%B9%A0%E4%B8%80%E9%81%8D%EF%BC%8C%E6%99%9A%E4%B8%8A%E5%86%8D%E5%A4%8D%E4%B9%A0%E4%B8%80%E9%81%8D%E3%80%82%E5%8A%A8%E5%8A%9B%E6%98%AF%EF%BC%8C%E6%88%91%E6%97%A9%E6%99%9A%E6%98%AF%E8%A6%81%E5%8E%BB%E5%88%B0%E5%BE%B7%E8%AF%AD%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%94%9F%E6%B4%BB%E7%9A%84%E3%80%82">https://www.bilibili.com/video/BV1Ut411F7p1）。每一节是一个三分钟左右的音频，配套练习和script。我的计划是，每周进行三节。每一节的音频，在做练习时应该会听到三遍，对着script听一遍。脱离script慢速听一遍，跟读2-3遍，耗时大概在半小时。这节的单词早上学习一遍，中午复习一遍，晚上再复习一遍。动力是，我早晚是要去到德语环境中生活的。</a></li><li>日语的话，找到了b站的一个教学系列。可以每天早上遛狗的时候听听音频，周末集中学习1-2节b站上的课。动力是，看孤独的美食家。</li></ul></li><li><p>系统性地学习街舞。</p><ul><li>跟着老师练，是在周五晚上的urban，周六晚上的locking和周日晚上的House。自己练习的话，放在我早上健身之后，以及晚上有空的时间吧。周一早上用十几分钟的样子，复习学过的内容。周二早上，简单复习，学习一个简单的locking元素。周三早上，简单复习locking元素，周三晚上学习四个简单的house元素。周四早上，复习house元素，学习两个hiphop元素，晚上自学一段Hiphop律动。周五早上，集中复习。动力，这是我一生的爱好，跳舞是个又费脑子又锻炼身体的活，我喜欢，而且还有融合音乐的快乐。</li></ul></li><li><p>精进职业技能</p><ul><li>包括各种编程的技术和知识点。这一点，在每天的工作中会遇到一些general的，之前不太理解的知识，譬如rpc，proto，C++的进阶知识这种；还可以系统性地学习巩固知识点。对于每天遇到的，最好工作日晚上十点后，简短地对当天的难点进行一些回顾和记录。对于系统性地学习，工作日中午抽出一小点阅读时间，把想要学习的资料按顺序阅读，周末再集中整理笔记。目前的阅读list有：《秒懂设计模式》，《代码之外的功夫：程序员的精进之路》，《C++语言的设计和演化》。动力是，要靠这家伙吃饭，工程基础一定要打扎实了。</li></ul></li><li><p>阅读和写作计划</p><ul><li>这个放在周二晚上写作吧，其他晚上的时间可以看看书。动力，这也是我的爱好，特别是涉及创造，让人很有成就感。</li></ul></li><li><p>健康的饮食和运动习惯。</p><ul><li>饮食的话，我心里老是很别扭。吃的时候不敢吃，过分控制又导致饿的时候自制力崩溃，狂吃。结果还不如不控制的好。要详细列出一个饮食时间表和内容表，好好控制住自己，要可持续。运动习惯是迄今为止，我比较满意的，算是养成了的一个习惯，每天早上工作前会去做T25，提高一天的代谢水平。还希望能把瑜伽加入进来，我这四十岁的肩颈，需要好好治治。动力，可持续的健康习惯会让整个人的状态都不一样。</li></ul><p>这次反思得差不多了，从时间的角度总结一下：</p><p>工作日的早晨，先起来遛豆包，这个时间可以听听日语音频和德语新闻，半小时左右。遛完豆包回家学习一段德语音频，又是半小时左右。八点到十点是运动加早餐的时间。十二点后是午餐、午间阅读，背单词和午休的时间。大概五点钟要补充些水果或者蛋白质缓解饥饿。七点后是下班时间，晚饭加遛豆包，到家应该是八点半。进行写作or街舞学习or阅读or看剧。十点小总结下，休息。</p></li></ul><p>不错，计划贴起来，加油宝贝！每周要来博客更新哦～</p><h1 id="下周计划"><a href="#下周计划" class="headerlink" title="下周计划"></a>下周计划</h1><ul><li><input disabled="" type="checkbox"> 博客更新技术贴：proto和thrift</li><li><input disabled="" type="checkbox"> 德语三篇<ul><li><input disabled="" type="checkbox"> KlimaSchutz-Index</li><li><input disabled="" type="checkbox"> Sternsinger helfen Kinder in Not</li><li><input disabled="" type="checkbox"> Tief Ahmet und Hoch Bezena</li></ul></li><li><input disabled="" type="checkbox"> 写作：<ul><li><input disabled="" type="checkbox"> 意大利初印象</li></ul></li><li><input disabled="" type="checkbox"> 阅读总结：<ul><li><input disabled="" type="checkbox"> 《厨房里的哲学家》</li><li><input disabled="" type="checkbox"> 《远方的鼓声》</li></ul></li><li><input disabled="" type="checkbox"> 影视：<ul><li><input disabled="" type="checkbox"> 消失的爱人</li><li><input disabled="" type="checkbox"> 国王排名第八集</li></ul></li><li><input disabled="" type="checkbox"> 健身：<ul><li><input disabled="" type="checkbox"> T25 beta 4</li><li><input disabled="" type="checkbox"> T25 beta 3+7</li><li><input disabled="" type="checkbox"> T25 gamma 1</li><li><input disabled="" type="checkbox"> T25 gamma 2</li><li><input disabled="" type="checkbox"> T25 gamma 3</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Life </tag>
            
            <tag> Work </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo进阶一：认识基本组件</title>
      <link href="/hexo3/"/>
      <url>/hexo3/</url>
      
        <content type="html"><![CDATA[<p>本篇是Hexo进阶内容的第一篇，主要介绍为了DIY Hexo主题风格，大概率会修改的组件/文件。将介绍以下内容：</p><ul><li>基本文件结构<ul><li>两个config的yaml文件</li><li>source文件夹</li><li>theme文件夹</li></ul></li><li>web前端“三剑客”：HTML+CSS+JavaScript及开发者工具</li></ul><p>本期视频很多内容参考<a href="https://www.youtube.com/watch?v=Jiwbmyc4nCA&amp;list=PLLAZ4kZ9dFpOMJR6D25ishrSedvsguVSm&amp;index=6">YouTube Hexo系列视频</a>，强烈推荐该系列视频，每一集只有几分钟，讲得深入浅出，实用性很强。之后会出一篇介绍我对Matery主题的个性化配置和修改，还会出一篇介绍hexo使用的优质资源分享。</p><h1 id="基本文件结构"><a href="#基本文件结构" class="headerlink" title="基本文件结构"></a>基本文件结构</h1><p>当你第一次成功运行了一次hexo之后<code>hexo s</code>或者<code>hexo d</code>，在你的blog文件夹下，会看到以下的文件结构：</p><pre class=" language-bash"><code class="language-bash">- _config.yml- source/    <span class="token operator">|</span>--- _posts/    <span class="token operator">|</span>--- _data/    <span class="token operator">|</span>--- drafts/    <span class="token operator">|</span>--- about/    <span class="token operator">|</span>--- other folders- themes/    <span class="token operator">|</span>--- one or <span class="token function">more</span> theme folders, <span class="token keyword">in</span> each folder         <span class="token operator">|</span>--- _config.yml         <span class="token operator">|</span>--- languages/              <span class="token operator">|</span>--- yaml files         <span class="token operator">|</span>--- layout/              <span class="token operator">|</span>--- <span class="token punctuation">(</span>_partial/<span class="token punctuation">)</span>              <span class="token operator">|</span>--- <span class="token punctuation">(</span>_widget/<span class="token punctuation">)</span>              <span class="token operator">|</span>--- layout.ejs              <span class="token operator">|</span>--- index.ejs              <span class="token operator">|</span>--- post.ejs              <span class="token operator">|</span>--- other ejs files         <span class="token operator">|</span>--- source/              <span class="token operator">|</span>--- css/              <span class="token operator">|</span>--- js/              <span class="token operator">|</span>--- libs/              <span class="token operator">|</span>--- medias/         <span class="token operator">|</span>--- Others- package-lock.json- package.json- scaffolds/    <span class="token operator">|</span>--- several markdown files- public/- node_modules/- db.json</code></pre><p>作为一名前端小白，我第一次看到这些文件夹时，两眼一抹黑，根本不知道要改哪里。经过好长一段时间的摸索，逐渐搞清楚了。这里会按照重要性的顺序和使用的顺序来进行重点介绍。</p><p>首先的首先，我以为前端/hexo的重要三部分就是<strong>“内容+样式+功能”</strong>。一切的一切都是围绕这三项展开。</p><h2 id="两个config的yaml文件"><a href="#两个config的yaml文件" class="headerlink" title="两个config的yaml文件"></a>两个config的yaml文件</h2><p>通常，要DIY自己的网站的第一步就是修改<code>_config.yml</code>文件。注意：有两种<code>_config.yml</code>文件，</p><ul><li>第一种在最上层的文件夹里<code>***.github.io/_config.yml</code></li><li>第二种是在<code>themes/</code>文件夹下，和每个theme相匹配，例如<code>***.github.io/themes/matery/_config.yml</code></li></ul><p>为了便于区分，我将第一种称为大config，第二种称为小config。第一步修改的是大config。</p><p>大config涵盖了网站general的设置，比如网站的title，description，permalink等，详情参考<a href="https://hexo.io/zh-cn/docs/configuration.html">Hexo官方配置文档</a>。其中，选择使用哪个主题也在大config里设置。将<code>theme:</code>属性的值设置为<code>themes/</code>文件夹下你希望使用的主题的文件夹名字即可。</p><p>小config主要是针对特定的主题进行属性设置，不同主题的小config文件包含的属性也不一样。在接下来的一篇分享，我会针对<a href="https://github.com/blinkfox/hexo-theme-matery">Matery主题</a>详细介绍如何进行小config的修改。 </p><p>这两个文件对内容，样式，功能三个方面都有涉及。</p><h2 id="source文件夹"><a href="#source文件夹" class="headerlink" title="source文件夹"></a>source文件夹</h2><p>source文件夹是在主题配置完成后，主要进行文档写作，博客内容更新的地方。其中：</p><ul><li><code>_posts/</code>文件夹存放的是一般的blog markdown文件，会被最终展示到博客上，</li><li>而<code>drafts/</code>下面放的是草稿，这部分内容默认是不会被hexo渲染，也不会显示在网站上的。很方便地用于存储创作中的文章。</li><li><code>_data/</code>文件夹，如<a href="https://hexo.io/zh-cn/docs/data-files.html">官网介绍</a>，用于存放一些并不在文章内，且是需要重复使用的资料/数据。该文件夹下的文档的调用方式是：使用js/ejs，通过<code>site.data.filename</code>来调用。</li><li>其他诸如<code>categories/</code>，<code>tags/</code>，<code>404/</code>等文件夹，都是规定了相对应的分类页面，标签页面，404页面的内容。可匹配对应页面的在主题里的css, ejs文件做修改。之后也会分享到。</li></ul><h2 id="theme文件夹"><a href="#theme文件夹" class="headerlink" title="theme文件夹"></a>theme文件夹</h2><p>theme文件夹是前期对主题进行个性化设置时，主要修改的地方。一个theme主题的构成包括什么？老三样：<strong>“内容+样式+功能”</strong>。theme文件夹下的文件及文件们也对应着这三样。</p><ul><li>小config文件：是与当前主题相关的general的设置。比如：是否开启当前主题的某种功能。</li><li><code>languages/</code>： 存储属性与对应语言的翻译，用于更改网站的基础显示语言。</li><li><code>layout/</code>：一系列的<a href="https://ejs.bootcss.com/">ejs文件</a>：是一套简单的模板语言，帮你利用普通的 JavaScript 代码生成 HTML 页面。可以理解为既包含了<strong>内容</strong>，又包含了<strong>功能</strong>，像是HTML和Java Script的综合体。其下的子文件夹无非是为了将同类的文件聚集到一起，增强结构的可读性。譬如：<code>layout/_partial/</code>里存放的是部分在不同页面共同使用的网页模块，页眉页脚等。</li><li><code>themes/.../source/</code>这个文件夹包含css的<strong>样式</strong>设置，网页展示使用的图片、logo等，额外安装的功能库等，如<a href="https://github.com/gitalk/gitalk/">gitalk</a>，<a href="https://echarts.apache.org/zh/index.html">echarts</a>。</li></ul><p>不同的主题下的文件结构可能略有差异，但构成内容大同小异。通常如果只是修改配色，就去到对应的<code>themes/.../source/css/...</code>去找到对应的部件/属性进行样式修改。如果要修改显示的内容，则需要到<code>themes/.../layout/</code>中找到对应的ejs文件进行修改。如果要修改/增删功能，也需要找到对应的ejs文件进行修改。</p><h2 id="其他的文件夹"><a href="#其他的文件夹" class="headerlink" title="其他的文件夹"></a>其他的文件夹</h2><p>其他的一级文件或者文件夹，很少会在个性化配置中进行更改，此处不赘述。如感兴趣<code>scaffolds/</code>文件夹，可以参考<a href="../hexo2/index.html#toc-heading-4">Hexo2: layout是什么</a>。<code>public/</code>文件夹请参考<a href="../hexo2/index.html#toc-heading-15">Hexo2：发布文章</a>中的<code>hexo clean</code>和<code>hexo generate</code>命令。</p><h1 id="Web前端“三剑客”"><a href="#Web前端“三剑客”" class="headerlink" title="Web前端“三剑客”"></a>Web前端“三剑客”</h1><p>这一部分，是我这个web前端小白入门前端的过程，希望能帮助到同样处境的人。当然前端的知识体系非常庞大，远不止我说的这三个，如果有进一步学习需求的小伙伴，推荐以下资源：</p><ul><li><a href="https://github.com/qianguyihao/Web">Github：前端入门到进阶图文教程</a></li><li><a href="https://www.youtube.com/watch?v=W6NZfCO5SIk">YouTube: JavaScript in 1 hour</a></li><li><a href="https://www.youtube.com/watch?v=qz0aGYrrlhU&amp;t=7s">YouTube: Learn HTML in 1 hour</a></li><li><a href="https://www.youtube.com/watch?v=TlB_eWDSMt4">YouTube: Node.js in 1 hour</a></li></ul><p>先来简要介绍一下“三剑客”都是谁，有什么作用，该如何使用。主要参考自<a href="https://github.com/qianguyihao/Web">Github：前端入门到进阶图文教程</a>。web前端“三剑客”包括：HTML，CSS和JS。</p><ul><li><strong>HTML</strong>：全称为 HyperText Markup Language，译为<strong>超文本标记语言</strong>。是用来组织网页的元素和<strong>内容</strong>的，也就是各个浏览器直接拿来显示给用户的文档。<ul><li>HyperText：超出了文本的限制，包括图片，音频，视频等</li><li>Markup：标记语言。会给元素做上标记，表明它是超链接啊，还是一级标题啊，还是图片啊，等等</li></ul></li><li><a href="https://www.runoob.com/css/css-intro.html"><strong>CSS</strong></a>：全称为<strong>C</strong>ascading <strong>S</strong>tyle <strong>S</strong>heets，译为<strong>层叠样式表</strong>。是定义如何显示HTML元素的，比如字体啊，颜色啊，大小啊，图片的长宽啊等等。负责老三样中的<strong>样式</strong>。</li><li>JS：全称为JavaScript，译为用Java写的脚本？是描述网页的<strong>行为功能</strong>（实现业务逻辑和页面控制）的，实现用户和网页的交互。而hexo里使用的ejs文档，又可译作embedded JavaScript，就是利用JavaScript生成HTML页面的。它和很多大家熟悉的编程语言Python，C/C++，Java等很像，有语法和对象。<ul><li>ECMAScript：JavaScript 的语法标准。包括变量、表达式、运算符、函数、if语句、for语句等。</li><li>DOM：Document Object Model（文档对象模型），操作页面上的元素的API。比如让盒子移动、变色、改变大小、轮播图等等。</li><li>BOM：Browser Object Model（浏览器对象模型），操作浏览器部分功能的API。通过BOM可以操作浏览器窗口，比如弹框、控制浏览器跳转、获取浏览器分辨率等等。</li></ul></li></ul><p>总结来说，就是HTML管内容，描述页面结构；CSS管样式，追求审美；JavaScript管功能，实现行为。当我们对这三方面有需求的时候，就去到各自的文件里进行修改即可。</p><h2 id="开发者工具"><a href="#开发者工具" class="headerlink" title="开发者工具"></a>开发者工具</h2><p>最后介绍一个特别好用的工具：浏览器的开发者工具。</p><p>我所使用的浏览器FireFox和Google Chrome都具备这个功能。在FireFox/Google Chrom的“更多工具”中有个名为“Web开发者工具”的，Mac上对应的快捷键是<code>Option+Command+I</code>。一开始，我并不知道这个工具，修改主题时，那叫一个痛苦，后来得此利器，原地起飞。Web开发者工具不仅方便定位到代码位置，还可以直接调试css样式属性，即时查看效果，另外这些修改并不会动到原始的代码，极其方便进行大量尝试。</p><p>这个视频<a href="https://www.youtube.com/watch?v=qz0aGYrrlhU&amp;t=7s">YouTube: Learn HTML in 1 hour</a>从14:30秒起简要介绍了web开发者工具，无法科学上网的小伙伴也可以参考<a href="https://developer.mozilla.org/zh-CN/docs/Tools">FireFox Tools</a>。</p><p>总结，本篇主要介绍了理论内容，尽可能地为进行主题个性化配置打下理论基础，免得到时候两眼一抹黑，胡同里乱钻。另外，强烈推荐使用<strong>Web开发者工具</strong>，此乃神器！</p><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><ol><li><a href="https://www.youtube.com/watch?v=Jiwbmyc4nCA&amp;list=PLLAZ4kZ9dFpOMJR6D25ishrSedvsguVSm&amp;index=6">YouTube Hexo系列视频</a></li><li><a href="https://github.com/blinkfox/hexo-theme-matery">Hexo Matery主题</a></li><li><a href="https://hexo.io/zh-cn/docs/data-files.html">Hexo data文件夹</a></li><li><a href="https://github.com/gitalk/gitalk/">gitalk</a></li><li><a href="https://echarts.apache.org/zh/index.html">echarts</a></li><li><a href="https://github.com/qianguyihao/Web">Github：前端入门到进阶图文教程</a></li><li><a href="https://www.youtube.com/watch?v=W6NZfCO5SIk">YouTube: JavaScript in 1 hour</a></li><li><a href="https://www.youtube.com/watch?v=qz0aGYrrlhU&amp;t=7s">YouTube: Learn HTML in 1 hour</a></li><li><a href="https://www.youtube.com/watch?v=TlB_eWDSMt4">YouTube: Node.js in 1 hour</a></li><li><a href="https://www.runoob.com/css/css-intro.html">CSS</a></li><li><a href="https://developer.mozilla.org/zh-CN/docs/Tools">FireFox Tools</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Sharing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一次完整的Hexo写作流程</title>
      <link href="/hexo2/"/>
      <url>/hexo2/</url>
      
        <content type="html"><![CDATA[<p>推荐有任何疑问点的时候，先去查阅<a href="https://hexo.io/zh-cn/docs/writing.html">hexo官方文档</a>。但是官方文档，有着工具书共同的弊端：缺乏对日常操作的指导性，难以分清阅读顺序，难以区分各个内容的重要程度和优先级。</p><p>我将根据一次hexo更新博客的完整流程，重新整理总结需要的命令操作。</p><p>网上也有很多博文进行此方面操作，可参考<a href="https://zhuanlan.zhihu.com/p/156915260">知乎Hexo博客写文章及基本操作</a>。不同于这些博文，我会额外介绍操作背后的原理。</p><p>一次使用hexo更新博客的基础操作流程为：</p><ol><li>新建一个文章</li><li>文章写作</li><li>本地预览更新后的博客</li><li>远程部署更新博客</li></ol><h1 id="新建文章"><a href="#新建文章" class="headerlink" title="新建文章"></a>新建文章</h1><p>实际上，hexo渲染一篇post的工作流程是：</p><ol><li><p>拿到一个markdown文件，</p></li><li><p>根据这个文件的layout类型，</p></li><li><p>进行样式排版，生成html文件，</p></li><li><p>最终展示到网页端。</p></li></ol><p>因此，一个<code>_posts/</code>文件夹下的markdown文件就会对应到一篇post。所以，第一步是创建一个markdown文件。有两种方法：</p><ul><li>使用hexo的命令</li><li>按常规的操作，新建一个markdown文件，并保存到<code>_posts/</code>文件夹下即可。</li></ul><h2 id="使用hexo的命令"><a href="#使用hexo的命令" class="headerlink" title="使用hexo的命令"></a>使用hexo的命令</h2><p>官方文档是这么说的：</p><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token punctuation">[</span>layout<span class="token punctuation">]</span> <span class="token operator">&lt;</span>title<span class="token operator">></span></code></pre><p>实际上，常用的操作是：</p><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"我的第一篇文章"</span></code></pre><p>输入这行命令背后的操作是：默认生成一个<strong>layout</strong>为post类型的markdown文件，该文件存储为<code>***.github.io/source/_posts/我的第一篇文章.md</code>。</p><h2 id="常规的操作"><a href="#常规的操作" class="headerlink" title="常规的操作"></a>常规的操作</h2><p>也可以不使用命令行进行生成，我更习惯于直接在Typora中新建文件，并保存到<code>***.github.io/source/_posts/</code>这个位置。</p><p>我觉得这样的操作更便捷，因为我常常是打开Typora之后，有多个文档要写，直接<code>Ctrl + N</code>新建一个文档，会快很多。当然这种操作也有弊端：</p><ul><li><p>需要手动添加文章头部信息Front Matter。添加头部信息Front Matter的操作是：</p><ul><li>先输入三个短横线-，<code>---</code>，然后回车。</li><li>在出现的阴影框里，输入希望添加的属性值，<ul><li>常用的有<code>title, date, author</code></li><li>次常用的有<code>categories, tags</code></li><li><a href="https://hexo.io/zh-cn/docs/front-matter">Front-Matter official manual</a></li><li>其他的还有比如：<code>mathjax</code>, <code>top</code>等是hexo的一些插件需要使用的参数。</li></ul></li></ul><p>Front Matter其实就是预先告诉hexo该博文的一些基本属性。可以用文件类比，理解为文件的类型信息，创建日期信息，用什么方式打开，而不涉及具体的文件内容。</p></li><li><p>如果该文章需要展示图片，pdf等其他文件时，需要自行创建一个<strong>同名文件夹</strong>。示例，如果你的markdown文件叫做<code>_posts/markdown-demo.md</code>的话，同名文件夹就是<code>_posts/markdown-demo/</code>。</p><p>如果你将<code>***.github.io/_config.yml</code>中的<code>post_asset_folder</code>设置为<code>true</code>，那么使用hexo命令，则会自行创建这个同名文件夹。</p></li><li><p>不适用于自定义layout以减少重复工作量的情形。（详细参考下面的layout是什么）</p></li></ul><p>使用hexo命令方式创建文档，会自动生成<code>title, date</code>信息。</p><h2 id="layout是什么（进阶内容，可跳过）"><a href="#layout是什么（进阶内容，可跳过）" class="headerlink" title="layout是什么（进阶内容，可跳过）"></a>layout是什么（进阶内容，可跳过）</h2><p>感兴趣且可以科学上网的同学，强烈推荐一个<a href="https://www.youtube.com/watch?v=Jiwbmyc4nCA&amp;list=PLLAZ4kZ9dFpOMJR6D25ishrSedvsguVSm&amp;index=6">YouTube Hexo系列视频</a>。第六集scaffolds和第十二集layout基本就对应本小节内容。</p><p>回到官方文档，会看到<code>hexo new</code>命令有个可选参数叫做<code>[layout]</code>。在文档的下一句说到</p><blockquote><p>您可以在命令中指定文章的布局（layout），默认为 <code>post</code>，可以通过修改 <code>_config.yml</code> 中的 <code>default_layout</code> 参数来指定默认布局。</p></blockquote><p>有的博主会介绍说，布局有三种：<code>post</code>（文章）、<code>draft</code>（草稿）、<code>page</code>（页面）。其实不够准确。如果你愿意，你可以有n多种布局。只不过这三种是hexo以及大多数主题theme已经默认帮你写好的。</p><p><em>那么什么是layout呢？</em></p><p>layout：英文直译是版面设计。也就是说这个命令告诉hexo，该如何排版。不同的排版使用不同的html网页布局，css样式，展示不同的属性。</p><p><em>hexo是如何根据这个layout参数值进行后续操作的呢？</em></p><ul><li><p>首先，每一个markdown文件都有自己的layout。对于没有显示在Front Matter写明layout种类的文件，hexo会自动根据<code>***.github.io/_config.yml</code>中的<code>default_layout:</code>属性值来决定是什么layout，这个值默认为<code>post</code>。也就是说hexo会默认根据post的内容及格式规定对markdown文章进行渲染。</p></li><li><p>一个layout有两个位置的定义来共同决定。</p><ul><li>在<code>***.github.io/scaffolds/</code>文件夹下，和</li></ul></li><li><p>在<code>***.github.io/themes/theme-name/layout/</code>文件夹下。</p></li></ul><h3 id="scaffolds文件夹"><a href="#scaffolds文件夹" class="headerlink" title="scaffolds文件夹"></a>scaffolds文件夹</h3><p>第一个部分<code>scaffolds/</code>文件夹下，主要规定新建markdown文件的内容：Front Matter和正文。</p><p>举例：可以在该文件夹下，创建一个新的md文件，假设叫做<code>selflayout.md</code>，在里面输入</p><pre><code>---title: {{title}}date: {{date}}author: hahahalayout: {{layout}}---Demo: self-defined post content</code></pre><p>  这之后，就可以直接使用hexo命令行操作</p><pre class=" language-bash"><code class="language-bash">hexo new selflayout <span class="token string">"demo"</span></code></pre><p>  在<code>_posts/</code>文件夹下，生成一个名为<code>demo.md</code>layout为selflayout的文件啦。</p><p>  更改<code>scaffolds/</code>下的对应markdown文件，可以大大减少很多重复工作。</p><ul><li>比如你想要创建一个系列博客，共享一些<code>categories, author</code>，你就可以新建一个layout，在Front Matter中添加<code>categories, author</code>的属性值。</li><li>再比如所有的post的作者都是同一个人，叫aa，而你不想在每一篇post的Front Matter中都手动添加<code>author: aa</code>。就可以选择在<code>scaffolds/post.md</code>的Front Matter中添加<code>author: aa</code>。这样，每次使用<code>hexo new file-name</code>都会自动实现这个功能啦。</li></ul><h3 id="theme的layout文件夹"><a href="#theme的layout文件夹" class="headerlink" title="theme的layout文件夹"></a>theme的layout文件夹</h3><p>一个layout的第二部分定义在<code>themes/theme-name/layout/</code>文件夹下。这部分主要规定ejs, css等具体的排版样式。hexo渲染一个页面的先后顺序是，所有的页面都建立在<code>layout.ejs</code>的基础上，然后根据各自的版面进行渲染，</p><ul><li>比如index.html的页面是这么生成的，最外层是<code>layout.ejs</code>，然后将<code>layout.ejs</code>内部的<code>&lt;%- body %&gt;</code>替换为<code>index.ejs</code>的渲染效果。</li><li>再比如一篇博客的html页面是这么生成的，最外层是<code>layout.ejs</code>，然后将<code>layout.ejs</code>内部的<code>&lt;%- body %&gt;</code>替换为<code>post.ejs</code>的渲染效果。</li></ul><p>对应于<code>_posts/</code>文件下的每一个markdown文件，如果Front Matter里</p><ul><li><p>没有指明layout是什么，会默认根据<code>_config.yml</code>里的<code>default_layout: post</code>使用<code>layout.ejs</code> + <code>post.ejs</code>方式进行渲染</p></li><li><p>如果指明了layout是什么（比如我们上面新建了一个叫做<code>selflayout</code>的layout），</p><ul><li>在<code>themes/theme-name/layout/</code>下也存在<code>selflayout.ejs</code>文件，就会使用<code>layout.ejs</code> + <code>selflayout.ejs</code>方式进行渲染</li><li>如果在<code>themes/theme-name/layout/</code>不存在对应的ejs文件，仍会默认使用<code>layout.ejs</code> + <code>post.ejs</code>方式进行渲染。</li></ul></li></ul><p>总结来说，<strong>scaffolds文件夹下，会对内容进行默认设置，而theme的layout文件夹下的ejs文件，则会对排版进行设置。</strong></p><h1 id="文章写作"><a href="#文章写作" class="headerlink" title="文章写作"></a>文章写作</h1><p>对于一般的文字内容排版，只需要按照markdown的写作格式进行写作即可。例如：一级标题，二级标题，emoji输入，加粗斜体等。</p><p>我这里添加几个我常用到的额外的功能：插入本地图片，展示本地pdf，展示数学公式，链接到本站其他blog</p><h2 id="插入本地图片"><a href="#插入本地图片" class="headerlink" title="插入本地图片"></a>插入本地图片</h2><p>这里主要参考这篇文章<a href="https://fuhailin.github.io/Hexo-images/">赵大宝hexo-images</a>，介绍的很详细，我在此基础上稍作补充。在此说明这篇文章里的前四个方法：</p><ul><li><p>绝对路径本地引用，方法：</p><ul><li>将图片存储于<code>source/images</code>文件夹中</li><li>在markdown文件中写<code>![picture description](images/picname.picformat)</code></li></ul></li><li><p>相对路径本地引用，方法：</p><ul><li>将图片存储于<code>_posts/</code>同名文件夹下</li><li>同绝对路径引用，在markdown文件中写<code>![picture description](images/picname.picformat)</code></li></ul></li><li><p>标签插件语法引用，方法：</p><ul><li><p>将图片存储于<code>_posts/</code>同名文件夹下</p></li><li><p>在markdown文件中写<code>{% asset_img image.jpg This is an image %}</code></p></li></ul></li><li><p>HTML语法引用</p><ul><li>将图片存储于<code>_posts/</code>同名文件夹下</li><li>在markdown文件中写<code>&lt;img src="picname.picformat" weight="50%" height="100%" title="picture description" alt="picture alternative description"/&gt;</code></li></ul></li></ul><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>示例以及优劣势比较。以下是我使用这四种方法展示本地图片的效果：</p><ul><li>绝对路径</li></ul><p><img src="/images/BD1.png" alt="绝对路径"></p><ul><li>相对路径</li></ul><p><img src="BD1.png" alt="相对路径"></p><p><img src="BD1_mini.png" alt="相对路径小图"></p><ul><li>标签插件语法引用</li></ul><ul><li>html引用</li></ul><img src="BD1.png" weight="50%" height="50%" title="html引用小图" alt="html引用小图"><img src="BD1.png" height="100%" title="html引用原图" alt="html引用原图"><h3 id="优劣势比较"><a href="#优劣势比较" class="headerlink" title="优劣势比较"></a>优劣势比较</h3><p>根据我的测试结果：</p><ul><li>标签插件语法引用失效。没闹明白为什么。如果有知道的同学，我真诚求教。</li><li>html引用小图失效。我的设置是<code>weight="50%" height="50%"</code>。依旧没弄明白为什么，求教中。</li><li>绝对路径和相对路径在引用效果上没有区别。唯一的区别是文件存储位置，是喜欢图片集中存放，还是每个post建一个文件夹存放，因人而异。</li><li>使用markdown本身的路径引用方式的话，无法在引用时调整图片大小。网页端最终显示的图片大小是图片原本的大小（如果屏幕放得下的话）。想要调整显示页面的图片大小，必须<strong>手动更改图片原本的大小</strong>。比如，我这里相对路径引用的原图和小图，其实对应着两个png文件，一个为原始图片大小为宽1097高537，一个我手动更改为小图，其尺寸为宽500高245。</li><li>使用html引用方式的优势在于，可以在引用时更改大小（？？？原理上是这样，但是我没有成功？？？）；还可以设置图片的替代描述文字（当图片无法正常显示的时候，用以替代图片的文字显示）。</li><li><strong>总体来说：我推荐绝对/相对路径引用方式</strong></li></ul><h2 id="展示本地pdf"><a href="#展示本地pdf" class="headerlink" title="展示本地pdf"></a>展示本地pdf</h2><p>对此网上也有诸多教程，在此参考一篇<a href="https://blog.csdn.net/u010820857/article/details/82356974">csdn博客hexo添加pdf插件</a>，并另外补充一种markdown的文件引用方式。</p><ul><li><p>使用npm插件方式：</p><ul><li><p>安装插件：<code>npm install --save hexo-pdf</code></p></li><li><p>将pdf文件存储于<code>_posts/</code>的同名文件夹下。</p></li><li><p>在markdown文本里输入：</p><pre><code>{% pdf file-name.pdf %} </code></pre></li><li><p>（如果需要引用网上pdf资源，可以直接使用<code>{% pdf http://url-to-pdf/file-name.pdf %} </code>）</p></li></ul></li><li><p>markdown自带的文件引用方式：</p><ul><li><p>将pdf文件存储于<code>_posts/</code>的同名文件夹下。</p></li><li><p>在markdown文本里输入：</p><pre><code>[pdf file description](file-name.pdf)</code></pre></li></ul></li></ul><p>这两种方法都可以使别人获取你的pdf文件，区别在于：</p><ul><li>npm插件方式：会生成内置pdf的小窗口，<strong>读者可以直接阅读到pdf文件内容</strong>。</li><li>markdown自带的方式：会生成一行带有超链接的文字，点击文字，则直接提示下载该文件。这行文字就是种括号里你输入的描述性文字。</li></ul><p>我一般希望别人直接阅读到我的pdf内容，所以推荐npm的插件方式。</p><h2 id="展示数学公式"><a href="#展示数学公式" class="headerlink" title="展示数学公式"></a>展示数学公式</h2><p>参考<a href="https://blog.csdn.net/qq_38496329/article/details/104065659">csdn:hexo博客支持数学公式</a>。</p><ul><li><p>安装npm渲染器：<code>npm install hexo-renderer-kramed --save</code></p></li><li><p>修改<code>***.github.io/_configs.yml</code>配置文件中</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">mathjax</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span></code></pre></li><li><p>在markdown文件的Front Matter加入<code>mathjax: true</code></p></li><li><p>按照markdown语法，在需要添加数学公式的地方，直接按照markdown语法使用<code>$ formula $</code>添加行内公式或者<code>$$ formula $$</code>添加整行公式。</p></li></ul><h2 id="链接到本站其他blog"><a href="#链接到本站其他blog" class="headerlink" title="链接到本站其他blog"></a>链接到本站其他blog</h2><p>如何在当前的blog里引用本站其他的blog呢？</p><p>本质上就是直接使用markdown的文件链接方式：</p><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>file description<span class="token punctuation">]</span><span class="token punctuation">(</span>file path<span class="token punctuation">)</span></code></pre><p>唯一不同的就是这里的file path，不是指要被引用的markdown文件在<code>_posts</code>文件夹的位置，而是<strong>经hexo渲染后生成的html文件的位置</strong>。</p><p>举例来说，我这里想引用另一篇介绍hexo的blog，它的原始文件叫做<code>source/_posts/Hexo1.md</code>，经hexo渲染后的文件存储为<code>public/hexo1/index.html</code>。</p><p>而我当前的文件叫做<code>source/_posts/Hexo2.md</code>，经hexo渲染后的文件存储为<code>public/hexo2/index.html</code>。</p><p>如果习惯于markdown文件的书写，可能会直接在本文件里写</p><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>Hexo1<span class="token punctuation">]</span><span class="token punctuation">(</span>Hexo1.md<span class="token punctuation">)</span></code></pre><p>正确的写法应该是，</p><pre class=" language-bash"><code class="language-bash"><span class="token punctuation">[</span>Hexo1<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">..</span>/hexo1/index.html<span class="token punctuation">)</span></code></pre><p>这是因为hexo在渲染的时候，并不会更改<code>()</code>中的内容。如果按照第一种写法，实际上会在<code>public/hexo2/</code>文件夹下寻找名为<code>Hexo1.md</code>的文件，并不存在。按照第二种写法，则是先去到父目录<code>public/</code>然后找到<code>hexo1/index.html</code>。</p><p><a href="../hexo1/index.html">Hexo1</a></p><p>当然，有的小伙伴的blog是用时间来生成路径的，比如<code>public/2019/07/02/hexo2/index.html</code>，同理寻找到正确的路径即可。至于如何控制hexo使用时间还是文章标题来命名，在<code>_config.yml</code>文件里有一个属性叫做<code>permalink: </code>，我这里设置为<code>:title/</code>，即按照blog标题生成链接路径。</p><h2 id="草稿"><a href="#草稿" class="headerlink" title="草稿"></a>草稿</h2><p>此外，可以在<code>source/drafts/</code>文件夹下，创建markdown文件，写草稿。在这些文档里，正常写作即可，但它们不会被渲染，也就不会显示在最终的博客页面里。</p><h1 id="发布文章"><a href="#发布文章" class="headerlink" title="发布文章"></a>发布文章</h1><p>先列举一些常用的命令</p><ul><li><p>Clean: <code>hexo clean</code>。该命令会删除整个<code>***.github.io/public/</code>文件夹</p></li><li><p>Generate: <code>hexo generate</code>或者简写为<code>hexo g</code>。该命令会生成静态文件夹<code>public/</code>，也就是从markdown到网页文件html等的转换操作</p></li><li><p>Server: 启动服务器常用的是<code>hexo server</code>或者简写为<code>hexo s</code>。</p><ul><li>若需指定端口号则为<code>hexo server -p 5000</code>5000可以更改为其他端口号。</li></ul><p>该命令会把生成好的静态文件部署到本地的指定端口，之后即可在本地浏览器输入<code>localhost:4000</code>即可预览。若指定了端口号，则把4000改为你指定的端口，如上个示例中的<code>localhost:5000</code></p></li><li><p>deploy：<code>hexo deploy</code>或者简写为<code>hexo d</code>。该命令将网站部署到服务器上。实际操作是：更新你在github上的仓库<code>***.github.io</code>的指定分支（如果你采用Hexo系列第一节说到的两分支方式的话）。这是你最终发表的博客页面，你可以在浏览器上访问<code>https://***.github.io</code>来查看更新后的博客啦。</p></li></ul><p>接着，给出一些命令使用的常见套路</p><ul><li><code>hexo clean</code>这个命令其实很少用。使用情况常见于：更新了<code>_config.yml</code>文件夹，删除了一些已有博文等。原因就是速度慢，耗费不必要的时间。毕竟它会将整个<code>public/</code>文件夹删除，再重新生成。推荐偶尔清理使用即可。</li><li>通常更新一次博客的套路是先本地预览，再远程部署。即先执行<ul><li><code>hexo g; hexo s</code>，再执行</li><li><code>hexo d</code>或者<code>hexo g; hexo d</code></li></ul></li><li>hexo有个特别便利的地方！<ul><li><p>在本地预览时，你仍可以更改markdown文件中一般的文字内容，然后直接在浏览器端刷新页面，就能看到实时更改的效果，而不需要再执行一次<code>hexo g;hexo s</code>，节省很多时间。常用于预览过程中进行微调操作。我的测试表明，此时更改文章的<code>categories, tags</code>等Front-Matter的属性的话，也可以动态刷新，很神奇。</p></li><li><p>但是，有些涉及到更深层次的操作，比如利用到themes文件里的js函数，css样式，文件链接等，可能无法实时更新。此时仍需要重新generate才可以预览最新效果。同理，如果你更改了themes文件夹下面的css文件, ejs文件, yml文件等，通常也需要重新渲染。</p></li><li><p>注意：在执行<code>hexo s</code>之后，想要中断操作，使用的是<code>control + C</code>快捷键。我老会习惯性地使用<code>con trol + Z</code>的快捷键。此时，可能出现端口被占用的错误。解决办法是：1. 找到被占用端口4000的进程号pid，2. kill掉这个进程。</p><pre><code>lsof -i:4000kill -9 pid</code></pre></li></ul></li><li>如果你采用两个分支的git部署方式。使用<code>hexo d</code>只是更新了其中的一个分支，此时仍需要进行常规的git仓库更新操作<code>git add ... git commit ... git push</code>这一系列来更新另一分支。</li></ul><p>总结来说，最常用的套路就是</p><ol><li><code>hexo g; hexo s</code>本地预览，再更改，直到满意为止</li><li><code>hexo d</code>或者<code>hexo g; hexo d</code>远程部署。</li></ol><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><ol><li><a href="https://hexo.io/zh-cn/docs/writing.html">hexo官方文档</a></li><li><a href="https://zhuanlan.zhihu.com/p/156915260">知乎Hexo博客写文章及基本操作</a></li><li><a href="https://hexo.io/zh-cn/docs/front-matter">Front-Matter official manual</a></li><li><a href="https://www.youtube.com/watch?v=Jiwbmyc4nCA&amp;list=PLLAZ4kZ9dFpOMJR6D25ishrSedvsguVSm&amp;index=6">YouTube Hexo系列视频</a></li><li><a href="https://fuhailin.github.io/Hexo-images/">赵大宝hexo-images</a></li><li><a href="https://blog.csdn.net/u010820857/article/details/82356974">csdn博客hexo添加pdf插件</a></li><li><a href="https://blog.csdn.net/qq_38496329/article/details/104065659">csdn:hexo博客支持数学公式</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Sharing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Simplicial neural network思路梳理</title>
      <link href="/simplicial-neural-network-si-lu-shu-li/"/>
      <url>/simplicial-neural-network-si-lu-shu-li/</url>
      
        <content type="html"><![CDATA[<p>我在准备master thesis的时候，第一个选题是希望利用simplicial complex结合GNN在hypergraph领域做些理论突破。现回顾梳理在GNN中使用simplicial相关理论的研究思路和代表性工作。</p><p>本文按照“明确问题——理论方案——实践”结构展开：</p><ul><li>明确问题：传统的图结构有什么不足，什么是高阶图？</li><li>理论方案：<ul><li>在高阶图上的解决思路有哪些？</li><li>用通俗的语言介绍simplicial complex理论</li><li>其他可能的方案：subgraph</li></ul></li><li>实践：简要介绍simplicial complex与neural network结合的代表性研究者/工作</li></ul><h1 id="问题：高阶图"><a href="#问题：高阶图" class="headerlink" title="问题：高阶图"></a>问题：高阶图</h1><p>GNN是当红的在图结构上进行深度学习的工具，而simplicial complex的引用主要是为了解决<strong>高阶图</strong>上的深度学习问题。</p><p>传统的Graph（图）是由点和边组成的结构。“一条边连接两个端点”，这就局限了传统的图只能直接捕捉<strong>pairwise relationship</strong>（成对的关系）。举例来说，假设A，B，C是一个学校社交图中的三名学生（看成该图中的三个点），我们把边定义为“好朋友”关系。</p><ul><li><p>我们可以很容易地刻画A和B是好朋友，在A点和B点间连一条边即可，这就是pairwise relationship，涉及两个人。</p></li><li><p>但是如果我们想描述A，B和C是一个好朋友团体，他们仨总是玩在一起，那该怎么表示？此时的关系涉及三个人，超过了pairwise，有的文章里将其称之为<strong>higher-order relationship（高阶的关系）</strong>。</p><p>利用传统的点-边图结构，会有这么种表示方法，一共连三条边，A和B之间一条，B和C之间一条，A和C之间一条。但其实，这种方法并不能很准确地表示“他们仨这个小团体”，也可以被诠释为，A和B，B和C，A和C互为好朋友，然而A和B在上午玩在一起，B和C在下午玩在一起，A和C却在晚上玩在一起。当然，在这种传统图结构上，人们也想出各种其他的方法来描述这种higher-order relationship，比如引入不同类型的点，引入“好朋友”类型的点，A，B和C三个“人”类型的点（可以用圆形点表示），都和一个“好朋友”类型的点（可以用正方形的点表示）相连，就能表示三个人的团体关系了。（例子可以类比于图1中的A图）这里不过多赘述。</p></li></ul><p>这里我们清楚了了要解决的问题：<em>是希望在包含<strong>higher-order  relationship高阶图（又叫hypergraph）</strong>上搭建神经网络模型</em>。超越成对关系的高阶图其实相当普遍，比如社交网络中的‘群组“概念，生态系统中物种之间的互动关系，化学反应中的多种物质共同作用等。对高阶图感兴趣的读者可以参考一篇综述<a href="https://arxiv.org/abs/2006.01764">1. Networks beyond pairwise interactions: structure and dynamics</a>。</p><p><img src="affiliations.png" alt="图1：Pairwise representation VS Hyperedge representation。图片来自于Networks beyond pairwise interactions: structure and dynamics"></p><h1 id="理论方案"><a href="#理论方案" class="headerlink" title="理论方案"></a>理论方案</h1><p>那么要如何解决这个问题呢？既然问题的根源出在“点-边”这种传统的图结构上，就必须寻求一种新的结构来刻画高阶关系。这里介绍两种具有代表性的新结构：1. hyperedge和2. simplicial complex。也有学者从subgraph的角度切入做研究，我表示好奇，还在观察中。</p><h2 id="Hyperedge（超边）"><a href="#Hyperedge（超边）" class="headerlink" title="Hyperedge（超边）"></a>Hyperedge（超边）</h2><p><strong>Hyperedge（超边）</strong>这种想法非常直观。传统图的限制在哪儿，在边，因为一条边只能有两个端点。Ok，那就打破这种限制，让一条边可以有三个甚至更多的端点，问题不就解决了吗？这样的边就叫做<strong>hyperedge（超边）</strong>。比如我们想表示Sarah, Ross, Allison都去了Party1这件事，我们就构造一条超边叫做Party1，它包含了三个点Sarah, Ross, Allison。形象的表示出来例如图1中的B，其中黄色的圈就是Party1这条超边，它圈住了三个点sarah, Ross和Allison。</p><p>还可以从集合论的角度来理解超边。在传统的无向图定义中，将一条边规定为包含两个点的集合，那么超边就可以定义为不限数量的点的集合。</p><p>已有一批学者尝试将超边的概念和GNN结合起来，代表工作有：</p><p><a href="https://arxiv.org/abs/1809.09401">2. HGNN: Hypergraph neural networks</a></p><p><a href="https://papers.nips.cc/paper/2019/hash/1efa39bcaec6f3900149160693694536-Abstract.html">3. HyperGCN</a></p><p><a href="https://dl.acm.org/doi/10.1145/3340531.3411870">4. NHP</a></p><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320320304404?via=ihub">5. Hypergraph Convolution and Hypergraph Attention</a></p><p>这些工作的思路主要是沿着图神经网络里的<strong>基于谱方法的图卷积</strong>（网上很多资源介绍，可参考<a href="https://zhuanlan.zhihu.com/p/78466344">知乎：从源头探讨GCN的行文思路</a>）分支走，尝试定义Hypergraph上的Laplacian矩阵，进而定义图卷积。</p><h2 id="Simplicial-complex"><a href="#Simplicial-complex" class="headerlink" title="Simplicial complex"></a>Simplicial complex</h2><p>另一种理论解决方案呢，则是寻求在数学上已经进行相当长时间的研究，且和我们的问题非常契合的理论工具：<a href="https://encyclopediaofmath.org/index.php?title=Simplicial_complex">simplicial complex</a>。</p><p>什么是simplicial complex？</p><p>一句话从集合的角度来描述simplicial complex，就是，首先有一个集合，集合里的每个元素叫做vertices（点），这个集合中<em>满足一定性质的</em>子集就叫做simplex。这里一定的性质，是子集封闭，也就是一个simplex的任何一个子集都得是一个simplex，最基本的，一个点是一个simplex。如果你把边看做是包含两个点的子集，那么边就是一种simplex。接着便很容易拓展到包含更多元素的simplex。图2的第一行就展示了什么是simplex，</p><ul><li>左上角的是边，也就是包含两个点的1-simplex。每一个点都是一个0-simplex</li><li>中间是包含三个点的2-simplex，其中每一条边都是一个1-simplex。</li><li>右边是包含四个点的3-simplex，<ul><li>它有四个包含3个点的子集，每一个子集都是一个2-simplex。</li><li>有6个包含2个点的子集（边），每一个子集都是一个1-simplex</li><li>有4个包含1个点的子集（也就是一个点），每一个子集都是一个0-simplex</li></ul></li></ul><p>第二行是hyperedge与simplex表示的对比。</p><p><img src="simplex.png" alt="图2:What is simplex?图片来自于Networks beyond pairwise interactions: structure and dynamics"></p><p>这个理论工具乍看很复杂，为什么要使用它呢？</p><p>我的理解是，一是hodge laplacian不局限于信号在点与点之间的传播，可以拓展到边与边之间，三角形与三角形之间等等，二是simplicial complex的理论研究成果丰富，应用起来有理论上的保障，能进行有良好定义的数学运算，其中的<strong>Hodge Laplacian</strong>是graph Laplacian的高阶拓展，而这也正是我们需要的。simplicial complex及hodge laplacian的理论涉及到很多数学知识，可能比较劝退。这里贴出两个偏科普类型的资源，较浅显易懂，感兴趣的小伙伴可以看看。</p><ul><li><p><a href="https://www.youtube.com/watch?v=rlI1KOo1gp4">YouTube: Simplicial Complexes</a></p></li><li><p>:+1: <a href="https://www.stat.uchicago.edu/~lekheng/work/psapm.pdf">Hodge Laplacian on Graphs</a>（虽然很数学，但讲得尽可能浅显）</p></li></ul><h3 id="Hodge-Laplacian"><a href="#Hodge-Laplacian" class="headerlink" title="Hodge Laplacian"></a>Hodge Laplacian</h3><p>将simplicial complex应用于高阶图的<strong>关键点就在于Hodge Laplacian</strong>。这里对Hodge Laplacian背后的intuition做介绍，尽量少地涉及公式。</p><p><a href="https://zhuanlan.zhihu.com/p/350259325">图拉普拉斯矩阵</a></p><p><em>首先，Laplacian是什么？</em></p><p>教科书上的定义是：Laplacian是梯度的散度the divergence of the gradient of a function。重点，它是一种<strong>散度divergence</strong>。<strong>散度</strong>这个中文看起来可能会比较陌生，想想它的英文<strong>divergence</strong>, diverge分散，会更容易理解。考虑某种属性（对应到数学语言，就是某个函数），如果一个点倾向于把该属性分散出去，这个点的散度就是positive正的，否则就是负的。这里有个视频<a href="https://www.youtube.com/watch?v=rB83DpBJQsE&amp;t=341s">YouTube: divergence and curl</a>很形象地描述了散度是什么。Laplacian是什么的散度，它是梯度的散度。梯度又是什么？是Gradient，倾斜度，变化度，表明了一种向周围变化的方向和大小。想象河里的水流，河里某一个点上的梯度就是说，此刻这个点上的水会向哪个方向，以多快的速度进行流动。那么散度，就是把这个点周围很小的范围内的所有的水流都考虑进来，看看这个点到底是个源头（向周围增加水流）还是个sink（吸收周围的水流），又或是块平地（流进的水流和流出的水流一样多）。再推荐一个视频<a href="https://www.youtube.com/watch?v=EW08rD-GFh0&amp;list=RDCMUC4a-Gbdw7vOaccHmFo40b9g&amp;start_radio=1&amp;rv=EW08rD-GFh0&amp;t=297">YouTube: Laplacian</a>简要介绍了Laplacian。</p><p>一句话总结，Laplacian是一种散度算子，描述一个点上的某种属性（对应到函数f）向周围邻居的分散程度。</p><p><em>那么，什么是Graph Laplacian？</em></p><p>类比过来，这是针对<strong>图上的点</strong>刻画某种属性（对应到函数f）分散程度divergence的一种算子operator。这篇文章<a href="https://zhuanlan.zhihu.com/p/368878987">知乎：GNN入门之路</a>给出了详细的公式和推导。这里的intuition有以下要素：</p><ul><li>针对图上的点</li><li>某种属性</li><li>分散程度</li><li>一种算子</li></ul><p>举个例子就很好理解了。假如有一个图，图上有5个点，代表5个幼儿园的小朋友。某种属性是：我给各个小朋友不同数量的巧克力。我的巧克力分配方式就可以看做一个函数，输入一个小朋友，经过我的一番思考，输出一个数字。分散程度，代表了巧克力的分散程度，也就是任给一个小朋友，他手里的巧克力是可能被同伴抢走还是他从同伴手里抢来更多的巧克力。一种算子，就是输入一个小朋友，计算这种分散程度的大小。</p><p>假如这五个小朋友叫A, B, C, D, E，我分别给他们1，2，3，4，5颗巧克力。他们不知道别人有多少巧克力，只有和对方见面后（给图上的点之间连边），才知道别人的巧克力数量。如果一个小朋友的巧克力少于对方的巧克力，他就会倾向于抢走对方的巧克力，反之，对方就会想要抢走他的巧克力。这种抢走的意愿程度和巧克力的数量差成正比。</p><p>现假设AB，AC，AE，BE，CD和DE见过面。那么A的巧克力分散程度就是(1-2) + (1-3) + (1-5)=-7，同理B是(2-1)+(2-5) = -2, C是(3-1)+(3-4)=1，D是(4-3)+(4-5)=0，E是(5-1)+(5-4)=5。简言之，E的巧克力更可能分散，A更可能聚集巧克力。</p><p>这里的计算思路就是站在每一个点的立场上，计算它的属性值和所有的邻居的属性值之间的差异。这就是Graph Laplacian的意义。数学推导后的公式就是$L = D- A$，L是Laplacian矩阵，D是度对角矩阵，A是邻接矩阵。更进一步，对L进行正则化normalize，就和上述“梯度的散度”的数学公式如出一辙了。（graph里的求和和连续的Laplacian里的求导，都可以看成是聚合信息的一种方式。对L进行normalize之后，求和和求导就更类似了。）</p><p>为了顺利过渡到Hodge Laplacian，现在从关系矩阵incidence matrix的角度来理解$L$。</p><p>关于图Laplacian有个性质是$L = BB^\top = D-A$，这里的$B\in V\times E$是incidence matrix。它的数学定义是：刻画点和边的关系，为边定义了方向，从出发节点到到达节点。行是节点，列是边；项是0，1或-1。一条边的出发节点为1，到达节点为-1。（有的地方也用转置了的定义，差别不大）</p><p>我不展开数学公式推理，而是从直观的角度理解$LX=BB^\top X$，还是拿上面小朋友中的A举例，原来的计算方式是A直接看到B，C和E手里有多少巧克力，而现在相当于引入了一个中介：边。A不是直接看到B，而是看到他和B之间有一条边AB，他告诉了AB他手里有多少巧克力。同样的，A告诉了所有他看到的边AC和AE。第一轮是所有点告诉所有与之相连的中介（边），然后每条边都有了自己的汇总信息$B^\top X$。第二轮是所有的边再把汇总后的信息转达给与之相连的点$B(B^\top X)$，比如A又从AB, AC和AE这三条边上获取汇总后的信息，计算出他的分散程度。</p><p>至于为什么incidence matrix里要为边定义方向，你可以理解为是一个边对它的两个点的不同“暗号”（编解码方式）。拿一条边AC举例，这条边分别从A和C处收集信息知道A有1个巧克力，C有3个巧克力，AC这条边关注的是差值。假如A对应的是1，C对应的是-1，那么AC汇总后的信息就是1-3=-2。对于这个-2，点A和点C也要以不同的方式来解读，点A用$1*(-2)=-2$，得到它的分散程度是负的，点C则用它的$-1*(-2)=2$，得到正的分散程度。这就是预先规定方向的必要性。</p><p><em>从Graph Laplacian到Hodge Laplacian</em></p><p>先给出Hodge Laplacian的数学定义<br>$$<br>L_0 = B_1B_1^\top<br>$$</p><p>$$<br>L_k = B_k^\top B_k + B_{k+1}B_{k+1}^\top, k = 1,\cdots, K-1<br>$$</p><p>$$<br>L_K = B_K^\top B_K<br>$$</p><p>这里的$L_k$表示不同度数的simplex对应的Laplacian矩阵，比如$L_0$对应0-simplex（点）也就是传统的Graph Laplacian，$L_1$对应以1-simplex（边）为对象的Laplacian。</p><p>$B_k$代表$k$-simplex和$k-1$-simplex之间的incidence matrix。</p><p>重点介绍如何理解$L_1$，其他度数的simplex很容易类推。</p><p>依然坚持Laplacian的理解要点“一个点的某种属性向周围邻居的分散程度”。这里的“点”，不再局限于图中的点vertices，而是拓展为一个对象unit，比如在超图中，$L_1$表示我们将从边的角度，关注信号是如何在边之间传播的，那这里的unit就是边，而不是vertices。</p><p>第二个要点是“中介”的思想。站在边1-simplex的角度上，信号在边与边之间传播，需要哪些中介呢？答案是点0-simplex和三角形2-simplex。</p><p>正如信号在点与点之间传播，其实是借助点和点之间相连的边来实现的，点0-simplex和三角形2-simplex是边们1-simplex之间相互连接的方式。一个点在所有以它为端点的边之间建立起了联系，一个三角形2-simplex包含三条边，这三条边之间也因为这个三角形建立起了关系。</p><ul><li>边通过点之间进行信号传播，又被定义为$L^{down}=B_k^\top B_k$</li><li>边通过三角形之间进行信号传播，又被定义为$L^{up}=B_{k+1} B_{k+1}^\top$</li></ul><p>综上，就是hodge laplacian在边上的定义$L_1$。以此拓展出去，可以得到信号在三角形之间传播的laplacian等等。</p><h1 id="Simplicial-complex的工作实践"><a href="#Simplicial-complex的工作实践" class="headerlink" title="Simplicial complex的工作实践"></a>Simplicial complex的工作实践</h1><p>目前在超图领域，simplicial cimplex主要被用于解决以下问题：预测点、边、三角形上的缺失信号，特别是流（边）上的信号。</p><p>代表论文有：</p><ul><li><a href="http://arxiv.org/abs/2010.03633">simplicial neural networks</a></li><li><a href="http://arxiv.org/abs/1912.02354">HodgeNet: Graph Neural Networks for Edge Data</a></li><li><a href="http://arxiv.org/abs/1807.05044">Random Walks on Simplicial Complexes and the normalized Hodge 1-Laplacian</a></li><li><a href="http://arxiv.org/abs/1802.06916">Simplicial Closure and higher-order link prediction</a></li><li><a href="https://ieeexplore.ieee.org/document/9244649">Topological Signal Processing: Making Sense of Data Building on Multiway Relations</a></li></ul><p>我在thesis的准备阶段探索体会是，simplicial complex虽然有很好的理论基础，但仍有相当多的局限性：</p><ul><li>目前为止，缺少良好定义的任务和数据集</li><li>从理论上讲，simplicial complex：<ul><li>对数据的“整齐度”要求很大，考察对象为同类型的simplex间的信号传播，比如0-simplex之间，1-simplex之间，2-simplex之间。而这么整齐的数据局限在特定领域中。像社交网络中的群组常常拥有不同的规模。</li><li>当k很大时，数据量太大。由于simplicial complex对任一子集的封闭要求，假如考察10-simplex之间的信号传播，每一个10-simplex都要求它的$\binom {11} {2}=55$个1-simplex，$\binom {11} {4}=330$个3-simplex必须存在。这在计算量的角度很不友好。</li></ul></li></ul><p>这个领域比较小众。以上分享均为个人见解，欢迎提出讨论和批评指正。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><strong>Networks beyond pairwise interactions: Structure and dynamics</strong>, <em>Battiston, Federico and Cencetti, Giulia and Iacopini, Iacopo and Latora, Vito and Lucas, Maxime and Patania, Alice and Young, Jean-Gabriel and Petri, Giovanni</em>, 2020</li><li><strong>Hypergraph Neural Networks</strong>, <em>Yifan Feng, Haoxuan You, Zizhao Zhang, Rongrong Ji, Yue Gao</em>, 2019</li><li><strong>HyperGCN: A New Method For Training Graph Convolutional Networks on Hypergraphs</strong>, <em>Naganand Yadati, Madhav Nimishakavi, Prateek Yadav, Vikram Nitin, Anand Louis, Partha Talukdar,</em> NIPS2019</li><li><strong>NHP: Neural Hypergraph Link Prediction</strong>, <em>Yadati, Naganand and Nitin, Vikram and Nimishakavi, Madhav and Yadav, Prateek and Louis, Anand and Talukdar, Partha,</em> CIKM2020</li><li><strong>Hypergraph convolution and hypergraph attention</strong>,  <em>Song Bai, Feihu Zhang , Philip H. S. Torr,</em> 2019</li><li><a href="https://zhuanlan.zhihu.com/p/78466344">知乎：从源头探讨GCN的行文思路</a></li><li><a href="https://encyclopediaofmath.org/index.php?title=Simplicial_complex">Encyclopedia: simplicial complex</a></li><li><a href="https://www.youtube.com/watch?v=rlI1KOo1gp4">YouTube: Simplicial Complexes</a></li><li><strong>Hodge Laplacian on Graphs,</strong> <em>Lek-Heng Lim</em>, 2019</li><li><a href="https://zhuanlan.zhihu.com/p/350259325">知乎：图拉普拉斯矩阵</a></li><li><a href="https://www.youtube.com/watch?v=rB83DpBJQsE&amp;t=341s">YouTube: divergence and curl</a></li><li><a href="https://www.youtube.com/watch?v=EW08rD-GFh0&amp;list=RDCMUC4a-Gbdw7vOaccHmFo40b9g&amp;start_radio=1&amp;rv=EW08rD-GFh0&amp;t=297">YouTube: Laplacian</a></li><li><a href="https://zhuanlan.zhihu.com/p/368878987">知乎：GNN入门之路</a></li><li><strong>Simplicial Neural Networks,</strong>  <em>Stefania Ebli and Michael Defferrard, Gard Spreemann</em>. CoRR 2020.</li><li><strong>HodgeNet: Graph Neural Networks for Edge Data,</strong> <em>T. Mitchell Roddenberry and Santiago Segarra,</em> 2019</li><li><strong>Random Walks on Simplicial Complexes and the normalized Hodge 1-Laplacian,</strong>  <em>Michael T. Schaub, Austin R. Benson, Paul Horn , Gabor Lippner and  Ali Jadbabaie</em>, CoRR2018</li><li><strong>Simplicial Closure and higher-order link prediction,</strong> <em>Austin R. Benson, Rediet Abebe, Michael T. Schaub, Ali Jadbabaie, Jon Kleinberg,</em> CoRR2018</li><li><strong>Topological Signal Processing: Making Sense of Data Building on Multiway Relations,</strong> <em>Barbarossa, Sergio and Sardellitti, Stefania,</em> IEEE2020</li></ol>]]></content>
      
      
      <categories>
          
          <category> Sharing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN </tag>
            
            <tag> High-order graph </tag>
            
            <tag> Simplicial complex </tag>
            
            <tag> thesis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>花花西陆·序</title>
      <link href="/hua-hua-xi-lu-xu/"/>
      <url>/hua-hua-xi-lu-xu/</url>
      
        <content type="html"><![CDATA[<p>从欧洲回国已将近一个月了。我仍不时念起过去三年里，在瑞士和其他欧洲国家的点点滴滴。如今退一步，以一种更宏观的视角细品这些日子，竟咂摸出些新的滋味，关于自己关于社会，对历史对未来。突然，脑中蹦出一个大胆的念头，“记录我在欧洲的点滴经历和体验”，与你共享。这个西陆尽头的花花世界，已有无数文化名人为其倾墨，留下了诸多脍炙人口的名篇。其主题深度和文笔功夫都是我无法企及的。在此，我想以一名留学生的视角，记述我在欧洲的真实经历和观念上的成长。一步步踩过的路，铺就了内心探途。</p><p>18年的9月，我生平第一次踏上亚欧大陆的西部。对于欧洲，二十几年来，常闻其名，未见其“人”。我怀揣初恋般的期待和幻想，开启了一段独一无二的生活冒险。和所有闯入异乡的人一样，我经历着新鲜、探寻、融合与比较。新鲜，为蓦然现于眼前的一座座史书中的城市，为奶香中夹带咸腥的芝士和丝滑却酸苦的巧克力，为硬邦邦的德语高贵的法语和重音分明节奏欢快的意大利语。顺着这些画面味道声音的线索，我开始探寻当地人的生活模式。许许多多的小细节向我揭示出这个模式的构成元素，譬如一个庞大却严格踩点的交通系统，譬如近乎强迫症式的垃圾分类与回收，譬如欧洲杯期间，酒吧里直播的大电视和聚在一起喝酒欢呼的老老少少。我拿起一个个片段，像拼拼图一样，慢慢拼凑出我眼中的这片土地，和土地上的人们。我不满足于远观，而要去走近、走进，把这些元素融入自己的生活，把辉煌跌宕的历史传说融入我看到的当下。于是，我在每次购物时说danke schön，在寒冷的冬天吃芝士火锅，在阿尔卑斯山的脊背上行走歌唱，在一座座教堂里用指尖去触碰虔诚的信仰。新冠疫情期间，中西方经历了一场多角度的比较。我在不同的高峰期分别生活在这两片土地上，亲身感受了大家不同的抗疫态度和方式，而其背后的价值观念和文化思想更是值得玩味。</p><p>三年的时间里，我贪婪地把自己沉浸在这片花花西陆。走过了一些路，仍有更多的未知要探索；从当今人们的生活风貌里，瞥见了漫漫历史的影子；在出走异乡的同时，也在探索自己的内心探索中国的厚重。</p><p>在此奉上些许见闻札记，望共享。</p>]]></content>
      
      
      <categories>
          
          <category> Literature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Travel </tag>
            
            <tag> Europe </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读书：如何阅读一本书</title>
      <link href="/du-shu-ru-he-yue-du-yi-ben-shu/"/>
      <url>/du-shu-ru-he-yue-du-yi-ben-shu/</url>
      
        <content type="html"><![CDATA[<p>如何阅读一本书</p><p>作者：【美】Mortimer J. Adler, Charles Wright Mills</p><p><img src="%E5%A6%82%E4%BD%95%E8%AF%BB%E4%B9%A6.png" alt="如何阅读一本书"></p><p>一句话总结：这本书主要论述了什么是阅读，以及有效阅读的方法。</p><p>作者将阅读方法由基础到深入总结为四类：基础阅读，检视阅读，分析阅读和主题阅读，涵盖内容从字句的理解，到文章概览，到分析整本书和比较理解同一主题下的多本书。</p><p>作为一本<strong>实用性的书</strong>，作者针对每种不同的阅读类型提供了一系列可操作性的方法。此外，还针对不同类型的书籍，详细给出阅读指导意见。这一部分可用作工具书，在以后需要时进行参考。</p><p>这本书与我有什么关系？对我的阅读观念和习惯起到了很大的改善。譬如，本次的读书总结就直接利用了书中所说的方法，一句话总结全书内容和回答与我有什么关系。可以使我更有效率更有章法地选书和读书，且不必落入生硬读书的“书呆子”里。书中所讲的条条框框不必严格一一执行，更多地应内化为指导思想。</p><h1 id="有意思的观点"><a href="#有意思的观点" class="headerlink" title="有意思的观点"></a>有意思的观点</h1><p>“沟通”（communication）这个字，字根来自“共通”（common）。我们谈一个社群（community），就是一群有共通性的人。而沟通是一个人努力想要跟别人（也可能是动物或机器）分享他的知识、判断与情绪。</p><p>一本书之所以能给你带来新的洞察力或启发，就是因为其中有一些你不能一读即懂的字句。</p><p>阅读的一部分本质就是被困惑，而且知道自己被困惑。</p><p>受教通常与卑躬屈膝混为一谈。一个人如果被动又顺从，可能就会被误解为他是受教的人。相反的，受教或是能学习是一种极为主动的美德。一个人如果不能自动自发地运用独立的判断力，他根本就不可能学习到任何东西。或许他可以受训练，却不能受教。因此，最能学习的读者，也就是最能批评的读者。</p><p>放入两张总结图。</p><p>第一张来自于xmind官网，属简要概括型笔记。</p><p><img src="%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E6%9C%AC%E4%B9%A6.png" alt="如何阅读一本书大纲导图"></p><p>第二张来自于我的读书摘抄。是大纲加内容摘抄。</p><p><img src="%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E6%9C%AC%E4%B9%A6%E6%88%91.png" alt="如何阅读一本书大纲笔记（我）"></p>]]></content>
      
      
      <categories>
          
          <category> Reading Summary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Book </tag>
            
            <tag> Tips </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在ETH Zurich就读体验</title>
      <link href="/zai-eth-zurich-jiu-du-ti-yan/"/>
      <url>/zai-eth-zurich-jiu-du-ti-yan/</url>
      
        <content type="html"><![CDATA[<p>答主刚刚从ETH毕业回国，拿到了Data Science Master的学位。在写这篇分享之前，我仔细拜读了前辈们的回答，十分详尽，内容涵盖从本科到博士博后，大力推荐。在此，我以Master的视角来分享，特别是分享些有关Data Science Master的学习生活体验，希望能为有意愿来ETH就读的学弟学妹们提供参考，也为ETH吸引更多中国小伙伴。本篇分享主要包括：</p><ul><li>学校介绍和专业录取</li><li>专业学习情况</li><li>学校活动</li><li>生活文化体验</li><li>毕业后就业</li></ul><h1 id="学校介绍和专业录取"><a href="#学校介绍和专业录取" class="headerlink" title="学校介绍和专业录取"></a>学校介绍和专业录取</h1><p>ETH Zurich是一所位于瑞士德语区，汇聚了欧洲甚至世界大量顶尖人才的理工学院，众人皆知的爱因斯坦，中学毕业之后，就是来ETH读的书。现在，在学校食堂，咖啡馆等场所还能看到各种画着爱因斯坦的海报，各种校园活动也很喜欢用爱因斯坦做“代言人”，把他画在宣传贴画上。在近几年的QS全球大学排行榜上，ETH Zurich不论是整体排名还是CS专业排名都位于全球前10。教学质量和资源在整个欧洲都是数一数二的，我的专业同学大部分来自于欧洲的各个国家，对ETH的认可度和仰慕度非常高。</p><h2 id="专业录取"><a href="#专业录取" class="headerlink" title="专业录取"></a>专业录取</h2><p>我就读的Data Science Master专业，是一个比较新的硕士项目，于2017年才招收第一届学生，我有幸在18年被录取入学。这个专业是由D-INFK（计算机院），D-MATH（数学学院）和D-ITEE（对应到国内的EE？）联合开设的，主要还是归属于D-INFK下，专业的行政人员、管理人员、学生会组织都在D-INFK下，和ETH的CS硕士项目像亲兄弟。普遍来说，ETH的master项目是教学类型的，项目学分大部分都需要通过上课考试获得。在完成学习任务之余，也可参与研究工作，去实验室当个助理或者选一门semester project/research project做科研项目等。</p><p>Data Science Master项目可能因为比较新，招生规模比较小。17年第一届的招生规模是二十多人，我们第二届的人数略有增加，三十人，19届20届规模继续扩大。中国学生人数也在稳步增长，最开始只有两三人，现在已经有十几个了？相比之下，兄弟项目CS同期的招生规模都在百人以上，队伍明显壮大很多。</p><p>ETH master项目录取的整体风格都很看重专业匹配度，这一点在申请时填写长长的已修课程介绍列表就能体现出来。如果专业先修要求这一部分不达标，基本上就很难通过申请。所以，在申请各个项目前一定要仔细阅读先修要求。只有少数几门先修课没上过的话，学校会在录取后，给你开一个补课列表，需要你开学后自行参加这些课程，不计算在项目学分内。在我们这一届的录取学生中，大家的本科背景主要是三个专业：CS，数学和Engineering，很多人还有另一个专业的辅修或双学位背景。所有生源中，亚洲人有几个，来自ETH本校的本科生也有几个，剩下大部分都来自欧洲的其他国家，像是意大利，法国，德国，匈牙利等。据在ETH就读本科的专业同学说，Data Science的录取竞争很激烈，要求十分严格，考量标准多元，很多表现优异的ETH本校本科生也没能通过录取。估计，这几年随着项目规模的扩大，竞争会有所缓和。</p><h1 id="专业学习情况"><a href="#专业学习情况" class="headerlink" title="专业学习情况"></a>专业学习情况</h1><h2 id="项目设置"><a href="#项目设置" class="headerlink" title="项目设置"></a>项目设置</h2><p>Data Science Master总体要求120学分，官方推荐2年修完，最长可延长至四年，我实际用了近三年的时间完成项目（也因为疫情20年3月回国呆了半年多，耽误了进度），上一届的一名中国的大神学长用了近两年时间毕业，成了本专业第一名毕业的学生。学分细节要求可以参考项目官网<a href="https://ethz.ch/content/dam/ethz/special-interest/infk/department/Images%20and%20Content/Studies/Master/DS/Study_Guide_MSc_DS_Content.pdf">ETH Data Science Master study guide</a>。ETH的学分这么定义的the number of weekly hours。基本上可以理解为1学分代表1周要花1小时，我的实际经历中学分定义存在一定偏差，比如当年我选修的Big Data为8学分，但实际的工作量超过每周8小时，不过这门课从2020年起改成了10学分，也有些课，实际课业耗时会比学分定义来得轻松。总之，课程学分只是一个参考值，具体情况还得具体分析。</p><p>再说些专业内部的课程设置。Data Science项目中的必修部分是：CS和Statistics相关的专业课，一门Data Science Lab，一门讨论班，和最后30学分的thesis。每个学生还需要选择一个应用领域的专攻方向，并在此方向修满一定数量的学分。目前DS开设的方向有，计算生物学，计算机网络，金融保险，地理信息系统，法律政策与创新，神经信息处理，社交网络，交通规划系统和天气气候系统。此外是一些人文社科等通识选修课，有少量学分要求。</p><p>DS专业必修课程与CS Master，RSC Master，Statistics Master，CBB Master的重合度很高。常常能在这些课的课堂上见到来自上述专业的小伙伴们。ETH与其邻居UZH的关系十分密切，很多选课互相开放，我在课程项目里也多次和来自UZH的小伙伴们合作。</p><h2 id="学习体验"><a href="#学习体验" class="headerlink" title="学习体验"></a>学习体验</h2><p>回顾整个硕士阶段的学习体验，可以概括为两个字“硬核”。我的本科背景是国内Top2数学专业，来了ETH之后，深感学业压力。很多老师自己写教材，对上课内容了如指掌，理论性体系性非常强。第一个学期，我试探性地修了24学分和一门德语课。讲道理课业压力应该不大，开学时我还美滋滋地计划周末都要去哪儿哪儿玩。然而现实是，第一学期的周末几乎都在和小伙伴一起做作业学习中度过了。周一到周五天天去学校，下午六点前除了上课就是去图书馆看参考书籍，去机房一起做小组project，去自习区讨论问题。同学们上课非常认真，课堂的互动性很高，常常有人打断老师提问题，老师也很注重与学生之间的互动。一方面老师讲课确实很吸引人，不敢错过，另一方面周围同学的认真态度也很有感染力，我在ETH生生把之前上课玩手机的坏习惯给改掉了。。大家的学习和工作方式是注重效率不拖延（maybe对于我这样的人，一旦拖延，任务就会越积越多），该学习的时候不玩，该玩的时候不学习，正如ETH宣传片里所说“work hard, play hard”。</p><p>DS的很多课是理论教学+小组/个人项目的模式。有些课会每周布置课后作业，但不是每一门课的课后作业都会记入最终的评分体系中。课后作业，更多是一种自发性的学习辅助材料。做了，可以发给助教帮忙批改，不做的话也没人监督不会扣分。可做与不做，往往能在最后的期末考试中看到区别。</p><p>讲到考试，必须详细介绍下ETH的考试季。一年中，ETH的硕士分为两个学期，秋季和春季。每学期的期末笔试分为两种类型：end-of-semester examinations和session exams。第一种考试，顾名思义，在每学期结束的时候进行，类似于国内很多大学的期末考时间。比如秋季学期的授课时间是9月中到圣诞节前，这种end-of-semester examinations就会发生在圣诞节前的最后两周。我经历的很多选修课，通识课都会在这个时间段考掉。第二种考试session exams，也是ETH的真正奇葩考试季，是在当前学期的假期结束后，下一个学期开始前进行。对于12月末放假的秋季学期来说，该学期的session exams会在第二年的1月-2月左右进行，春季学期的session exams则会在8月-9月进行。往往是专业必修课等学分多，任务重的“大”课会安排session exams。这意味着什么？意味着，寒暑假当即减半。我19年7月将近一个月都在学校备考，工作日去CS图书馆（特别小的一间屋子）比学期内上课都早，因为图书馆常常在开门半小时内就没位置了。7月准备了一个月，8月整个考试月把几门课考掉，再休息两周，欢欢喜喜迎来新学期。</p><h1 id="课余活动"><a href="#课余活动" class="headerlink" title="课余活动"></a>课余活动</h1><p>ETH绕不开的课余活动就是ASVZ了。ASVZ是一家专门给高校提供健身活动课程的机构。它提供的课程之丰富，群众参与度之高，都是我非常喜欢的。还没有疫情的时候，每个工作日下午五六点后，Polyterrasse健身房活动室都是人挤人，连空的衣物存储柜都很难找到。在ETH读过书的小伙伴，应该都知道ASVZ的(Super)Kondi课，综合身体素质训练，我第一次参加，老命差点都跳没了。周围的小哥哥小姐姐大爷大妈们，一个个可带劲儿地享受着。ASVZ提供一些自我训练的健身器材，还提供一百多种的体育教学课程。从学期内常规的课程，比如有氧，搏击，芭蕾，攀岩，跑酷到假期内的连续性项目，比如水上滑板冲浪等，应有尽有。说实话，我为自己安排ASVZ课程的热情一度超过安排学习内容。要参加ASVZ的服务，需要成为它的会员，对Bachelor/Master学生来说，这个会员身份包含在校园卡里了，每学期应该是三十瑞法，交学费的时候一并交了，然后就能享受整整一个学期的健身房和健身课程，几乎可以说是免费了（除了个别假期的项目会额外收费）。</p><p>此外的课余活动主要来自VSETH（ETH学生会），各个院的学生社团和其他学生组织。VIS（CS学生会）学期初会组织迎新BBQ，学期末最后一个周五会有免费的brunch，疫情前春季学期末还会组织全院的同学去猫湖BBQ。平时也几乎周周有活动，讲座，宣讲会，hackthon，datathon等，可以把课余生活过得很充实。</p><p>再多提一个活动polyball，这是个充满了故事的舞会，一年一度（疫情前）。学生教授校友都会穿上舞裙西装来参加。据说很多教授夫妇们是在舞会上开始恋情的。整个ETH主楼都会被装饰，主楼的不同区域有多种舞蹈音乐风格，还有脱口秀，吉他演奏等小节目。Polyterrasse的篮球操场会被改造为一个超大的舞池，集体跳舞，大家能从晚上嗨到凌晨。Tip：Polyball的门票还是很贵的，也有人选择为polyball做志愿服务减免一些门票开销。</p><h1 id="生活文化体验"><a href="#生活文化体验" class="headerlink" title="生活文化体验"></a>生活文化体验</h1><p>下一个想分享的是在苏黎世的生活文化体验。选择来一所学校就读，间接地就意味着选择了当地的生活方式。我很享受在苏黎世的便捷生活，不论是城市基础设施还是人文历史自然旅游资源，都无可挑剔。首先，讲讲经济花销。</p><h2 id="生活开支"><a href="#生活开支" class="headerlink" title="生活开支"></a>生活开支</h2><p>瑞士的物价是全球出了名的高，之前有很多学弟学妹们咨询过我开销的问题。然而事实上，整个开销其实相对于美国读硕士要少很多。首先，ETH读书的学费是真的很低，不同于大多数美国硕士按学分收费，ETH是按照学期收费，一个学期是七百多瑞法，按7的汇率换成人民币的话，是四五千人民币一学期。这个费用大部分家庭应该都能接受。在ETH读书，大头开支是生活费，住房吃饭和交通。一学期的学费会比一个月的生活费还少。最主要的房租，其实浮动范围也很大，最便宜的学生宿舍不到四百瑞法一个月，常见的学生宿舍/在外合租公寓大部分价格在七百到九百瑞法一个月，好一些的studio会达到一千多瑞法一个月。住宿条件优劣不一，不过这方面个人可根据自己的能力选择。吃饭也是一样，学校食堂的饭多在7-10瑞法一顿，在餐馆可以20瑞法起步吧，如果选择自己做饭的话，会便宜很多，购物选择Aldi/Lidl等折扣超市的话，又可以节省很多。最便宜的预算每月三百瑞法足以喂饱自己了。交通通讯这种也有很大的自主选择空间，不赘述。</p><p>说完开销之后，再说说收入。在ETH读硕士也是可以赚取一笔可观的零用钱的。学校在申请时提供一种ESOP奖学金，每学期提供12000瑞法同时豁免学费，持续三到四个学期。基本上拿到这种奖学金来ETH读书，不但不用付钱还能收获一笔。ESOP是基于本科时候的表现来评判的。如果入学时没有拿到ESOP也不要紧，在前两个学期结束后，学业表现达到一定要求还能继续申请学校的资助，之后每学期也能收获一笔可观的资助。除了奖学金助学金之外，在ETH当学生助理/助教也有一定的报酬，时薪扣了税之后，在二十多不到三十瑞法。学期内做助理有每周时长限制，假期中就没有限制了。学业之外有额外精力，可以联系喜欢的实验室看看有没有助理职务。我们常常开玩笑说，ETH不缺的就是钱，要相信瑞士的经济实力。</p><h2 id="当地文化"><a href="#当地文化" class="headerlink" title="当地文化"></a>当地文化</h2><p>苏黎世在德语区，处处体现着德国人的严谨，独立和对规则的崇尚。我一开始挺不适应苏黎世的条条框框，做什么事情都要严格遵循规则来，对约定的时间要严格遵守。但后来逐渐习惯，慢慢喜欢上了这种生活方式，对个人生活确实带来了极大的便利。在苏黎世的生活体验如果展开了说，可以写成好多篇小作文。这里只选取几大点，概述我的生活体验。</p><p>第一点是时间管理。作为世界闻名的手表大国，当地人的时间管理堪称master级别。最直观的在搭乘公共交通时就能体会到。电车公交小火车严格遵守时刻表，精确到以分钟为单位，市区内不同车的中转衔接也都控制的很到位。大到年度时间管理，例如各个社区回收不同垃圾的日程，工作日节假日的车次安排等。</p><p>第二点是严格遵循规则。我第一个面对的就是丢垃圾的规则。垃圾分类在中国也开始实行了，但是在公民执行的动力和精细程度上，远不在一个level上。日常要配备的垃圾袋有：巨贵的Zurichsack装杂物垃圾，生物垃圾（食物残渣等）专门丢一个垃圾桶，纸/纸板丢一个垃圾桶，塑料瓶分透明不透明丢在不同地方，铝制品丢一个，玻璃瓶分白绿棕颜色丢在不同地方。此外还有专门的地方或者小电车回收家具，家电等，绝不能乱扔。类似的要严格遵守的还有交通出行规则，房屋出租退房等。一般来说，苏黎世人会主动仔细地介绍各种规则，大家都自觉遵守确实会给生活带来很大便利。</p><p>还有就是浓烈的运动氛围，特别是户外运动。双休日，特别是周日超市商店不开门，大家特别喜欢朝户外跑，徒步骑车或者攀岩。滑雪季的时候，早晚在火车站总能看到拿着滑雪装备的人。瑞士的自然景观条件相当优秀，路线开发出行服务也很成熟，是个进行户外运动的绝佳地点。</p><p>最后想说的就是，瑞士处在欧洲的中部，对热爱旅游的小伙伴来说，是个周游欧洲的绝佳位置。从瑞士出来就是法国，德国，意大利，奥地利。再远一点去西班牙，葡萄牙，荷兰，东欧各国都不会很远。再加上瑞士自身的国际氛围浓厚，人文艺术资源丰富，简直是个旅游天堂。不过这两年因为疫情，旅游得慎重。希望疫情快快过去。</p><h1 id="毕业去向"><a href="#毕业去向" class="headerlink" title="毕业去向"></a>毕业去向</h1><p>这一点，相信很多来ETH读Master的同学都很关心。我自己也花了很大一部分时间和精力在这上面。虽然最终我没有留在瑞士，而是选择毕业后先回国工作（某种程度上也是受疫情影响），但仍想把了解到的信息和大家分享。</p><p>在瑞士工作是一个非常香的选择，work-life balance，巨高的时薪，合适的税率，舒适的工作条件等等等等。但是作为一名中国人，硕士毕业后留在瑞士工作是存在一定难度的。这个难度主要来自于移民局的工作签证。对于非瑞士或者欧盟的居民来说，每年各个州的工作签证是有限额的，申请工作签证必须在限额没用完之前。雇佣你的公司需要向移民局提出申请，并证明“There is nobody available in Switzerland or any EU/EFTA country for the job”。这一点就很玄，很多公司也因此不太愿意为刚毕业的同学申请工作签。比如了解到的狗家，更愿意为senior level的人申请工作签，而非刚毕业的同学，哪怕是在ETH就读。对于跨国公司还好，很多瑞士本土的公司还会有语言要求，比如德语/法语/意语达到一定水准，所以有意留瑞士工作的小伙伴可针对目标公司，提前准备语言。在瑞士拥有学生签的人，在毕业后还可以使用六个月的学生签来找工作。对于想在学期内找实习的小伙伴来说，如果你的学期项目包含强制实习，在瑞士境内的公司实习的成功率会大很多。遗憾的是，目前DS的项目里并不包含强制实习，如此来说，许多公司也不太愿意帮助申请工作许可。</p><p>以上都是官方说法，我认识的同学中，毕业后留瑞士的人大多数是以继续读PhD的方式，对于科研有热情的同学，读PhD真的是一个很棒的选择，ETH/UZH/EPFL等有着非常优质的教学资源和令人羡慕的工资。成功留在瑞士工作的也有不少小伙伴，所以大家也不用担心之前讲的工作签是完全不可行的。还有一大部分同学会去欧洲的其他国家工作或读博，比如德国英国荷兰等。ETH在欧洲的认可度是很高哒。再有就是像我这种，回国工作。（希望以后有机会能回到瑞士工作）</p><p>以上就是我在ETH读DS Master的经验分享，希望能对大家了解ETH提供有用信息，也欢迎大家来到ETH读书/工作！</p>]]></content>
      
      
      <categories>
          
          <category> Sharing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Swiss </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读书：建筑也可以很好玩：欧洲篇</title>
      <link href="/du-shu-jian-zhu-ye-ke-yi-hen-hao-wan/"/>
      <url>/du-shu-jian-zhu-ye-ke-yi-hen-hao-wan/</url>
      
        <content type="html"><![CDATA[<p>建筑也可以很好玩：欧洲篇：从古希腊到文艺复兴</p><p>建筑也可以很好玩：欧洲篇：从古典主义到近现代</p><p>作者：密小斯</p><p><img src="%E5%BB%BA%E7%AD%911.png" alt="建筑也可以很好玩：欧洲篇：从古希腊到文艺复兴"></p><p><img src="%E5%BB%BA%E7%AD%912.png" alt="建筑也可以很好玩：欧洲篇：从古典主义到近现代"></p><p>关于欧洲建筑历史和知识的通俗读物。将建筑的历史背景，起源，功能，特点，影响有机地结合起来，不枯燥且有逻辑，同时配以简明有趣的图辅助理解。作者常利用讲故事的方式展开介绍，很有意思。我这种外行人表示学到了很多，能试着开始去理解建筑，进而欣赏建筑。阅读这两本书之后，我一方面积累了些欧洲建筑的基本知识，另一方面学会了欣赏建筑的一些方法论：从材料，功能，历史人文，物理结构多个角度切入。在欧洲旅游的时候，不再是一脸懵逼了，很喜欢。</p><p>牢记古希腊的维特鲁威在《建筑十书》中说的：</p><blockquote><p> 建筑的三大终极定律：坚固，美观，实用</p></blockquote><p>这本书的笔记分为以下几个部分：</p><ul><li>各种建筑风格/元素笔记</li><li>具体建筑作品笔记</li><li>整体概览图</li></ul><p>重点挑了我喜欢的或者熟悉的建筑内容做笔记摘抄，至于偏现代的建筑，也没怎么看过，做了笔记也没有印象 <span class="github-emoji"><span>😢</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f622.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>，很多就略过了。。。</p><h1 id="建筑风格-元素"><a href="#建筑风格-元素" class="headerlink" title="建筑风格/元素"></a>建筑风格/元素</h1><table><thead><tr><th>是什么</th><th>时间</th><th>为何产生/历史背景</th><th>特点/风格</th><th>运用/发展</th></tr></thead><tbody><tr><td>神庙</td><td>公元前9-公元前6世纪</td><td>古希腊人心目中神偶尔居住的地方。古希腊人是相信世界上有神的，但是神和人并没有地位上的高下之分，只是能力更强大一些。</td><td>从氏族领袖的住宅改建而来，规模不大，与住宅相似</td><td>有的神庙中间纵向加一排列柱，以增大宽度；有的建筑外侧有外廊</td></tr><tr><td>几何学与数字比例</td><td>公元前9-公元前2世纪</td><td>古希腊崇尚理性主义，认为世间万物之间的关系要符合几何学才会有一种和谐的美感</td><td>黄金分割法，几何图形</td><td>柱式中的比例，神庙立面的黄金螺旋比例等</td></tr><tr><td>柱式</td><td>公元前7-公元前5世纪</td><td>早期古希腊祭祀主要在室内举行；到了后期，圣地的活动多转移到了室外，圣堂是活动广场的中心景观，外观气质很重要。<br>当时的建筑主要材料是大理石，便于雕刻，但不能做出很大的跨度。所以只能通过在建筑周围布置一圈的柱廊来增加层次感和变化。</td><td>固定的比例和使用规定</td><td>多立克柱式Doric order（西西里）：代表男性，较粗壮， 宽高比大约1:5.5，檐部厚重（约为柱子高的1/3），没有什么装饰，外形明朗的高浮雕<br>爱奥尼柱式Ionic Order（小亚细亚）：代表女性，较修长，宽高比约为1:9，檐部轻盈（约为柱子高的1/4），柱头布满细密雕刻的漩涡，像一双大眼睛或者小姐姐垂下的秀发，较浅较柔和的浅浮雕</td></tr><tr><td>雅典卫城Acropolis</td><td>公元前6世纪左右</td><td>顾名思义，用来保卫城市，防卫外地。一般会建在城市的最高处。平时作为公民祭祀和举行庆典的场所。如果打仗时，战况不利，所有人都会躲到卫城里，跟敌人打消耗战。后来守护神崇拜盛行，卫城变成了守护神的圣地，在最突出显眼的地方，建造守护神殿。</td><td>多立克柱式和爱奥尼柱式混合使用：为了解决地面高差。地势低用修长的爱奥尼柱式，地势高就用短粗的多立克柱式。</td><td>伊瑞克提翁神庙Erechtheion：西侧六根女郎柱，把女人的身体直接当作柱子的装饰。</td></tr><tr><td>公共建筑</td><td>公元1世纪前后</td><td>罗马国立强盛，出现了很多供普通老百姓使用的场所，增加了对大型公共建筑的需求</td><td>大</td><td>角斗场，浴场等</td></tr><tr><td>拱券技术</td><td>公元1世纪成熟</td><td>大型建筑场所的需求，增加了对建筑承重的要求</td><td>圆弧形的拱：一方面能够增大建筑的跨度，承受更大的压力；另一方面，拱下可以形成更大的空间。</td><td>最早用在输水道上：塞哥维亚城Segovia的输水道。从筒形拱：一个圆筒形的拱（需要很厚的承重墙，光照不进来，不透气），发展成为十字拱（两个筒形拱以90度垂直的方式交叉在一起，可用柱子作支撑，无须承重墙，透光透气），为了解决十字拱的侧推力，将十字拱相连，形成了拱顶体系</td></tr><tr><td>柱式的发展</td><td>古罗马时期</td><td>古罗马人在使用古希腊的柱式风格时，遇到了问题，主要有：1.柱式与拱券结构上存在矛盾；2.古希腊柱式与古罗马多层建筑的矛盾；3.古罗马巨大建筑的细部装饰矛盾</td><td>大建筑与柱式相融合</td><td>券柱式：在拱券结构的基础上，用柱式来装饰；<br>叠柱式：用多层叠加柱式的方法来支撑巨大的建筑，底层多立克，其上爱奥尼，再往上科林斯柱式Corinthian order<br>巨柱式：直接把柱子做大<br>塔斯干柱式Tuscan order和混合柱式：对于柱式的装饰，包括檐口，柱头，雕刻，线脚的处理等。</td></tr><tr><td>穹顶</td><td>公元1世纪</td><td>一个拱券旋转360度而成，现浇混凝土技术</td><td>建筑整体性强，跨度大</td><td>万神庙</td></tr><tr><td>巴西利卡basilica domus</td><td>4世纪的古罗马晚期</td><td>由于基督教在欧洲普遍传播，人们也需要进行宗教活动的场所。最基本的要求：一个可以聚集很多人的大空间。</td><td>普遍比较简单，内部经常用几排纵向的柱子把一个长方形的空间分成几条窄一些的空间，例如两排柱子将空间分成了三条，那中间的一条叫作“中厅”，最宽；两边的“侧廊”对称布置，窄一些。“中厅”比“侧廊”高，高出部分的两侧做出用来采光的侧窗。<br>在举行仪式的时候，教徒们要面向东方的耶路撒冷，所以圣坛在建筑的东侧，入口在西侧。</td><td>十字形，三短一长的“拉丁十字式”。到中世纪，宗教意味加重，慢慢成了当时小型教堂的代名词。</td></tr><tr><td>哥特式Goth</td><td>10世纪左右</td><td>国王和教会对建筑的要求：接近上帝。让身处教堂的人，无论是教皇/牧师还是信徒都能有一种“保送天堂”的感觉。如何达到这个目的？把教堂做高，越高越好，越高越接近上帝。</td><td>骨架券：框架结构，四个角做出拱券，石板架在拱券上。这样顶部的围护部分可以做得非常薄，既大大减轻了重量，也节省材料。<br>飞券/飞扶壁：解决骨架券遗留的最外侧侧推力的问题，把自身的结构暴露出来，重复实用产生一种向上韵律感<br>双圆心尖拱：将拱券做成两个圆心，从力学的角度，将侧推力变得更小，于是墙可以做得更薄，屋顶可以伸得更高。<br>彩色玻璃窗：圣经故事画，除了采光，还为了传播基督教。无法人手一本《圣经》，就将故事刻在教堂玻璃上。</td><td>骨架券第一次应用：1144年建成的法国的圣丹尼教堂<br>飞券的代表作：巴黎圣母院</td></tr><tr><td>东拜占庭式教堂</td><td>4-15世纪</td><td>东正教的宗教仪式主要强调信徒们<strong>亲密和谐</strong>，所有教堂内的核心往往是一个穹顶之下的大空间。东正教把穹顶越做越大，越做越高。穹顶成了整个教堂的精神中心和视觉中心。</td><td>帆拱：优雅地连接圆形穹顶和下部多边形的结构<br>鼓座：为把穹顶架高，在穹顶和帆拱之间加一圈环形墙。<br>希腊十字：用四格筒形拱顶住帆拱的四个发券外侧，解决最外侧的侧推力</td><td>意大利威尼斯：圣马可教堂<br>圣索菲亚大教堂</td></tr><tr><td>文艺复兴</td><td>14-16世纪</td><td>拜占庭灭亡和黑死病，人们开始向教权发起挑战。新兴资产阶级崛起，大量古希腊古罗马建筑遗迹被发现，《建筑十书》重新发表</td><td>矢形穹顶，柱式，拜占庭建筑风格得到发扬，学习和模仿古希腊和古罗马。哥特式遭摒弃</td><td>佛罗伦萨主教堂</td></tr><tr><td>“坦比哀多式”</td><td>15世纪</td><td>文艺复兴盛期，致敬古希腊和古罗马的建筑风格</td><td>大气稳重的形态<br>穹顶<br>古典柱廊<br>柱式的运用<br>形象鲜明/标准的半圆形穹顶作为整个建筑的统率，结合柱廊的集中式建筑形制</td><td>梵蒂冈圣彼得大教堂<br>英国的圣保罗大教堂<br>美国的国会大厦</td></tr><tr><td>巴洛克</td><td>17世纪以后</td><td>16世纪后半叶，教廷重获话语权，坚决废除人文主义的建筑形式。<br>古希腊和古罗马没啥新东西可挖了。建筑师们想创新。<br>米开朗基罗擅长雕塑，在设计建筑时会不顾建筑结构的逻辑而将大量的雕塑装饰手法运用其中，发展出一批粉丝。<br>教会越来越奢靡，相信上帝住在豪华的宫殿里。</td><td>堆砌装饰，让人“目眩”<br>雕刻充满教堂内部，分不清四面墙壁和屋顶的界线<br>色彩鲜艳，对比强烈，大量使用镀金/象牙等贵重材料<br>大量使用“双柱”。<br>巴洛克：原意：畸形的珍珠，法国人起的。</td><td>枫丹白露宫内部<br>波洛米尼的圣卡罗教堂</td></tr><tr><td>法国古典主义</td><td>17世纪以后</td><td>法国随着皇权的发展壮大，在艺术上也需要一种风格用来配合皇权的强化。法国把自己比喻成当年辉煌的罗马帝国，建筑上也需要像当年罗马盛行的雄伟大气的风格。皇帝路易十四成立了各种艺术学院，在学校里，学生们只能画两种画：歌颂古代的英雄以及颂扬伟大的君主。颂扬君主的“伟大”，逐渐形成了法国独特的宫廷文化。</td><td>看重艺术中“理性”和“条理”<br>“系统”的美学标准，“规矩”和“套路”<br>总平面上往往采用对称式布局，轴线清晰；立面通常采用“横三纵五”的分段方式，强调立面构图的主次关系。</td><td>凡尔赛宫<br>卢浮宫</td></tr><tr><td>洛可可</td><td>18世纪</td><td>建造凡尔赛宫几乎掏空了国家。18世纪初期，法国社会已经民不聊生。整个法国的上层生活糜烂。绝对君权时期讲究“威严”和“爱国”的基调已经不再受到关注，取而代之的是“轻柔”和“自在”的趣味。</td><td>以室内装饰为主<br>装饰风格倾向于自然元素，各种细密的植物草叶，贝壳的雕塑装饰<br>构件和物品的每个细节都是独一无二的，更像是自然生长出来的，而非几何化的比例和对称。<br>给人一种很“娘”的感觉，粉粉嫩嫩</td><td>罗马耶稣会教堂内部装饰</td></tr><tr><td>古典复兴</td><td>18-19世纪</td><td>资产阶级革命期间，以法国为中心，由对民主与共和的追求追溯到了老祖宗古希腊（民主）和古罗马（共和）。法国建筑也产生了代表古典复兴的两种倾向：罗马复兴和希腊复兴。</td><td>一大批仿古罗马风格的建筑，只不过建筑体量要比后者大得多。</td><td>巴黎雄师凯旋门<br>巴黎万神庙<br>大英博物馆<br>英格兰银行<br>柏林国立美术馆</td></tr><tr><td>浪漫主义</td><td>18世纪末-19世纪上半叶</td><td>英国的资产阶级革命胜利之后，大资产阶级取代了皇帝成为了国家的统治者，随手将曾经一起革命的小资产阶级与农民兄弟们丢在了一边，出现了一些乌托邦主义者，他们通过文学作品来宣扬建立一个没有压迫的和谐世界。社会的底层痛恨“机器社会”对他们的压榨，进而产生了“逃避现实”的情绪，向往回到中世纪自由的田园生活，对工业大城市充满了排斥。英国的古代文化最悠久和最灿烂的，自然是中世纪时期的哥特式风格。</td><td>以寨堡为原型<br>摒弃严格的中轴对称布局，回到了以使用功能为核心的自由式布局状态<br>用原本哥特式教堂的建筑风格去装饰非宗教建筑的处理方案：整体“直冲天际”的动势，顶部布满了大量“尖尖的”塔楼，表面细密的浮雕，布满花纹的玻璃窗。</td><td>英国伦敦大本钟<br>英国曼彻斯特市政厅<br>匈牙利国会大厦<br>英国议会大厦<br>伦敦塔桥</td></tr><tr><td>折中主义</td><td>19世纪上半叶</td><td>以美国为中心。美国从建国一开始就不存在“贵族”这个阶级。新国家迫切需要一种能被广大资产阶级接受的建筑风格，而这种风格，首先是不能使用英国的哥特式，而法国代表皇权的古典主义和巴洛克也一定要避开，所以美国的开国元勋们将学习对象大致锁定在了共和国时期的古罗马建筑上。后来与欧洲国家之间矛盾缓和，于是美国放开手脚开始将欧洲历史上各个时期的建筑“拼凑”在一起。</td><td>将欧洲历史上一千多年间各式各样的建筑风格杂糅在一起的样式：<br>希腊的庙宇、双柱、柱式、穹顶</td><td>美国国会大厦</td></tr><tr><td>钢铁与玻璃</td><td>20世纪初期</td><td>随着冶炼技术的成熟，钢铁也开始在建筑中扮演了越来越重要的角色。它的综合性能（抗拉、抗压、可塑性等）上均有较大的优势，例如可以把建筑建得更高，在跨度上也大大突破了传统的局限。<br>出现了大量新功能的建筑：百货公司、集中办公楼、火车站等。就拿火车站来说，这种建筑往往需要超级大的内部空间。</td><td>用钢铁打造框架结构，<br>框架之间的缝隙用玻璃或砖根据采光等需要来填充</td><td>伦敦水晶宫</td></tr><tr><td>工艺美术运动</td><td>19世纪下半叶以来</td><td>19世纪下半叶以来，欧美国家纷纷进入资本主义经济飞速发展的阶段。大城市的崛起速度加快，城市的规模也越来越大，由此带来了一系列规划、交通、居住等复杂的城市问题。建筑作为其中的一环，也不得不跟上城市发展的脚步。新技术新材料一波接一波地更新，它们与旧有建筑形式之间的矛盾也越来越尖锐。</td><td>功能需求作为首要的考虑，为大多数人服务<br>装饰上反对古典建筑的繁琐和堆砌<br>首次强调建筑使用功能的重要性，提倡朴实的设计<br>运用哥特式风格手法</td><td>红屋</td></tr><tr><td>新艺术运动</td><td>19世纪末20世纪初</td><td>将建筑的发展坚决地从古典中剥离出来的运动。早期还大多停留在形式上，后来逐渐发展至功能。</td><td>摒弃任何历史上的元素<br>“新风格”：当时以自然风格为主）模仿植物形态和花纹<br>喜欢曲线<br>“装饰即罪恶”</td><td>塔塞旅馆<br>德国魏玛工艺与美术学校<br>格拉斯哥艺术学院<br>斯坦霍夫教堂</td></tr><tr><td>德意志制造联盟</td><td>20世纪初</td><td>由于当时的德国的工业实力已经超过了英国和法国，所以制造联盟号召本国的设计师与工厂联合起来，进一步提升本国工业产品在世界市场上的竞争力。建筑必须与工业生产结合。</td><td>艺术和工业深度结合<br>避免政治对设计的“干扰”<br>功能至上原则，全盘接受现代工业<br>坚决抵制任何形式的装饰<br>主张标准化和批量化</td><td>德国科隆大展综合楼</td></tr><tr><td>高层建筑</td><td>19世纪末</td><td>1871年整个芝加哥发生了一场重大的火灾，这场导致10万人无家可归的大火烧掉了市中心几乎全部的建筑。火灾过后，市政府开始着手城市的重建工作，由于市中心用地面积有限，又需要尽可能多的建筑面积，唯一的解决方式就是将建筑造得尽量高一些。</td><td>高层钢铁框架结构<br>功能与形式的统一</td><td>芝加哥家庭保险公司大楼<br>第一莱特尔大厦<br>温莱特大厦<br>瓜拉迪大厦</td></tr><tr><td>未来主义</td><td>20世纪初</td><td>这个流派最早出现在意大利，对机器时代拥抱得最彻底的一场的运动。认为速度、运动、战争的暴力才能代表未来的世界。</td><td>未来的城市一定是为大众服务<br>利用地下或地上架空的方式<br>用火车作为城市内部的交通手段</td><td>巴黎蓬皮杜艺术与文化中心<br>香港汇丰银行大厦</td></tr><tr><td>构成主义</td><td>20世纪上半叶</td><td>发源于俄国的构成主义将“结构”作为建筑的本质。</td><td>很类似工程结构物。</td><td>“第三国际”纪念塔</td></tr><tr><td>风格派</td><td>20世纪上半叶</td><td>一战期间，荷兰作为中立国，聚集了一批来自欧洲国家比男的艺术家。成了一个一个艺术组织，提倡将传统的雕塑、建筑等元素“净化”成最基本的几何形体，再利用这些基本的几何形体进行组合来产生新的艺术形象，</td><td>追求几何形体<br>对造型简化处理</td><td>乌德勒支的“施罗德住宅”</td></tr><tr><td>现代主义</td><td>20世纪上半叶</td><td>两次世界大战后，大量城市遭到严重破坏。住房短缺的问题暴露充分。如何快速并且廉价地建造大量住房就成了各国政府最着急的事情。有人提出将建筑设计“标准化”，因为只有这样，大量的房屋构件才可以结合工业批量化地生产、生产的成本也大大降低。功能和材料决定建筑的形式。</td><td>框架体系+玻璃幕墙等多种风格</td><td></td></tr></tbody></table><h1 id="建筑作品"><a href="#建筑作品" class="headerlink" title="建筑作品"></a>建筑作品</h1><p>时代，地理位置，设计者，元素/特色，功能，意义</p><h2 id="万神庙Pantheon"><a href="#万神庙Pantheon" class="headerlink" title="万神庙Pantheon"></a>万神庙Pantheon</h2><p>公元前27-25年，现位于意大利罗马。</p><p>罗马第一位皇帝屋大维Gaius Octavius Augustus为献给奥林匹亚众神而建。</p><ul><li>穹顶：古代欧洲跨度最大无梁圆拱，象征着“天”<ul><li>中央圆洞：建筑内部唯一光源，在4月21日，阳光能通过圆洞照亮整个建筑及入口处。这一天恰好是罗马建城日。</li><li>内部布满凹龛：能减轻穹顶的重量，视觉上形成优美的韵律</li></ul></li><li>柱式：入口8根科林斯式柱子，三角形屋顶，有古希腊神庙的感觉</li><li>集中式建筑</li><li>壁龛：一圈墙体内有8个凹进去的空间，一个用作大门，七个用作目的。其中一个里面躺着拉斐尔</li></ul><h2 id="罗马斗兽场Colosseum"><a href="#罗马斗兽场Colosseum" class="headerlink" title="罗马斗兽场Colosseum"></a>罗马斗兽场Colosseum</h2><p>建于公元72-80年，现位于意大利罗马。</p><p>古罗马后期，由于奴隶制的发展导致社会上出现大量的无业游民，为了安抚这些不安定因素，合理地诱导宣泄暴力，统治者建造了这座免费的公共娱乐设施。</p><ul><li>叠柱式：共四层<ul><li>底层：多立克柱式：象征男性，风格硬朗</li><li>接着：爱奥尼柱式：象征女性，婉转轻柔</li><li>接着：科林斯柱式：雕刻繁复</li><li>顶层：科林斯的实墙</li></ul></li><li>券柱式：单纯的几何外形，丰富的韵律感</li></ul><h2 id="建筑十书"><a href="#建筑十书" class="headerlink" title="建筑十书"></a>建筑十书</h2><p>作者：维特鲁威Marcus Vitruvius Polli，公元前一世纪，活跃于古罗马</p><ul><li>肯定人体与建筑美学的关系，举例：多立克柱式与男性，爱奥尼柱式与女性</li><li>建筑的三大终极定律：<strong>坚固，美观，实用</strong></li></ul><h2 id="圣索菲亚大教堂Hagia-Sophia-Aya-Sofya-Saint-Sophia"><a href="#圣索菲亚大教堂Hagia-Sophia-Aya-Sofya-Saint-Sophia" class="headerlink" title="圣索菲亚大教堂Hagia Sophia/Aya Sofya/Saint Sophia"></a>圣索菲亚大教堂Hagia Sophia/Aya Sofya/Saint Sophia</h2><p>始建于360年，历经三次重建，现为一座博物馆。位于土耳其君士坦丁堡。</p><p>第三次重建于532年，皇帝查士丁尼一世Iustinianus I。目的：</p><ul><li>显示他对基督教的虔诚（笼络民心）。他选择古罗马的巴西利卡作为建筑的基本形式，因为巴西利卡是最原始的教堂形式。</li><li>彰显自己的帝王决心。他看中了象征古罗马帝国极盛时期建筑典范的万神庙的超大穹顶。</li></ul><p>难点：将大穹顶落在方形的巴西利卡上。</p><p>解决方法：使用帆拱，在拱的外侧，用四个巨大的墙墩和垂直方向的两个半穹顶来抵住侧推力。</p><p>经历：553年558年两次地震，859年大火，869年地震，989年地震，圆顶屡次遭到破坏。第四次十字军东征，从东正教被改为天主教教堂。1344年地震，又破坏了圆顶。1453年，土耳其人占领君士坦丁堡，被改为清真寺，现在教堂周围四个高高的宣礼塔就是清真寺建筑的特征。</p><h2 id="佛罗伦萨主教堂Basilica-di-Santa-Maria-del-Fiore"><a href="#佛罗伦萨主教堂Basilica-di-Santa-Maria-del-Fiore" class="headerlink" title="佛罗伦萨主教堂Basilica di Santa Maria del Fiore"></a>佛罗伦萨主教堂Basilica di Santa Maria del Fiore</h2><p>建于1296年，建筑师们：坎皮奥Arnolfo di Cambio，乔托Giotto di Bondone，伯鲁乃列斯基Filippo Brunelleschi</p><p>13世纪末，佛罗伦萨的行会从贵族手中夺取了政权，为了庆祝胜利，市民们建造一座属于自己的教堂。</p><ul><li><p>教堂的平面采用拉丁十字式</p></li><li><p>教堂的歌坛部分设计成了属于东方的集中式</p><ul><li>其上，想建造一个形象鲜明，举世无双的大穹顶来体现新政权的权威。</li></ul></li></ul><p>难点：做出一个完全暴露的大穹顶。建筑建得越高，穹顶造得越大，结构向两边的侧推力就越大。</p><p>解决办法：Brunelleschi</p><ul><li>采用矢形而非半球形，受哥特式的双圆心拱的启发</li><li>穹顶分里外两层，中间是空的，大大减轻了穹顶的重量，也从另一个角度减小了侧推力。</li><li>教堂主体和穹顶之间垫了一段12米高的鼓座，为了进一步抬高穹顶。（拜占庭建筑手法）</li></ul><h2 id="圣彼得大教堂Basilica-di-San-Pietro-in-Vatican"><a href="#圣彼得大教堂Basilica-di-San-Pietro-in-Vatican" class="headerlink" title="圣彼得大教堂Basilica di San Pietro in Vatican"></a>圣彼得大教堂Basilica di San Pietro in Vatican</h2><p>教会与人文主义的拉锯战</p><ul><li>1503年，罗马教皇尤里乌斯二世Giuliano della Rovere下令重建为了纪念圣彼得的圣堂。要求：空前绝后。当时教皇的御用建筑师伯拉孟特Donato Bramante（设计坦比哀多那位）担任总设计师。他是一名坚定的人文主义者。方案：建造一座正方形和<strong>圆形</strong>的大教堂，一个集中式的希腊十字式，完全对称。</li><li>前任教皇去世，Bramante去世。新人教皇利奥十世Giovanni di Lorenzo de’ Medici要求改回天主教的标准形制——<strong>拉丁十字式</strong>。任命拉斐尔Raffaello Santi做设计。</li><li>16世纪上半叶，教皇保罗三世Alessandro Farnese任命米开朗基罗Michelangelo Buonarroti来主持大教堂的设计。Michelangelo主张<ul><li>恢复<strong>希腊十字式的集中式平面</strong></li><li>在<strong>西立面设计了象征古典的柱廊</strong></li><li><strong>穹顶</strong>：推进了一步，更加突出和饱满</li></ul></li><li>1564年，建筑师维尼奥拉Giacomo Barozzi da Vignola建造了大穹顶周围的<strong>四个小穹顶</strong>，引入了拜占庭建筑的手法</li><li>16世纪中叶，欧洲宗教战争，教会获胜。<ul><li>代表天主教的<strong>拉丁十字式重新</strong>被强制规定为标准建筑形式。建筑师卡洛·马代尔诺Carlo Maderno继续完成大教堂的建筑部分</li><li>希腊十字的西侧被强行加上了一段巴西利卡</li><li>米开朗基罗设计的西立面被拆除</li></ul></li><li>文艺复兴之后，教会聘请了巴洛克式大神贝尼尼Gianlorenzo Bernini设计教堂全部内部装饰和教堂外西面的大广场。</li></ul><h2 id="卢浮宫Musee-du-Louvre"><a href="#卢浮宫Musee-du-Louvre" class="headerlink" title="卢浮宫Musée du Louvre"></a>卢浮宫Musée du Louvre</h2><p>13世纪为了抵抗十字军东征而建设的一座城堡。现位于法国巴黎塞纳河北岸。</p><p>路易十四时期，对建筑进行改造。17世纪中期，宫殿的<strong>四合院形态</strong>基本建设完成，东面是一座皇家教堂。</p><p>法国宫廷邀请了贝尼尼Gianlorenzo Bernini，设计了一套<strong>巴洛克风格</strong>方案。</p><p>贝尼尼回国后，采用了<strong>古典主义</strong>方案，东立面最终的形态。</p><p>20世纪末，卢浮宫需要扩建，贝聿铭设计了一个由钢铁和玻璃制造的“大金字塔”和4个“小金字塔”，位于卢浮宫大院子中心。</p><h2 id="凡尔赛宫Chateau-de-Versailles"><a href="#凡尔赛宫Chateau-de-Versailles" class="headerlink" title="凡尔赛宫Château de Versailles"></a>凡尔赛宫Château de Versailles</h2><p>1661年动土。现位于法国巴黎凡尔赛。</p><p>路易十四为了集中控制大贵族们，将他们迁到这座宫殿中。后来为了方便，他干脆将自己的办公地点也迁到了这里。</p><ul><li>建筑整体属于法国<strong>古典主义</strong>风格，<strong>注重理性的比例与几何的运用</strong>，</li><li>由于当时巴洛克的影响，建筑内部的装饰也多为巴洛克风格<ul><li>“镜厅”芒萨尔Monshall设计。他擅长将法国古典主义与意大利巴洛克风格相混合。</li></ul></li><li>其中部分房间发展成了后来的洛可可风格。</li></ul><h1 id="整体概览图"><a href="#整体概览图" class="headerlink" title="整体概览图"></a>整体概览图</h1><p><img src="%E5%BB%BA%E7%AD%91%E4%B9%9F%E5%8F%AF%E4%BB%A5%E5%BE%88%E5%A5%BD%E7%8E%A9%EF%BC%9A%E6%AC%A7%E6%B4%B2%E7%AF%87.png" alt="概览图"></p>]]></content>
      
      
      <categories>
          
          <category> Reading Summary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Europe </tag>
            
            <tag> Book </tag>
            
            <tag> Architecture </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A quick reflection on Master thesis</title>
      <link href="/thesis1/"/>
      <url>/thesis1/</url>
      
        <content type="html"><![CDATA[<p>This article is a quick review of the path of my master thesis until now. I hope this record could be some guide for my future learning path.</p><p>I started the thesis unofficially from the middle of October 2020. The topic was about simplicial complex. In one sentence, building neural networks for higher-order graphs via designing a new graph convolution method based on simplicial complex. My mentor gave me 3-4 papers for reference reading. In the beginning, I was a perfectionist. I hoped to figure out each concept I met in the paper reading. I did the paper survey and collected over 50 papers for reading. However, on one side, that field was quite new for me, and the terms I was unfamiliar with were in a huge amount. On the other side, the field itself had not been well studied. I got lost in the paper reading part. I read for around three weeks without clear ideas.</p><p>In November, I began to make my hands dirty.  I started coding by reproducing a paper’s results. I tried to apply it on other datasets and also adjust its’ structure in some way. The experiments results were not good. In December, we worked on putting forward to our own creative ideas in this filed by designing a training task. The name was triangle prediction. The task was not well designed from the following aspects. First, we couldn’t find a wide range of useful applications for the task as well as not many suitable datasets for it. Besides, assuming that we have such a task, what was its contribution? We failed to figure out those problems. I did the experiments, more paper reading and datasets collection for around one month. In the end of January, we still couldn’t find hopeful path for this topic and had to say goodbye to it.</p><p>From Feburary, I started the current topic on temporal knowledge graph. We hope to model temporal knowledge graph by capsule network. In this time, I gave up my perfection principle, and put more attention to efficiency under time pressure. According to experience from the last topic, the paper reading process was greatly accelerated. </p><ul><li>Two weeks reading for capsule network and temporal knowledge graph.</li><li>two weeks for code studying by downloading, running and understanding. I did this for 5 repositories.</li><li>Two weeks for rewriting the baseline work from tensorflow to pytorch, and write a clear training and testing architecture for it.</li><li>two weeks for testing the baseline models and reproducing the results in the original paper</li><li>two week for comparison experiments on the baseline models and other baseline models.</li><li>Two week for designing and implementing my own models.</li></ul><p>This week, I work on adjusting my own model. Many things I would never realized until I created by my own. The biggest issues I met this week are </p><ul><li>loss function choice, </li><li>initialization method and </li><li>the inproper model structure</li></ul><p>How did I realize these issues? It came from an NaN loss. After several epochs of training, my model’s loss became NaN. I looked for solutions. Many articles online, e.g. <a href="https://zhuanlan.zhihu.com/p/89588946">this one</a>, saied it could be a inproper initialization issue. Then I checked the intermediate embedding of my model. As expected, the norm of these embeddings became infinitely large, compared to a small value less than 1 when initialized. So, I realized it could be my parameters initialization issue as well as the match between parameters’ and embeddings’ initialization. <a href="https://www.deeplearning.ai/ai-notes/initialization/">A very nice article from deeplearning-AI</a> explains and shows the power of Xavier initialization. My next step is to find a proper initialization method.</p><p>For the issue of loss function, I founded it by observing the gap between the achievable length range of my model’s output and ideal length range of the loss function’s input. In other words, given the output of my model, the loss couldn’t be decreased under a certain bar. Thus, I need to figure out which loss to use in the following week.</p><p>I designed an inapproriate model structure for my task: temporal knowledge graph forecasting. Namely, given an incomplete triplet with one element missing, the task is to find the missing elements. For knowledge graph, we are interested in the missing subjects (the first element in the triplet) or objects (the third element), not the relation (the second relation). In the beginning, I modeled this as a multi-class classificaiton problem. Given a pair of subject and object, I hope the model will predict the real relation type and use a cross-entropy loss. This way doesn’t work since the relation types could be huge, more than hundreds. Then, the true lable of 1 will be sparse and my model prefer to predicting every type with a low score to minize the loss. By the way, I tried to add negative sampling into this model and made things worse. Since all the labels of the negative samples are zero. </p><p>To wrap up, the main issue of the following week is to find a proper initialization method, design an effective model structure and choose a loss function for it.</p>]]></content>
      
      
      <categories>
          
          <category> Sharing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Thesis </tag>
            
            <tag> Capsule Network </tag>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读书：30岁前的每一天</title>
      <link href="/du-shu-30-sui-qian-de-mei-yi-tian/"/>
      <url>/du-shu-30-sui-qian-de-mei-yi-tian/</url>
      
        <content type="html"><![CDATA[<p>30岁前的每一天：实用梦想管理指南</p><p>作者：水湄物语</p><p>这本书的重点是要培养年轻人的理财观念，同时涵盖了年轻人的价值观塑造，心态认识的转变和一些生活工作习惯的推荐。对于理财部分，主要介绍了理财带来的好处，而其重点是为了推销作者创办的理财课程。对于理财观念的转变有帮助，但对于课程推销部分，不置可否。本书主要的可取之处在于价值观，心态和习惯养成部分。</p><p>以下是各个章节，它们的主要内容和重点可取部分。</p><h2 id="梦想改变生活"><a href="#梦想改变生活" class="headerlink" title="梦想改变生活"></a>梦想改变生活</h2><p>这一章是帮助人们识别出/定义自己的理想，认识到理想与现实的差距，为之后的如何实现理想打基础。</p><h2 id="聚集正能量的人生"><a href="#聚集正能量的人生" class="headerlink" title="聚集正能量的人生"></a>聚集正能量的人生</h2><p>这一章重点通过几个课题来将怎么产生正能量。这几个课题是：如何面对选择，如何认识到自己的能力，如何面对失败，以及如何变得乐观。</p><p>在“如何面对选择”中，有个观点比较有启发，大意是，当我们面对多个选择时，希望找到一个“最好的”选择，这个“最好的”定义，是迈向成功的捷径。然而，迈向成功一定有捷径吗？</p><p>譬如面对工作的选择时，我们常常会花费过多精力在比较工作的薪水，技能，内容方面的好坏。自己的才华没有得到展现时，只忙于抱怨工作本身，然而却会忽略“脚踏实地做好每一件事才有可能施展自己的才华”。</p><p>新颖的观点：</p><ul><li>社会和公司都不会长久地埋没一个人的才华，因为这是一个价值交换的经济社会。除非这种才华只是你自认为的才华，而不是社会和公司认可的价值。</li><li>做好你手中的每一项工作，如果你认为自己值得更好的薪水和工作，一定要将之建立在能完全做好目前这份工作的基础上。</li></ul><p>在”如何面对失败“时，有这些观点</p><ul><li>现在，既不是过去的奴隶，也不是未来的手段。（我想，这句话强调的是活在当下）</li><li>练习和失败的区别在于，练习无所谓成功与否，练习是为成功做的积累，甚至是”试错“。（如果我常常能怀着这种”练习“的心态，而不是成败的观念，是不是能给我带来更多的愉悦感以及成长呢？）</li></ul><h2 id="职业、学习、爱情的规划"><a href="#职业、学习、爱情的规划" class="headerlink" title="职业、学习、爱情的规划"></a>职业、学习、爱情的规划</h2><p>职业规划，作者给出了几个具体的步骤：</p><ol><li><p>要知道”我能做什么“</p></li><li><p>要知道”这个职业的路径是什么“。如何找到职业路径呢？</p><ul><li>公司招聘广告的JD</li><li>与业内人士进行交流</li></ul></li><li><p>”我还能再做些什么“：</p><p>分析自己的实际情况与目标岗位之间的差距，利用理论学习和实践经历来弥补这些差距。</p></li></ol><p>学习规划，主要讲了如何读书。同样的，作者给出了几条实用的建议：</p><ul><li>做读书笔记。”做读书笔记不是摘抄，而应该用自己的思维逻辑把作者的知识和想法重新阐述出来。“（这也是我这篇读书笔记的来源，现学现用，在摘抄的基础上把作者的想法阐述出来，提炼出自己的东西。）</li><li>善用思维导图</li><li>要读旧书：省时，经过了自己的检验，符合自己的胃口，温故而知新。作者为自己建了一个书单，叫做“值得再读的书”。</li><li>要读懒书。主要说的是筛选书。因为一个人无法读完所有的书，所以如何筛选书呢？<ul><li>借助时间。多次再版的书可能更有价值</li><li>借他人之手。当涉猎某一领域时，多看专家点评，名家推荐。</li></ul></li></ul><p>爱情规划，主要提出了几个建议来脱单，其实就是增加遇见的人，来增加备选。不置可否。</p><h2 id="财富规划"><a href="#财富规划" class="headerlink" title="财富规划"></a>财富规划</h2><p>作者有句话道破了工作的真相，“当你从事某个行业三四年之后，就会发现一件事——每天做的工作其实都是一样的，都是在重复做那些工作，这就是工业化社会带来的弊端。”</p><p>在将如何向别人询问投资理财的建议的时候，别人的结论固然有一定的价值，但作者还提到另一个更有价值的方面“不要轻易相信结论，而要思考一个人说话的逻辑，保持独立的思考，这是学习投资理财很基本的东西。”</p><p>在财富自由与薪水之间，作者提了一个大多数人都关注的问题“薪水高了就有余钱了吗？”作者认为，不。钱够不够花，是有消费习惯决定的。“消费习惯很难在短时间之内改变，而消费欲望则是无止境的。”换句话说，如果消费习惯是“有多少花多少”，那么无论多少钱都不够花。</p><h2 id="打败挡在梦想路上的“小怪兽”"><a href="#打败挡在梦想路上的“小怪兽”" class="headerlink" title="打败挡在梦想路上的“小怪兽”"></a>打败挡在梦想路上的“小怪兽”</h2><p>作者主要介绍了常见的降低大多数人生产效率的因素：拖延症，注意力涣散，无法说“不”，完美主义者，三分钟热度。针对每个因素，作者给出了一些小策略，帮助改进。</p><table><thead><tr><th>症状</th><th>对策</th></tr></thead><tbody><tr><td>拖延症</td><td>5分钟法：即不管三七二十一，挑选最有成就感的部分，先开始干五分钟。效果是，很可能就持续性地干下去了。<br>以毒攻毒法：就是啥也不干，静坐。效果是，往往会有很多完成工作的idea<br>积分奖励法：做到一定分量，就给自己一些奖励。<br>任务竞赛法：也就是下决心要超过对手（从而提升自己的效率）</td></tr><tr><td>注意力涣散</td><td>用一张便签记下所有的，因为外部环境而让自己分心的事情都列在上面，稍后再做。<br>倒计时工作法：通过增加对时间的焦虑感，来刺激自己更加集中注意力。<br>重视休息时间</td></tr><tr><td>无法说“不”</td><td>无法说不，是因为自信不足，“害怕”发生严重的后果。<br>最坏结果法：问问自己，如果我不做这件事，最坏的结果是什么？<br>说不的技巧：<br>积极倾听对方的请求，用抱歉语舒缓对方的情绪，明白干脆地说出“不”字，清楚地说明拒绝的理由。</td></tr><tr><td>完美主义者</td><td>（我太有共鸣了！）<br>将观念从追求完美的结果，转为追求速度和效率。不要害怕犯错。</td></tr><tr><td>三分钟热度</td><td>SMART原则。S：specific：目标应该明确，Measurable：可量化的目标。Attainable，R：relevant，T：time-based（有截止日期的）<br>安排的计划要详细，要有可执行性。</td></tr></tbody></table><p>作者有些观点：</p><ul><li>一个优秀的领导者，有一点品质就是“知道什么是最重要的事”。20%的工作产出80%的成果。</li></ul><h2 id="记事本改变生活"><a href="#记事本改变生活" class="headerlink" title="记事本改变生活"></a>记事本改变生活</h2><p>这里，作者给出了一个具体的，让生活更加高效的习惯/方法：每天“计时”。样例</p><table><thead><tr><th>时间</th><th>内容</th><th>计划时间</th><th>实际时间</th></tr></thead><tbody><tr><td>8:30-11:00</td><td>上班</td><td>2.5h</td><td>2.5h</td></tr><tr><td></td><td></td><td></td><td></td></tr></tbody></table><p>注意事项：</p><ul><li>留足充分的消息时间</li></ul>]]></content>
      
      
      <categories>
          
          <category> Reading Summary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Book </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weekly summary</title>
      <link href="/y2020w49-summary/"/>
      <url>/y2020w49-summary/</url>
      
        <content type="html"><![CDATA[<p>上周的总结，我悄咪咪地鸽了。给自己找个理由：亲戚来了，不在状态。直接总结两周哈。这周的感受一个词来形容就是：尽兴！我终于要学会倾听自己最真实的声音了。</p><p>之前的注意力更多放在了形式上，比如：我要在几点几点做什么。但很可能那个时刻并不是很想做这些事，就会走神，走神，走神，低效率，气死了。然鹅，这周经过几次尽兴的体验之后，感悟到：如果把时间投入到某个时刻最想干的事情上，而不是死板地执行计划表，会更有效率且开心。人毕竟不是机器嘛，情绪主导。还有一件，自己现在想想还蛮可笑可爱的事情，就是玩缺氧玩到生气，好生气，建的东西不是理想中的那样。经过和元元的交流，意识到向别人学习的重要性，以及问问题是一种非常非常高效的学习方式，比一个人死磕来得高效的多。我之前太喜欢自己一个人死磕了，自学是很好，但有时候效率不高，要学会去请教别人哇！不要把自己定位太高，充满疑问好奇接纳的眼光去看待周围，会发现很多好玩儿的事哦。有时候嘛，要把自己当成个傻子，别太高估自个儿了～</p><p>好啦，废话不多说，照例总结</p><h1 id="计划回顾"><a href="#计划回顾" class="headerlink" title="计划回顾"></a>计划回顾</h1><h2 id="Mathematical-Optimization"><a href="#Mathematical-Optimization" class="headerlink" title="Mathematical Optimization"></a>Mathematical Optimization</h2><ul><li>所有的课程都跟上节拍啦</li><li>Problem set2，证明题基本看完了</li></ul><h2 id="Thesis"><a href="#Thesis" class="headerlink" title="Thesis"></a>Thesis</h2><ul><li>triangle prediction的数据处理部分框架搭建好，模型框架搭建好</li></ul><h2 id="Life"><a href="#Life" class="headerlink" title="Life"></a>Life</h2><ul><li>骑车去了Zug</li><li>做了蒸米蛋糕</li><li>煎了鱼块吃</li><li>一周练习了三次瑜伽</li><li>《彩虹》各小节分开练习完成</li><li>《权力的游戏》第七季看完</li><li>入坑《我的世界》啦</li><li>对《缺氧》有了些新认识</li><li>和元元一起看了《半个喜剧》</li><li>《Rick and Morty》第四季看完了（好快。。。）</li><li>发了一个b站vlog</li></ul><h1 id="本周计划"><a href="#本周计划" class="headerlink" title="本周计划"></a>本周计划</h1><h2 id="Life-1"><a href="#Life-1" class="headerlink" title="Life"></a>Life</h2><ul><li><input disabled="" type="checkbox"> 《阳光普照》看电影</li><li><input disabled="" type="checkbox"> 《权力的游戏》第八季看完</li><li><input disabled="" type="checkbox"> 《彩虹》练熟</li><li><input disabled="" type="checkbox"> 做个排骨吃</li><li><input disabled="" type="checkbox"> 做个绿豆糕吃</li><li><input disabled="" type="checkbox"> 继续练三次瑜伽</li></ul><h2 id="Mathematical-Optimization-1"><a href="#Mathematical-Optimization-1" class="headerlink" title="Mathematical Optimization"></a>Mathematical Optimization</h2><ul><li><input disabled="" type="checkbox"> 跟住上课的节奏<ul><li><input disabled="" type="checkbox"> 争取上课问问题</li></ul></li><li><input disabled="" type="checkbox"> 把Problem set2的编程题做完</li><li><input disabled="" type="checkbox"> 直接跳到最新的Problem set上，去上习题课</li></ul><h2 id="Thesis-1"><a href="#Thesis-1" class="headerlink" title="Thesis"></a>Thesis</h2><ul><li><input disabled="" type="checkbox"> 精读link prediction任务场景和代码</li><li><input disabled="" type="checkbox"> 把Triangle prediction成功跑出来</li><li><input disabled="" type="checkbox"> 考虑模型适当地拓展</li></ul>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Thesis </tag>
            
            <tag> Life </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weekly summary</title>
      <link href="/y2020w47-summary/"/>
      <url>/y2020w47-summary/</url>
      
        <content type="html"><![CDATA[<p>上一周，和元元一起过了“在一起一千天”的纪念日，越来越爱他了！每天和他视频，看着他充满宠溺的小眼神，感觉自己是最幸福的人！上周文明6更新，和他开了一期巴比伦，英雄模式，这eurika拿得爽歪了。周六骑车去了趟Zug，然后去启凡party中心蹭饭吃。饭后，和熊熊，珊珊，小启凡一起上山看鹿，又是悠闲舒适的下午。周日感觉自己光打电话了，看到楠养的小奶猫：牛奶。她曾经说，养猫有什么好玩的。现在呢，可真香！</p><h1 id="计划回顾"><a href="#计划回顾" class="headerlink" title="计划回顾"></a>计划回顾</h1><ul><li>Life:50%. Incomplete tasks:<ul><li>每天八小时</li><li>香蕉糊的vlog</li><li>权力的游戏</li><li>This is us</li><li>练字</li></ul></li><li>Mathematical Optimization: 70%. Incomplete taskÖ<ul><li>Script and problem set</li></ul></li><li>Thesis: 100%</li></ul><p>一些感慨：睡觉这个要用心，不要给自己太大压力。看视频嘛，看rick and morty快看完了，感觉作者真天才，想重新再看一遍。MO在复习中遇到了新的需求，就是先重新整理一下笔记吧。然后再做练习题。感觉这种证明为主的东西，学了一遍，认为老师证明的有道理，还是远远不够的，要弄明白为什么这么证明，思路是怎么来的，几何直观要想想吧，intuition这些东西要好好想想。</p><p>Thesis进入了全面阅读paper的模式。</p><h1 id="下周计划"><a href="#下周计划" class="headerlink" title="下周计划"></a>下周计划</h1><h2 id="Mathematical-Optimization"><a href="#Mathematical-Optimization" class="headerlink" title="Mathematical Optimization"></a>Mathematical Optimization</h2><ul><li><input disabled="" type="checkbox"> Course 11-23 (11-23)</li><li><input disabled="" type="checkbox"> Course 11-26 (11-26)</li><li><input disabled="" type="checkbox"> Script + Note: page 18-46 (11-23)</li><li><input disabled="" type="checkbox"> Problem set2 (11-24)</li><li><input disabled="" type="checkbox"> Script + Note: page 46-71, Problem set 3 (11-25)</li><li><input disabled="" type="checkbox"> Script+Note: page 71-81, Problem set 4 (11-27)</li></ul><h2 id="Thesis"><a href="#Thesis" class="headerlink" title="Thesis"></a>Thesis</h2><ul><li><input disabled="" type="checkbox"> 整理出Issue部分(11-23)</li><li><input disabled="" type="checkbox"> 提出值得研究的问题(11-24)</li><li><input disabled="" type="checkbox"> 待定</li></ul>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Thesis </tag>
            
            <tag> Life </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weekly summary</title>
      <link href="/y2020w45-summary/"/>
      <url>/y2020w45-summary/</url>
      
        <content type="html"><![CDATA[<p>经过比历史波折一些的选举，Joe Biden最终当选为第46届美国总统，恭喜恭喜！懂王还在各种挣扎，他的律师团队正在进行一波操作。不过估计没啥卵用了。这么一个能闹腾的总统没有继续当选，我表示很理解（虽然选举过程中心情那个忐忑哇，就像看跑步比赛一样）</p><p>不说美国啦，说说自个儿，上周周四整个人居然崩了，完全没按计划走，而且上周的睡眠好差。本周重点在改善睡眠。不带手机上床，好好睡觉。</p><h1 id="计划回顾"><a href="#计划回顾" class="headerlink" title="计划回顾"></a>计划回顾</h1><p>上周计划的完成情况：</p><p>Mathematical Optimization: 80%. Incomplete tasks:</p><ul><li>Script: 18-57 (11.4)</li></ul><p>Thesis</p><ul><li>Papers: 28%</li><li>Task: 50%</li></ul><p>Life: 28%. Incomplete tasks:</p><ul><li>Game of throne. Season 6 Episode 9 10</li><li>Deutsch Vokabel: Everyday</li><li>Deutsch lernen: 2 episodes</li><li>Bodycombat: 50%</li><li>Fit: lose 1kg weight</li></ul><p>总结：MO一如既往的完成了，因为我养成了学它的习惯。可是其他的任务完成不来，甚至包括life的！和上上周感觉自己被打扰的体验不一样，上周主要是感觉缺少social support。因为疫情长时间在家里自己呆着，整个人都不好了。心情不好，啥都做不了。说是拥有了自己的全部时间，实际上这些时间都是垃圾时间，木有动力。周日就跑去找小启凡和熊熊玩耍了。。。</p><p>话说回来，上周说好的具体的时间表呢？？？光说不做假把式！这就列出来～我这个人，计划只有写在纸上才会执行，表示对自己很无奈。</p><p>另外一个感受是：需要给自己减压！！！如果我认为自己一天有十个小时来工作的话，最好只安排6个小时的工作量吧，别老给自己整15个小时的工作量。做事情的强迫症那么严重，不时会掉进一些细节里死抠。这是毛病，要改。不过还是给自己的强迫症留一些喘息空间，就不全改掉了，精致点挺好的。</p><h1 id="收获"><a href="#收获" class="headerlink" title="收获"></a>收获</h1><ul><li>一架电子琴！冲动消费冲动消费冲动消费！但是我好开心哇，哇咔咔咔咔。老公说得在理：要练起来哟～</li><li>一个最新版的ipad Air和apple pencil！昨晚老公说他发工资了，买给了我！太爱他了也。（呵，女人！什么时候能成熟点）</li><li>抖音和TikTok账号，并发布了俩小视频，让我嘚瑟一会儿。</li><li>咸蛋三人组一起剪视频时，发现自己的眼睛真小（这不是很多年前就发现了吗。。。）</li><li>十字编织法的熟练运用，以及另外两个旧物改造手工作品</li><li>bodycombat练到背部酸了四天。。。</li><li>写完了thesis的proposal</li><li>和某互联网公司聊了业务，即将进入谈薪资的部分。我还蛮想去那里工作的，最大的顾虑就是不能和老公在一起。怎么办</li><li>和老公在缺氧，以及文明6中各开了一个档。我俩在游戏中的家～</li></ul><h1 id="下周计划"><a href="#下周计划" class="headerlink" title="下周计划"></a>下周计划</h1><p>为了给自己减压，先把life放在第一位</p><h2 id="Life"><a href="#Life" class="headerlink" title="Life"></a>Life</h2><ul><li><input checked="" disabled="" type="checkbox"> 每天睡满八个小时（包括午觉哈）</li><li><input checked="" disabled="" type="checkbox"> 每个工作日留给运动一个小时的时间</li><li><input checked="" disabled="" type="checkbox"> 精心制作一款栗子泥</li><li><input checked="" disabled="" type="checkbox"> Game of throne. Season 6 Episode 9 10</li><li><input disabled="" type="checkbox"> Deutsch Vokabel: Everyday</li><li><input disabled="" type="checkbox"> Deutsch lernen: 2 episodes</li><li><input checked="" disabled="" type="checkbox"> Bodycombat 2次（周二和周五）</li><li><input checked="" disabled="" type="checkbox"> 缺氧<ul><li><input checked="" disabled="" type="checkbox"> 学会高压制氧</li><li><input checked="" disabled="" type="checkbox"> 学会小动物放牧</li></ul></li><li><input checked="" disabled="" type="checkbox"> 钢琴：<ul><li><input checked="" disabled="" type="checkbox"> 学会致爱丽丝</li><li><input checked="" disabled="" type="checkbox"> 学会另一首曲子</li></ul></li></ul><h2 id="Mathematical-Optimization"><a href="#Mathematical-Optimization" class="headerlink" title="Mathematical Optimization"></a>Mathematical Optimization</h2><p>进展顺利的话，本周应该可以看直播啦，而不是补录播。争取做到哦</p><ul><li><input checked="" disabled="" type="checkbox"> Video: 2020-11-2 (11.9)</li><li><input checked="" disabled="" type="checkbox"> Video: 2020-11-5 (11.10)</li><li><input checked="" disabled="" type="checkbox"> Video: 2020-11-9 (11.11)</li><li><input disabled="" type="checkbox"> Video: 2020-11-12 (11.12)</li><li><input disabled="" type="checkbox"> 总结之前所学的内容（11.13）</li></ul><h2 id="Thesis"><a href="#Thesis" class="headerlink" title="Thesis"></a>Thesis</h2><ul><li><input disabled="" type="checkbox"> coding<ul><li><input checked="" disabled="" type="checkbox"> snn的结果复现</li><li><input disabled="" type="checkbox"> hodgenet的模型pytorch重写</li><li><input checked="" disabled="" type="checkbox"> 生成其他数据集</li></ul></li><li><input disabled="" type="checkbox"> reading<ul><li><input checked="" disabled="" type="checkbox"> <a href="https://malllabiisc.github.io/publications/papers/nhp_cikm20.pdf">NHP</a></li><li><input checked="" disabled="" type="checkbox"> <a href="https://arxiv.org/pdf/1809.09401.pdf">hypergraph neural networks</a></li><li><input disabled="" type="checkbox"> <span class="github-emoji"><span>⭐</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span><a href="https://arxiv.org/pdf/1907.11577.pdf">Topological</a></li><li><input disabled="" type="checkbox"> Hodge-1 Laplacian and HodgeNet they only use Hodge-1 Laplacian, but we can define a new wavelet transform using geometric scattering and random walk matrix, check eq. 2 in <a href="https://arxiv.org/pdf/1810.03068.pdf">https://arxiv.org/pdf/1810.03068.pdf</a></li><li><input disabled="" type="checkbox"> 以及他们最新的改进 <a href="https://arxiv.org/pdf/2010.15010.pdf">https://arxiv.org/pdf/2010.15010.pdf</a></li></ul></li><li><input disabled="" type="checkbox"> task<ul><li><input disabled="" type="checkbox"> 最重要的任务：想清楚自己要做的方向</li><li><input disabled="" type="checkbox"> 把每篇读过的paper写个摘要</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Thesis </tag>
            
            <tag> Life </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weekly summary</title>
      <link href="/y2020w44-summary/"/>
      <url>/y2020w44-summary/</url>
      
        <content type="html"><![CDATA[<p>十月过去啦，马上就是十一月二日美国大选了！万众瞩目，坐等更新。这一周发生了蛮多事情的。今天借住的好朋友搬走了，又回到了一个人的卧室。法国的宗教暴力事件让人害怕。欧洲疫情的第二波高峰汹汹来袭，瑞士的每日新增人数达到了前所未有的高峰，这个八百万人口的国家，每日新增已经破九千了。学校健身房再次关门，所有课程改为线上。国家新政策：赴华旅客需要出示双阴性证明。（国外的检测效率和国内是没得比的）还有据说今年双十一的排场很大，各大卫视都在这两天搞起了晚会庆祝双十一。。。我置身事外，无动于衷。在周围众女生的安利下，种草了几款电视节目：梦想改造家，演员请就位，脱口秀大会。以后，工作之余可以用它们打发打发时间了。此外，秋招各大厂开奖了。美团很壕气，听说已经超越字节。算法岗“白菜价”为二三十万。</p><p>同屋室友走后，我真的要开始减肥了。</p><h1 id="计划回顾"><a href="#计划回顾" class="headerlink" title="计划回顾"></a>计划回顾</h1><p>上周计划的完成情况：</p><p>Mathematical Optimization: 80%. Incomplete tasks:</p><ul><li>Script: 18-37 (10.28)</li></ul><p>Graph Papers: 0%</p><p>Life: 72%. Incomplete tasks:</p><ul><li>Guitar: 七月上</li><li>Deutsch lernen: Episode 3</li><li>开始玩 我的世界</li></ul><p>总结：</p><p>想为自己的计划未完成找个借口，就是好朋友同住一屋，没办法严格根据自己的routine来。很多情况下，需要协调两个人的生活节奏。比如：早起之后，我不能在房间里运动，会打扰她睡觉。吃饭时间运动时间聊天时间玩耍时间都要相互协调。包括吃什么玩什么聊什么也不能完全顺遂自己的心意。晚饭之后，时间几乎都和她一起看综艺，玩游戏聊天唱歌了。不是说这样不好，在和同伴在一起的时候，很珍惜这些时光。不过，没有同伴时，自我独处的时间也很令人享受，能对自己行驶最大的控制权。</p><p>需要反思的是：为什么我额外的paper都没看呢？我还没在生活中养成一个看paper的习惯，没有这么一个时间，让我去浏览最新的paper。这个时间段应该安排在哪里？不如就晚饭后？下周试运行一下。</p><h1 id="收获"><a href="#收获" class="headerlink" title="收获"></a>收获</h1><p>上周尝试了很多新鲜的东西。第一次做了发糕，好好吃哇。</p><p><img src="20201101-4.jpeg" alt="cake"></p><p><img src="20201101-5.jpeg" alt="cake2"></p><p>周六和好闺蜜一起做了手工：一个插头收纳盒和一个衣物收纳架。我还是蛮嫌弃她的剪裁的，略粗糙。。。在精修之后，手工作品们已经投入使用。以后再慢慢包装它们。</p><p><img src="20201101-1.jpeg" alt="box"></p><p><img src="20201101-2.jpeg" alt="box2"></p><p><img src="20201101-6.jpeg" alt="box3"></p><p>近一年没拿过毛笔，今天小练了一哈。</p><p><img src="20201101-3.jpeg" alt="ca"></p><p>计划表里列在life中的任务，几乎都是周六周日在做了<span class="github-emoji"><span>😂</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f602.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span></p><p>额外收获：第一次自制蛋黄酱，沙拉的享受程度提升了好几个level。</p><h1 id="下周计划"><a href="#下周计划" class="headerlink" title="下周计划"></a>下周计划</h1><h2 id="Mathematical-Optimization"><a href="#Mathematical-Optimization" class="headerlink" title="Mathematical Optimization"></a>Mathematical Optimization</h2><p>这门课是11学分，课程内容还是很多的。加上我之前落下了将近一个月的进度，补课任务安排得还是蛮紧凑的。如果顺利按照进度走，再有两周就能把课补回来。在这之后，要好好地做作业。</p><ul><li><input checked="" disabled="" type="checkbox"> Video: 2020-10-19 (11.2)</li><li><input checked="" disabled="" type="checkbox"> Video: 2020-10-22 (11.3)</li><li><input checked="" disabled="" type="checkbox"> Video: 2020-10-26 (11.5)</li><li><input checked="" disabled="" type="checkbox"> Video: 2020-10-29 (11.6)</li><li><input disabled="" type="checkbox"> Script: 18-57 (11.4)</li></ul><h2 id="Thesis"><a href="#Thesis" class="headerlink" title="Thesis"></a>Thesis</h2><p>毕设的任务来得比我想象中的多。一起合作的博后idea来的很快，paper给的也很快，讨论的也很频繁。我原先读paper的方法需要进行的改善，来适应现在的节奏。如何跟上节奏，是接下来一周需要好好思考的议题。</p><p>需要阅读的paper list</p><ul><li><input disabled="" type="checkbox"> <a href="https://malllabiisc.github.io/publications/papers/nhp_cikm20.pdf">NHP</a></li><li><input disabled="" type="checkbox"> <a href="https://arxiv.org/pdf/1809.09401.pdf">hypergraph neural networks</a></li><li><input disabled="" type="checkbox"> <span class="github-emoji"><span>⭐</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span><a href="https://arxiv.org/pdf/1907.11577.pdf">Topological </a></li><li><input checked="" disabled="" type="checkbox"> Simplicial neural network</li><li><input checked="" disabled="" type="checkbox"> random walk on normalized hodge-1 laplacian</li><li><input disabled="" type="checkbox"> Hodge-1 Laplacian and HodgeNet they only use Hodge-1 Laplacian, but we can define a new wavelet transform using geometric scattering and random walk matrix, check eq. 2 in <a href="https://arxiv.org/pdf/1810.03068.pdf">https://arxiv.org/pdf/1810.03068.pdf</a></li><li><input disabled="" type="checkbox"> 以及他们最新的改进 <a href="https://arxiv.org/pdf/2010.15010.pdf">https://arxiv.org/pdf/2010.15010.pdf</a></li></ul><p>任务：</p><ul><li><input checked="" disabled="" type="checkbox"> 写一个proposal，concrete一些。加一些图，具体落地。</li><li><input disabled="" type="checkbox"> 把每篇paper写个摘要</li><li><input disabled="" type="checkbox"> 是否可以在simplicial complexes去尝试新的idea</li><li><input checked="" disabled="" type="checkbox"> 找一下smooth gradient flow 的来源</li></ul><h2 id="Life"><a href="#Life" class="headerlink" title="Life"></a>Life</h2><ul><li><input disabled="" type="checkbox"> Game of throne. Season 6<ul><li><input disabled="" type="checkbox"> Episode 9</li><li><input disabled="" type="checkbox"> Episode 10</li></ul></li><li><input disabled="" type="checkbox"> Deutsch Vokabel: Everyday</li><li><input disabled="" type="checkbox"> Deutsch lernen: 2 episodes</li><li><input checked="" disabled="" type="checkbox"> Running: every 2 day</li><li><input disabled="" type="checkbox"> Bodycombat：2 times</li><li><input checked="" disabled="" type="checkbox"> Food: <ul><li><input checked="" disabled="" type="checkbox"> 栗子泥</li><li><input checked="" disabled="" type="checkbox"> 三汁焖锅</li></ul></li><li><input disabled="" type="checkbox"> Fit：减重一公斤</li></ul>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Thesis </tag>
            
            <tag> Life </tag>
            
            <tag> Food </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weekly summary</title>
      <link href="/y2020w43-summary/"/>
      <url>/y2020w43-summary/</url>
      
        <content type="html"><![CDATA[<h1 id="计划回顾"><a href="#计划回顾" class="headerlink" title="计划回顾"></a>计划回顾</h1><p>上周<strong>未</strong>完成的计划：</p><p>Graph paper: 50%. </p><ul><li><input disabled="" type="checkbox"> MoNet</li><li><input disabled="" type="checkbox"> GraphSage</li><li><input disabled="" type="checkbox"> GAT</li></ul><p>Higher-order graph: 45.4%.</p><ul><li><input disabled="" type="checkbox"> Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks</li><li><input disabled="" type="checkbox"> <span class="github-emoji"><span>🌟</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> Simultaneous group and individual centralities. Phillip Bonacich. Soc. Netw., 13(2):155–168, 1991.</li><li><input disabled="" type="checkbox"> <span class="github-emoji"><span>⭐</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> Random walks and diffusion on networks, Physics Reports, N. Masuda, M. A. Porter, and R. Lambiotte, 2017.</li><li><input disabled="" type="checkbox"> <span class="github-emoji"><span>🌟</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>High-ordered random walks and generalized Laplacians on hypergraphs.  Linyuan Lu and Xing Peng. In International Workshop on Algorithms and Models for the Web-Graph, pages 14–25. Springer, 2011.</li><li><input disabled="" type="checkbox"> <a href="http://www.geometry.caltech.edu/pubs/dGDT16.pdf">http://www.geometry.caltech.edu/pubs/dGDT16.pdf</a></li><li><input disabled="" type="checkbox"> Discrete Connection and Covariant Derivative for Vector Field Analysis and Design (10.21)</li></ul><p>Optimization: 100%</p><p>Misc： 0%. </p><ul><li><input disabled="" type="checkbox"> <a href="https://archwalker.github.io/blog/2019/11/10/GNN-Go-Through-Main-Models.html">https://archwalker.github.io/blog/2019/11/10/GNN-Go-Through-Main-Models.html</a></li></ul><p>Video: 66.7%. </p><ul><li><input disabled="" type="checkbox"> Game of thrones: Season 6 <ul><li><input disabled="" type="checkbox"> Episode 6</li><li><input disabled="" type="checkbox"> Episode 7</li></ul></li></ul><p>Game: 90%.</p><ul><li><input disabled="" type="checkbox"> 隐形的守护者第十章</li></ul><p>总结：</p><ul><li>为什么有些任务全部完成了，有些任务几乎没有完成呢？我觉得原因可以分为以下几点：<ul><li>任务的可执行度上。比如：higher-order graph的论文阅读。我这里虽然列出了list，但是，list上的item之间<strong>缺乏联系</strong>。 我在读完一篇论文之后，可能心里存在很多疑问，此时与我的疑问最相关的论文并没有出现在list上，导致我不想沿着list去读。在读完list上的一篇论文之后，我不知道为什么要去读下一篇，list失去了引导力，致使我无法完成。与之相比，optimization的任务内部非常的连贯，我愿意按照它执行。</li></ul></li><li>Video这种娱乐性质的任务为什么没有完成？<ul><li><strong>习惯没有养成</strong>。我坚持的是routine指导行为的方法，绝不要忽视习惯的力量。而我现在的routine并没有建立起来，比如健身时间，休息时间，娱乐时间，都是散乱的。不过，鉴于这周小伙伴住在我房间里的情况，我不能太过任性，一味坚持自己的时间表，还需要适当考虑到她的生活习惯。习惯留待她离开之后再培养叭。</li></ul></li></ul><h1 id="收获"><a href="#收获" class="headerlink" title="收获"></a>收获</h1><p>本周在论文上的收获不大，在课程mathematical optimization收获更多些，坚持按计划学习了课程。此外，重新布置起自己的blog，在对blog进行修整之后，还要经营我和元元的blog哦～</p><p>周六和熊，小可爱，室友一起度过了12个小时，虽然这个时间预算对我来说有些超支了<span class="github-emoji"><span>😂</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f602.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>，完全没想到会和小伙伴玩这么久。不过元元有句话开导的很对“不要因为烦恼而影响玩耍时的快乐”，“很占据时间，又不能拒绝”时，我应该尽力去享受这段时间，而不是为被额外占据掉的时间焦虑。<strong>我对自己的时间真的很吝啬</strong>。其实反过来想想，对于与朋友在一起的时间，如果事先有个预期的话，我会舒服很多。害，说到底就是想尽可能地掌控。</p><h2 id="Mathematical-Optimization"><a href="#Mathematical-Optimization" class="headerlink" title="Mathematical Optimization"></a>Mathematical Optimization</h2><p>对于这次总结，我希望达到的目的不是复述知识，而是建立起知识之间的联系，突出要点。</p><p>经过复习，我发现我对以下内容掌握得不够：</p><ul><li>degenerate/degeneracy： 引入这个概念是为了干什么？</li></ul><p><img src="20201025Module.png" alt="Module"></p><p><img src="20201025Polyhedron.png" alt="Mindmap"></p><h2 id="Graph-models"><a href="#Graph-models" class="headerlink" title="Graph models"></a>Graph models</h2><p>本周的认识都是high-level的，没有基础知识的积累：GIN的那篇paper从现有的基于邻居消息传递的GNN框架的局限性出发，引起我思考：什么样的模型是基于这个框架的，除此之外还有哪些其他模型种类。各种基于Laplacian的模型是不是也基于这个邻居消息传递的？比如GCN，其实是根据Laplacian矩阵选择weighted的邻居的。</p><h1 id="下周计划"><a href="#下周计划" class="headerlink" title="下周计划"></a>下周计划</h1><h2 id="Mathematical-optimization"><a href="#Mathematical-optimization" class="headerlink" title="Mathematical optimization"></a>Mathematical optimization</h2><p>Video</p><ul><li><input checked="" disabled="" type="checkbox"> 10.5 (10.26)</li><li><input checked="" disabled="" type="checkbox"> 10.8 (10.27)</li><li><input checked="" disabled="" type="checkbox"> 10.12 (10.29)</li><li><input checked="" disabled="" type="checkbox"> 10.15 (10.30) (last 7 minutes)</li></ul><p>Script:</p><ul><li><input disabled="" type="checkbox"> 18-37 (10.28)</li></ul><h2 id="Graph-Papers"><a href="#Graph-Papers" class="headerlink" title="Graph Papers"></a>Graph Papers</h2><p>这周准备采取综述，书籍和最新论文相结合的模式来进行领域学习。学习的目的：</p><ul><li>了解图领域的主要任务</li><li>了解现有模型没有解决的问题</li><li>未来可能的发展方向是什么</li><li>如何把经典理论和现代nn的方法结合起来呢？</li><li><input disabled="" type="checkbox"> ICLR2021专栏：<ul><li><input disabled="" type="checkbox"> Graph-graph similarity network</li><li><input disabled="" type="checkbox"> how to find your friendly neighborhood: graph attention design with self-supervision</li><li><input disabled="" type="checkbox"> graph neural network pooling by edge cut</li></ul></li><li><input disabled="" type="checkbox"> NIPS专栏：<ul><li><input checked="" disabled="" type="checkbox"> （10.26） <span class="github-emoji"><span>🌟</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> Random walks on hypergraphs. Timoteo Carletti, Federico Battiston, Giulia Cencetti, and Duccio Fanelli. Phys. Rev. E, 101(2):022308, 2020. 及其周边</li><li><input disabled="" type="checkbox"> Path Integral Based convolution and pooling for graph neural networks</li><li><input disabled="" type="checkbox"> Convergence and Stability of GCN on Large Random graphs</li><li><input disabled="" type="checkbox"> Erdos Goes Neural: an Unsupervised Learning Framework for Combinatorial Optimization on Graphs</li><li><input disabled="" type="checkbox"> Learning Graph Structure With A Finite-State Automaton Layer</li></ul></li><li><input disabled="" type="checkbox"> KDD2020: GraphSTONE</li><li><input disabled="" type="checkbox"> 综述：<ul><li><input disabled="" type="checkbox"> <span class="github-emoji"><span>📖</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> The Emerging Field of Signal Processing on Graphs</li><li><input disabled="" type="checkbox"> <span class="github-emoji"><span>📖</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> Discrete Signal Processing on Graphs</li><li><input disabled="" type="checkbox"> <span class="github-emoji"><span>📖</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> <span class="github-emoji"><span>⭐</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> Introducing Hypergraph Signal Processing:Theoretical Foundation and Practical Applications</li><li><input disabled="" type="checkbox"> <span class="github-emoji"><span>📖</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>  Centralities in simplicial complexes. applications to protein interaction networks.Ernesto Estrada and Grant J Ross. 2018.</li><li><input disabled="" type="checkbox"> <span class="github-emoji"><span>📖</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>  Centrality measures in simplicial complexes, Daniel Herna ́ndez Serrano and Dar ́ıo Sa ́nchez G ́omez. 2019</li></ul></li></ul><h2 id="Life"><a href="#Life" class="headerlink" title="Life"></a>Life</h2><ul><li><input disabled="" type="checkbox"> Guitar: 七月上</li><li><input checked="" disabled="" type="checkbox"> 毛笔字一张</li><li><input disabled="" type="checkbox"> Deutsch lernen 看三集<ul><li><input checked="" disabled="" type="checkbox"> 1</li><li><input checked="" disabled="" type="checkbox"> 2</li><li><input disabled="" type="checkbox"> 3</li></ul></li><li><input checked="" disabled="" type="checkbox"> 权力的游戏：<ul><li><input checked="" disabled="" type="checkbox"> 第六季第五集</li><li><input checked="" disabled="" type="checkbox"> 第六集</li><li><input checked="" disabled="" type="checkbox"> 第七集</li></ul></li><li><input checked="" disabled="" type="checkbox"> 做一个南瓜发糕</li><li><input checked="" disabled="" type="checkbox"> 隐形的守护者玩完</li><li><input disabled="" type="checkbox"> 开始玩 我的世界</li></ul>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Thesis </tag>
            
            <tag> Life </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weekly summary</title>
      <link href="/y2020w42-summary/"/>
      <url>/y2020w42-summary/</url>
      
        <content type="html"><![CDATA[<p>本周总结：</p><p>初步了解了higher-order graph的一些模型，重点了解用simplicial complex进行建模的理论基础和实际案例。</p><p>主要入手的几篇论文：</p><ul><li>simplicial neural network：这篇文章在simplicial complex上定义了laplacian，进而根据卷积定理定义了convolution操作，融入到现有的神经网络框架中。</li><li>hodgenet：这篇文章关注于edge层面的hodge laplacian，把hodge laplacian融入到现有的网络框架中，解决edge相关的一些问题。 </li><li>random walk … normalized hodge laplacian：使用Hodge laplacian在边上定义random walk，来解决与边相关的一系列问题。</li></ul><p>十分推荐在理解simplicial complex的理论性质时，参考论文：HODGE LAPLACIANS ON GRAPHS。这篇论文的第二三四章主要讲解hodge的一些理论基础。由浅入深，其中第二章很容易理解，其他两章在第二章的基础上也可以理解。第五章讲证明，可以跳过。</p><p>此外，推荐一篇hyper场景下的综述文章：Networks beyond pairwise interactions: structure and dynamics。可以用作闲着的时候的读物。</p><p>个人感受，simplicial complex模型的局限性比较大，对item的要求严格，而且理论性质多应用于同度（k）的边之间，不适用于higher-order不一致的情况，而我认为后者可能才是主流。</p><p>解决的想法：使用hypergraph这个模型。对于higher-order的理论研究非常多，能不能遵循graph中的模型发展路径，将其类比迁移到hypergraph上？</p><p>下周的计划：</p><p>Graph Paper：</p><ul><li>normal graph, Goal: have a general idea of GNNs, implement all the following GNNs using DGL<ul><li><input checked="" disabled="" type="checkbox"> How Powerful are Graph Neural Networks? (10.23)</li><li><input checked="" disabled="" type="checkbox"> GCN</li><li><input checked="" disabled="" type="checkbox"> ChebyNet (10.20)</li></ul><strong>Unfinished</strong><ul><li><input disabled="" type="checkbox"> MoNet (10.21)</li><li><input disabled="" type="checkbox"> GraphSage (10.22)</li><li><input disabled="" type="checkbox"> GAT (10.22)</li></ul></li><li>higher-order graph<ul><li>Datasets: How to get the datasets we want? How to design tasks? See other papers.<ul><li><input checked="" disabled="" type="checkbox"> <a href="https://snap.stanford.edu/data/com-Amazon.html">Amazon dataset</a> to see how to get the triangle values? (10.20)</li><li><input checked="" disabled="" type="checkbox"> Other papers tasks. (10.20, 10.21)</li></ul></li><li><input checked="" disabled="" type="checkbox"> <span class="github-emoji"><span>🌟</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> A. R. Benson, D. F. Gleich, and J. Leskovec, Higher-order organization of complex networks, Science, 353 (2016), pp. 163–166. (10.20)<span class="github-emoji"><span>🌟</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span></li><li><input checked="" disabled="" type="checkbox"> Learning with hypergraphs: Clustering, classification, and embedding. Dengyong Zhou, Jiayuan Huang, and Bernhard Scho ̈lkopf.  NIPS2007. </li><li><input checked="" disabled="" type="checkbox"> <span class="github-emoji"><span>🌟</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> Random walks on hypergraphs. Timoteo Carletti, Federico Battiston, Giulia Cencetti, and Duccio Fanelli. Phys. Rev. E, 101(2):022308, 2020. (10.21)</li></ul><strong>Unfinished</strong><ul><li><p><input disabled="" type="checkbox">  <span class="github-emoji"><span>🌟</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> Simultaneous group and individual centralities. <strong>Phillip Bonacich</strong>. Soc. Netw., 13(2):155–168, 1991.</p></li><li><p><input disabled="" type="checkbox">  Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks</p></li><li><p><input disabled="" type="checkbox">  <span class="github-emoji"><span>⭐</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> Random walks and diffusion on networks, Physics Reports, N. Masuda, M. A. Porter, and R. Lambiotte, 2017.</p></li><li><p><input disabled="" type="checkbox">  <span class="github-emoji"><span>🌟</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>High-ordered random walks and generalized Laplacians on hypergraphs.  Linyuan Lu and Xing Peng. In International Workshop on Algorithms and Models for the Web-Graph, pages 14–25. Springer, 2011.</p></li><li><p><a href="http://www.geometry.caltech.edu/pubs/dGDT16.pdf">http://www.geometry.caltech.edu/pubs/dGDT16.pdf</a></p></li><li><p><input disabled="" type="checkbox">  Discrete Connection and Covariant Derivative for Vector Field Analysis and Design (10.21)</p></li></ul></li></ul><p>Optimization:</p><ul><li><input checked="" disabled="" type="checkbox"> September all lecture video and notes <ul><li><input checked="" disabled="" type="checkbox"> 10.20: 9.24</li><li><input checked="" disabled="" type="checkbox"> 10.21: 9.28</li><li><input checked="" disabled="" type="checkbox"> 10.22: 10.1</li></ul></li></ul><p>Video:</p><ul><li><input checked="" disabled="" type="checkbox"> Game of thrones: Season 6 <ul><li><input checked="" disabled="" type="checkbox"> Episode 5</li></ul></li><li><input checked="" disabled="" type="checkbox"> Deutsch lehrnen: 2-4</li></ul><p><strong>Unfinished</strong></p><p>Misc</p><ul><li><input disabled="" type="checkbox"> <a href="https://archwalker.github.io/blog/2019/11/10/GNN-Go-Through-Main-Models.html">https://archwalker.github.io/blog/2019/11/10/GNN-Go-Through-Main-Models.html</a></li></ul><p>Video:</p><ul><li><input disabled="" type="checkbox"> Game of thrones: Season 6 <ul><li><input checked="" disabled="" type="checkbox"> Episode 5</li><li><input disabled="" type="checkbox"> Episode 6</li><li><input disabled="" type="checkbox"> Episode 7</li></ul></li></ul><p>Game:</p><ul><li><input disabled="" type="checkbox"> 隐形的守护者</li></ul>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Thesis </tag>
            
            <tag> Life </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Background Knowledge of Paper Willnump</title>
      <link href="/sysml-willump/"/>
      <url>/sysml-willump/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="https://arxiv.org/abs/1906.01974">Willump</a></p><h2 id="Model-serving-system-MLaaS"><a href="#Model-serving-system-MLaaS" class="headerlink" title="Model serving system(MLaaS)"></a>Model serving system(MLaaS)</h2><p>机器学习作为一种服务。<a href="https://zhuanlan.zhihu.com/p/33357581">zhihu</a></p><h2 id="应用实例"><a href="#应用实例" class="headerlink" title="应用实例"></a>应用实例</h2><ul><li>Amazon ML平台： 完全自动化</li><li><a href="https://www.zhihu.com/question/263394266/answer/312114268">Amazon Sagemaker平台</a>: 内附对数据科学家的有用tips哦！</li><li>微软的Azure平台</li></ul><h2 id="平台架构"><a href="#平台架构" class="headerlink" title="平台架构"></a>平台架构</h2><p><a href="https://zhuanlan.zhihu.com/p/31056374">zhihu2</a></p><p>机器学习，本质上是一系列的数值计算，因此 TensorFlow 定位也不是一个深度学习库，而是一个数值计算库。</p><p>机器学习中的命令式（Imperative）编程接口，是把公式提前推导出来，然后像其他编程脚本一样根据代码顺序执行。而我们知道 TensorFlow 提供的是一种声明式（Declarative）的编程接口，通过描述计算图的方式来延后和优化执行过程。</p><p>设计一个针对机器学习全流程的基础架构平台，需要涵盖哪些功能呢？</p><ol><li>实现资源隔离。在一个共享底层计算资源的集群中，用户提交的训练任务不应该受到其他任务的影响，尽可能保证 CPU、内存、GPU 等资源隔离。</li><li>实现资源调度和共享。随着通用计算的 GPU 流行，目前支持 GPU 调度的编排工具也越来越多，而部分企业内还存在着 GPU  专卡专用的情况，无法实现资源的动态调度和共享，这必然导致计算资源的严重浪费。在设计机器学习平台时，需要尽可能考虑通用的集群共享场景，例如同时支持模型训练、模型存储以及模型服务等功能，可以对标的典例就是 Google Borg 系统。</li><li>平台需要有灵活的兼容性。目前机器学习业务发展迅速，针对不同场景的机器学习框架也越来越多，灵活的平台架构可以兼容几乎所有主流的应用框架，避免基础架构因为业务的发展而频繁变化。</li><li>需要实现机器学习场景下的 API 服务。针对机器学习的模型开发、模型训练和模型服务三个主要流程，我们可以定义提交训练任务、创建开发环境、启动模型服务、提交离线预测任务等 API，用熟悉的编程语言来实现 Web service 接口。</li></ol><p><a href="https://zhuanlan.zhihu.com/p/51522413">a good collection</a></p><h1 id="ML-inference-pipelines"><a href="#ML-inference-pipelines" class="headerlink" title="ML inference pipelines"></a>ML inference pipelines</h1><p>图片来自：<a href="https://zhuanlan.zhihu.com/p/39931551">知乎</a></p><p><img src="pipeline.jpg" alt="Machine Leanring Pipeline"></p><ol><li><p>原始数据经过数据的ETL处理，入库到数据仓里。  </p></li><li><p>上面蓝色部分代表机器学习：</p><ol><li>首先把样本数据与我们的自有数据进行匹配，</li><li>然后洞察这份数据并生成特征，这个过程叫特征工程。</li><li>接下来基于这些特征，选择合适的算法训练后得到模型，</li><li>最终把模型具体应用到全量的数据中，输出预测的结果。 </li></ol></li></ol><p>标准的机器学习工作流：针对业务上产生的具体问题，我们把它转化成数据问题，或者评估它能否用数据来解决。将数据导入并过滤后，我们需要将数据与业务问题和目标进行相关性分析，并根据具体情况对数据做二次处理。</p><p>下一步我们进行特征工程。从数据里找出跟目标有关的特征变量，从而构建或衍生出一些特征，同时要把无意义的特征剔除掉。我们大概需要花80%的时间在特征工程这个环节。</p><p>选出特征之后，我们会用逻辑回归和RNN等算法进行模型的训练。</p><p>接下来需要对模型做验证，判断其是否符合目标。不符合目标的原因有可能是数据和目标不相关，需要重新采集；也有可能是我们在探索的时候，工作不到位，因而需要对现有的数据重新探索，再进行特征工程这些步骤。如果最终模型符合业务预期，我们会把它应用在业务线上面。</p><h1 id="Model-Cascade"><a href="#Model-Cascade" class="headerlink" title="Model Cascade"></a>Model Cascade</h1><h1 id="Compile"><a href="#Compile" class="headerlink" title="Compile"></a>Compile</h1><h2 id="AST"><a href="#AST" class="headerlink" title="AST"></a>AST</h2><p><a href="https://zhuanlan.zhihu.com/p/102385477">zhihu</a> 这篇讲得非常好！</p><p>abstract syntax tree (抽象语法树)实际上是一个解析树（parse tree）的精简版本。</p><p>一棵解析树是包含代码所有语法信息的树型结构，它是代码的直接翻译。所以解析树，也被成为具象语法树（<strong>Concret Syntax Tree</strong>, 简称CST）;而抽象语法树，忽略了一些解析树包含的一些语法信息，剥离掉一些不重要的细节，所以它看起并不像解析树那么事无巨细，这也是AST名字中抽象一词的由来。</p><p>一些解析树和抽象语法树的不同之处:</p><ol><li>AST不含有语法细节，比如冒号、括号、分号</li><li>AST会压缩单继承节点</li><li>操作符会变成内部节点，不再会以叶子节点出现在树的末端。</li></ol><p>有了抽象语法树，我们基于它可以建立清晰的代码描述，非常有利于后续阶段的修改、变换。</p><h2 id="Weld"><a href="#Weld" class="headerlink" title="Weld"></a>Weld</h2><p><a href="https://zhuanlan.zhihu.com/p/56138380">zhihu</a></p><p>Weld 是一个用于数据计算的 Runtime，它的上层通常是一些计算框架，例如 Spark SQL、NumPy  等。用户用这些计算框架编写程序，这些框架将用户需要的计算翻译成 Weld 中间表示（IR），然后 Weld  对其进行一系列的优化，最后生成代码并编译运行。</p><p>就像 LLVM 的工作方式一样：各种语言的编译前端将高级语言翻译成 LLVM IR，LLVM 再对 IR 做一系列的优化，最后再编译成二进制。</p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul><li><strong>Weld IR 是声明式的</strong>：只表达计算流程，不包含具体的实现。比如下面会提到的 Builder，上层不需要指定用什么方式构建数组或是哈希表等数据结构，这些是由 Weld 优化器决定的；</li><li><strong>Weld IR 是 Lazy 的</strong>：只有当需要输出结果时，相应的 DAG 计算才会真正开始运行。</li></ul><h1 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h1><p><a href="https://www.zhihu.com/question/28300645/answer/67707287">zhihu question</a></p><p>推荐两个回答：刘允鹏和木头龙</p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Background Knowledge of Paper Privacy-preserving bandits</title>
      <link href="/sysml-p2b/"/>
      <url>/sysml-p2b/</url>
      
        <content type="html"><![CDATA[<p>Paper: <a href="https://arxiv.org/abs/1909.04421">Privacy-preserving bandits</a></p><h1 id="安全计算Secure-computation"><a href="#安全计算Secure-computation" class="headerlink" title="安全计算Secure computation"></a>安全计算Secure computation</h1><p><a href="https://zhuanlan.zhihu.com/p/31635977">zhihu</a></p><p>General idea: there is a function on all of data as the union of each owner’s data. Each owner doesn’t need to share or send his data to a common place to run the function but still can get the result from the function.</p><p>大家都不用把确切数据告诉别人（或曰：真实数据从未离开过自己），最后仍然能得到联合计算的结果。</p><p>安全计算适用于： 凡是一个计算任务需要用到来自多个参与者的数据，但各个参与者又不想（或不被允许）交换或公开数据。</p><h2 id="计算方法"><a href="#计算方法" class="headerlink" title="计算方法"></a><a href="https://zhuanlan.zhihu.com/p/31641175">计算方法</a></h2><ul><li><p>基于噪音的：基本思想：让原始数据淹没在噪音中，使别有用心者无法从得到的结果反推原始数据</p><p>噪音的增加方法：</p><ul><li>对输入数据加噪音</li><li>对模型参数加噪音</li><li>对输出加噪音</li></ul><p>评价：效率高，会伤害模型质量</p><ul><li><input checked="" disabled="" type="checkbox"> 会不会伤害模型的质量？会的。</li></ul></li><li><p>不基于噪音的：基本思想：通过密码学方法将数据编码或加密，得到一些奇怪的数字。这些数字保持了原始数据的某些关系。在源头上对数据加密或编码，计算操作方法看到的都是密文。主要包括三种方法</p><ul><li><a href="https://zhuanlan.zhihu.com/p/41172002">混淆电路（Garbled Circuit）</a></li></ul></li><li><p><a href="https://zhuanlan.zhihu.com/p/77478956">同态加密（Homomorphic Encryption）</a></p><ul><li>RSA：支持的是同态乘法</li></ul></li><li><p><a href="https://zhuanlan.zhihu.com/p/44999983">密钥分享（Secret Sharing）</a></p></li></ul><p>评价：不会对计算过程加干扰。缺点：使用了很多密码学方法，计算量通讯量庞大。对于复杂的任务，短时间内可能无法完成。</p><h1 id="差分隐私Differential-Privacy"><a href="#差分隐私Differential-Privacy" class="headerlink" title="差分隐私Differential Privacy"></a>差分隐私Differential Privacy</h1><p><a href="https://zhuanlan.zhihu.com/p/40760105">zhihu</a></p><p>保护的是数据源中一点微小的改动导致的隐私泄露问题。比如有一群人出去聚餐，那么其中某人是否是单身狗就属于差分隐私。</p><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><h3 id="相邻数据集"><a href="#相邻数据集" class="headerlink" title="相邻数据集"></a>相邻数据集</h3><p>现给定两个数据集D和D’, 若它们有且仅有一条数据不一样，那我们就称此二者为相邻数据集。</p><h3 id="算法能达到差分隐私的效果"><a href="#算法能达到差分隐私的效果" class="headerlink" title="算法能达到差分隐私的效果"></a>算法能达到差分隐私的效果</h3><ul><li>对于一个随机化算法 $A$ <ul><li>所谓随机化算法，是指对于特定输入，该算法的输出不是固定值，而是服从某一分布</li></ul></li><li>其分别作用于两个相邻数据集</li><li>得到的两个输出分布难以区分：得到一个特定输出的概率差不多。$\Pr[A(D)=O]\leq e^\epsilon \Pr[A(D’)=O]$​</li></ul><h3 id="放松版定义"><a href="#放松版定义" class="headerlink" title="放松版定义"></a>放松版定义</h3><p>有delta：$\Pr[A(D)=O]\leq e^\epsilon \Pr[A(D’)=O] + \delta$​</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><ul><li>加噪音<ul><li>拉普拉斯噪音：由于拉普拉斯分布的数学性质正好与差分隐私的定义相契合</li><li>高斯噪音：针对于放松版的差分隐私。</li></ul>评价：噪音会伤害模型。特别是数据量小的情况下，噪音的影响会很大。</li></ul><h1 id="Bandit"><a href="#Bandit" class="headerlink" title="Bandit"></a>Bandit</h1><p>内容来自：<a href="https://zhuanlan.zhihu.com/p/21388070">zhihu</a> <a href="https://zhuanlan.zhihu.com/p/35753281">zhihu2</a></p><h2 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h2><p>多臂赌博机问题：一个赌徒，要去摇老虎机，走进赌场一看，一排老虎机，外表一模一样，但是每个老虎机吐钱的概率可不一样，他不知道每个老虎机吐钱的概率分布是什么，那么想最大化收益该怎么整？</p><p>在计算广告和推荐系统领域，针对这个问题，还有个说法叫做EE问题：exploit－explore问题。</p><ul><li><p>exploit意思就是：比较确定的兴趣，当然要用啊。好比说我们已经挣到的钱，当然要花啊；</p></li><li><p>explore意思就是：不断探索用户新的兴趣才行，不然很快就会出现一模一样的反复推荐。就好比我们虽然有一点钱可以花了，但是还得继续搬砖挣钱啊，不然花完了喝西北风啊。</p></li></ul><h2 id="评价标准"><a href="#评价标准" class="headerlink" title="评价标准"></a>评价标准</h2><p>累积遗憾：</p><p>$$<br>R_T=\sum_{i=1}^T (w_{opt}-w_{B(i)})<br>$$</p><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><ul><li><p>Thompson sampling：每次选择臂的方式是：用每个臂现有的beta分布产生一个随机数b，选择所有臂产生的随机数中最大的那个臂去摇。</p></li><li><p>UCB算法（全称是Upper Confidence Bound（置信区间上界））：就是以收益（bonus）均值的置信区间上限代表对该arm未来收益的预估值。</p><blockquote><p> 置信区间可以简单地理解为不确定性的程度，区间越宽，越不确定，反之亦反之。</p><blockquote><p>每个item的回报均值都有个置信区间，随着试验次数增加，置信区间会变窄（逐渐确定了到底回报丰厚还是可怜）。</p><p>每次选择前，都根据已经试验的结果重新估计每个item的均值及置信区间。</p><p>选择置信区间上限最大的那个item。</p></blockquote></blockquote><p>做法：每次先对每一个臂都试一遍，然后选择以下值最大的那个臂：</p><p>$$<br>\bar{x}<em>j (t) + \sqrt{ \frac{2 \ln t}{T</em>{j,t} } }<br>$$</p><ul><li>$x_j(t)$：这个臂$j$到目前的收益均值，即对臂$j$期望收益的预估</li><li>$t$：截止到目前总的试验次数</li><li>$T_{j,t}$: 臂$j$被试到的次数</li></ul><p>诠释：</p><ul><li>前一项触发exploitation机制，均值（期望收益）越高，被选中的概率越大</li><li>后一项触发exploration机制，累积被选中的次数越少，之后被选中的概率越大</li></ul></li><li><p>Epsilon-greedy算法：</p><p>做法：选一个(0,1)之间较小的数epsilon ，每次以概率epsilon（产生一个[0,1]之间的随机数，比epsilon小）做一件事：所有臂中随机选一个。否则，选择截止当前，平均收益最大的那个臂。</p><p>epsilon的值可以控制对Exploit和Explore的偏好程度。越接近0，越保守。</p></li><li><p>完全朴素的算法：先试几次，每个臂都有了均值之后，一直选均值最大那个臂。这个算法是我们人类在实际中最常采用的。</p></li><li><p>LinUCB: <a href="https://zhuanlan.zhihu.com/p/35753281">zhihu3</a> </p><ul><li>启发：UCB这样的context-free类算法，没有充分利用推荐场景的上下文信息，为所有用户的选择展现商品的策略都是相同的，忽略了用户作为一个个活生生的个体本身的兴趣点、偏好、购买力等因素都是不同的，因而，同一个商品在不同的用户、不同的情景下接受程度是不同的。</li><li>特点：<ul><li>加入了用户和物品的特征，即context。</li><li>收益是特征的线性函数：Lin(linear): $\mathbb{E}[r_{a,t}|x_{a,t}]=x_{a,t}^\top \theta_a$ <ul><li>$x_{a,t}$是每个老虎机的特征</li><li>$\theta$​ 是模型的参数，每个老虎机维护一个$\theta$</li><li>使用每个老虎机的前$m$个特征向量$x$和遗憾值$r$，用岭回归的方法，可以求解$\theta$</li></ul></li></ul></li></ul></li></ul><p>算法分类：</p><ul><li>context-free:Thompson sampling, UCB, Epsilon-greedy, naive</li><li>contextual: LinUCB</li></ul><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><ul><li><p>推荐系统冷启动问题：</p><blockquote><p>用分类或者Topic来表示每个用户兴趣，我们可以通过几次试验，来刻画出新用户心目中对每个topic的感兴趣概率。</p><p>这里，如果用户对某个topic感兴趣，就表示我们得到了收益，如果推给了它不感兴趣的topic，推荐系统就表示很遗憾(regret)了。</p><p>当一个用户来了，针对这个用户，我们用Thompson算法为每一个topic采样一个随机数，排序后，输出采样值top N 的推荐item。注意，这里略有改动，原始多臂问题每次只摇一个臂，我们这里一次摇N个臂。</p><p>获取用户的反馈，比如点击。没有反馈则更新对应topic的lose值，点击了则更新对应topic的wins值。</p></blockquote></li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Security </tag>
            
            <tag> Privacy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SysML提前看</title>
      <link href="/sysml-ti-qian-kan/"/>
      <url>/sysml-ti-qian-kan/</url>
      
        <content type="html"><![CDATA[<p>机器学习本质上是一系列的数值计算。当需要计算的数据量很大或者计算模型很大时，就需要设计一个合适的平台来进行这种计算。机器学习系统就是针对此方面的研究，即开发一类特殊的系统，用于支持和部署机器学习模型。</p><p>在本篇提前看中，我们从不同的角度选择三篇文章，以求对机器学习与系统（Machine Learning and  Systems）领域有多面的了解。其中，第一篇文章对机器学习系统制定了一套具备一般性的工业衡量标准，第二篇文章从模型部署层面对机器学习模型进行加速，主要解决瓶颈是特征计算的问题，第三篇文章则针对一个特定应用场景——大量依赖隐私数据的机器学习任务设计了一个权衡隐私传输与模型效果的系统。</p><p>论文列表：</p><ol><li>MLPerf Training Benchmark</li><li>WILLUMP: A Statistically-Aware End-To-End Optimizer For<br>Machine Learning Inference</li><li>Privacy-Preserving Bandits</li></ol><h1 id="1-MLPerf-Training-Benchmark"><a href="#1-MLPerf-Training-Benchmark" class="headerlink" title="1. MLPerf Training Benchmark"></a>1. MLPerf Training Benchmark</h1><ul><li>论文链接：<a href="https://arxiv.org/pdf/1910.01500.pdf">https://arxiv.org/pdf/1910.01500.pdf</a></li><li>Github链接：<a href="https://github.com/mlperf/training">https://github.com/mlperf/training</a></li><li><a href="../SysML-P2B/index.html">补充背景知识</a></li></ul><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>日趋复杂的机器学习算法和庞大的数据量对真正运行模型的系统提出了一系列的挑战，在这篇文章的工作之前，业界尚未存在一套针对机器学习系统具备工业级别的衡量标准。然而，纵观各个领域的发展，这样的一套标准不仅能起到具有说服力的比较效果，更能促进创新，推动科研和工业界的发展。由此，来自谷歌，百度，斯坦福大学，哈佛大学等众多业界和学界的研究人员共同合作，克服了在衡量机器学习系统的各种独特难题，定义了一套衡量基准MLPerf。</p><p>该论文总结分析了衡量训练机器学习的系统的各种挑战，针对各种机器学习任务（如：图像分类，目标检测，机器翻译，强化学习等）给出不同的衡量标准，并附有详细的使用指南。</p><h2 id="设计难点"><a href="#设计难点" class="headerlink" title="设计难点"></a>设计难点</h2><p>一个训练机器学习的系统的工作流程抽象而言就是：系统输入端接受选定的数据集，优化器，模型，然后在系统上运行该模型直到模型质量（比如：图片分类的精确度）达到预期水平。选择一个系统，便要在训练后的模型质量和系统各方面的表现之间做出权衡。</p><p>那么，衡量训练机器学习的系统相较于一般的计算机系统，有哪些独特的挑战呢？</p><ol><li>系统优化对系统表现与模型质量的不同影响。系统层面的优化可能在短期提高系统的表现性能，却会最终伤害到训练的模型的质量。这就要求，系统必须运行完整个训练过程才能判断模型是否达标，而不能只根据短时间的吞吐量进行优劣评估。</li><li>并行化训练规模的双重影响。在大型分布式计算场景中，为了增加数据并行度和系统利用率，常常使用大的批量规模（batchsize）。这反过来要求调整模型的优化参数来保证模型性能，比如学习率（learning rate）（可参考文末引用1）。而这些参数的调整却可能对模型训练时间带来负面影响。简言之就是，大批量规模减少了每次训练的时间，却增加了所需的训练次数。</li><li>模型中的随机性引起的系统表现的差异。即使是相同的模型和超参数，在不同的训练会话（session）中也可能需要不同的迭代次数以达到相同的准确度。这些差异为可信地比较系统表现带来了挑战。</li><li>不同的软件环境的影响。不同软件框架，不同的数学计算表达，编程界面等诸多因素都可能影响一个系统的表现。</li></ol><h2 id="衡量标准"><a href="#衡量标准" class="headerlink" title="衡量标准"></a>衡量标准</h2><p>MLPerf的整体思路是，根据不同的机器学习训练任务，让系统运行预先规定的数据集，模型，测量其使训练模型达到特定性能后的训练时间。目前所涵盖的机器学习任务有：图片分类，目标监测，实例分割与目标检测，翻译（循环与非循环神经网络），推荐和强化学习。图示为0.5版本，当前已更新至0.6版本。</p><p><img src="mlperf1.png" alt="MLPerf0.5 版本训练基准"></p><p>为了尽可能排除模型本身的造成的系统表现差异，MLPerf规定了作为测试基准的数据集，模型和标准阈值，同时附有模型的参考实现和超参数设置。</p><p>就如何测量训练时间，MLPerf也从测量时间的构成和结合多次测量两个方面给出了详细说明。</p><ul><li>时间构成方面，系统的初始化时间，20分钟以内的模型创建和初始化时间等不包括在内。</li><li>由于机器学习任务的训练时间有相当大的随机性，MLPerf 的最终训练结果是由指定多次的基准测试时间在去掉最低和最高值后平均得出的。</li></ul><h2 id="提交与结果"><a href="#提交与结果" class="headerlink" title="提交与结果"></a>提交与结果</h2><p>MLPerf的测试根据专区和系统类型进行分类。其中，专区有两种：封闭式和开方式。封闭式要求必须使用基准中规定的模型（或与之等价的模型），参数初始化，数据集，超参数等，以求尽可能公平地对比各个硬件/软件系统。开放式的测试专区则侧重于鼓励创新，允许使用不同的模型架构，优化过程等。</p><p>系统类型分为三种：可获取类，预览类和研究类。根据软硬件的可获取程度进行区分。做这一类型上的区分也是为了鼓励创新和便于横向比较。后期会增加云系统的测量。</p><p>MLPerf测试的最终结果不是一个单一得分，而是系统在各个不同任务中测试的加速比。加速比即模型在该系统下的测试时间与基础系统的测试时间的比值。这一设定考虑到了不同任务的差异悬殊的训练时间。</p><p>目前，MLPerf已发布了训练基准0.5和0.6两个版本，来自业界和学界的超过五十个机构参与到了MLPerf测试竞赛中。相信这一标准将会极大促进行业竞赛，激励创新。</p><h1 id="2-WILLUMP-A-Statistically-Aware-End-To-End-Optimizer-For-Machine-Learning-Inference"><a href="#2-WILLUMP-A-Statistically-Aware-End-To-End-Optimizer-For-Machine-Learning-Inference" class="headerlink" title="2. WILLUMP: A Statistically-Aware End-To-End Optimizer For Machine Learning Inference"></a>2. WILLUMP: A Statistically-Aware End-To-End Optimizer For Machine Learning Inference</h1><p>论文链接：<a href="https://arxiv.org/abs/1906.01974">https://arxiv.org/abs/1906.01974</a></p><p><a href="../SysML-Willump/index.html">补充背景知识</a></p><h2 id="引言-1"><a href="#引言-1" class="headerlink" title="引言"></a>引言</h2><p>机器学习作为一种服务正在受到越来越多的关注。随着Amazon的Sagemaker，Microsoft的 AzureML众多机器学习计算平台被人们熟知和使用，机器学习正在成为一项门槛更低，推广度更高的服务。本文专注于机器学习推理中——即模型已经训练完成，将直接用于对新数据进行预测——的系统优化问题。机器学习模型一旦被训练好，实际上就是一个数据转化器：将用户输入经过格式转化，特征计算，模型计算等，最后得到输出预测。推理流水线常直接作为用户端的服务，因此要求低延迟，高吞吐，在负载尖峰时也要保证一定的性能。据研究，在推理服务中，特征计算是一个重要的瓶颈问题。这篇论文设计了一套端到端的推理流水线优化Willump，着力于加速特征计算，增加系统响应性能。</p><h2 id="优化流程及原理"><a href="#优化流程及原理" class="headerlink" title="优化流程及原理"></a>优化流程及原理</h2><p>Willump提供了两种任务的优化方法：1. 分类预测，2. top-k排名。</p><h3 id="级联优化"><a href="#级联优化" class="headerlink" title="级联优化"></a>级联优化</h3><p>针对分类任务，Willump采用了一种“区别对待”的思想，即搭建一个级联模型：结合原有模型和一个使用特征更少，计算更快的简单模型。对于每一个新的输入，先对其的部分特征在简单模型上进行快速计算，并根据输出结果的置信度决定是否使用原来的模型进行更为复杂的计算。流程如图所示：左边为原来的模型推理流水线，右边为Willump优化后的流水线。</p><p><img src="willump1.png" alt="Willump 的级联优化"></p><p>如何决定从所有的特征中选择哪一部分进行简单模型的训练呢？Willump的目标是选择一部分对预测很重要，但是计算开销又不大的特征。但直接计算所有特征的组合，并评估它们各自模型的精确度显然在计算层面是不可行的。于是，Willump使用了一个trick：</p><ol><li>首先根据计算独立的要求对所有的特征进行分组。计算独立性可用常规的编译技术解析出数据转换树得到。</li><li>接着，针对每一组特征，Willump计算两个统计量：计算花销和排列重要性（permutation importance）。后者是用来衡量一组特征对预测结果重要程度的常用方法。</li><li>最后，设定特征计算所允许的最大开销，从独立的特征组中选取使排列重要性和最大的组合。这就将原目标转化为一个knapsack问题，可用动态规划进行求解。</li></ol><h3 id="Top-K优化"><a href="#Top-K优化" class="headerlink" title="Top-K优化"></a>Top-K优化</h3><p>针对Top-K排名问题，Willump依然采取“区别对待”的思想：主要资源用于计算可能性大（排名可能更靠前）的对象，少数资源用于计算可能性小的对象。实现起来就是：Willump首先训练一个近似的模型，用于快速过滤掉得分低的对象，再把未被淘汰的对象送给原模型进行评分，对它们进行排名，从中得到Top K。</p><p>如何训练一个近似的模型呢？Willump依然试图确定一部分“最优的特征”，并在这组特征上训练一个近似的模型。不同于前述方法，这里”最优“的定义有所变化。给定一个Top K预测的准确率要求，给定一部分特征，可以计算出在这部分特征上多大的数据量（设定为N）能以预设的准确率覆盖Top K。最优意味着N/K的值最小。直观上说，就是没被这组特征过滤掉的数据量尽可能地少，尽可能地接近K。当然，在搜索特征组的时候，依然以最大的计算开销为限制进行搜索。</p><p>总体而言，Willump的工作流程包括三个阶段：</p><ol><li>数据流阶段：将原有的机器推理流水线转化为转换图。</li><li>优化阶段：使用级联/Top-K的优化方法。</li><li>编译阶段：将优化后的图转化会程序函数，交给Weld等优化系统进行编译。</li></ol><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>论文针对级联优化和Top-K优化分别进行实验，使用系统吞吐量，延迟和模型的准确度进行结果衡量。</p><p>实验使用了七种不同的数据集，分别来自数据科学竞赛平台CIKM, Kaggle和WSDM。数据集包括分类与回归两个类别，所用的机器学习模型包括：线性模型，GBDT，Ensemble和NN。</p><p>表格显示了数据集的详细信息，图片给出了特征与输入间的计算依赖关系。</p><p><img src="willump2.png" alt="Willump 使用的基准数据集"></p><p><img src="willump3.png" alt="所有基准数据集的转换图。白色：输入，黑色：转换节点，灰色：模型。"></p><h3 id="级联优化-1"><a href="#级联优化-1" class="headerlink" title="级联优化"></a>级联优化</h3><p>级联优化针对前五个分类任务的数据集，在Weld平台上进行编译，对比展示了Python源代码的吞吐量和延迟，直接用Weld平台编译后的吞吐量和延迟，以及Weld+Willump优化后的吞吐量和延迟。同时，给出Willump选定的特征组优化的模型精确度。</p><p><img src="willump4.png" alt="Willump 在离线批查询上的吞吐量表现"></p><p><img src="willump5.png" alt="Willump 在线上点查询上的延迟累积分布函数"></p><p><img src="willump6.png" alt="吞吐量与精确度的对比图。蓝色标注原始模型，红色标注 Willump 选定的级联阈值，橙色标注近似模型。"></p><p>综上，在精确度损失0.1%的范围内，级联优化的吞吐量相较于原Python程序最高达到16倍加速，相较于经Weld优化后的程序，仍可达到最高5倍的加速。级联优化的延迟也有显著减小。</p><h3 id="Top-K优化-1"><a href="#Top-K优化-1" class="headerlink" title="Top-K优化"></a>Top-K优化</h3><p>在Top-K优化的实验设置中，K设定为20，覆盖精确度设定为95%，使用的编译优化平台为Clipper。吞吐量优化结果如图所示。</p><p><img src="willump7.png" alt="Willump 在 Top-K 优化中的吞吐量表现"></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>Willump针对机器推理流水线中的特征计算进行优化，它开创性地利用了特征对模型结果影响的统计信息，通过结合更简单的模型和原有模型，在分类问题和Top-K问题上展示出系统吞吐量和延迟上的显著改善。它是一个位于Python端与编译平台中间的优化方法，在多个编译优化平台上均取得显著提升效果。</p><h1 id="3-Privacy-Preserving-Bandits"><a href="#3-Privacy-Preserving-Bandits" class="headerlink" title="3. Privacy-Preserving Bandits"></a>3. Privacy-Preserving Bandits</h1><p>论文链接：<a href="https://arxiv.org/abs/1909.04421">https://arxiv.org/abs/1909.04421</a></p><h2 id="引言-2"><a href="#引言-2" class="headerlink" title="引言"></a>引言</h2><p>在计算广告和推荐系统领域，一个典型应用是针对用户进行个性化推荐。用多臂赌博机模型来描述这个问题，就是将每一个待推荐的物品看作一个赌博机，在将此推荐给这个用户前，并不知道会获得多大的收益。那么每次推荐时，该如何选择一个赌博机呢？更进一步，如果考虑到不同用户具有不同特征，即同一个物品推荐给不同的用户会带来不一样的收益，又该怎样设计算法来最大化收益呢？这类问题被抽象为与情景有关的赌博机（contextual bandit）问题。LinUCB算法是解决这类问题的一个典型算法，它利用了用户特征和物品特征，训练模型进行推荐。收集到越多的用户数据，越有利于模型进行更精确，收益更高的推荐。</p><p>但是，在这个面向诸多个体的问题情境中，又涉及了一个重要的研究课题：隐私保护。很多情况下，为了保护用户数据的隐私，并不能将每个终端模型的数据信息全数汇总，以更新模型参数（比如：物品的特征）。最大化收益要求尽可能多的用户数据，隐私保护又限制了用户数据的传输。如何在隐私保护与模型效果中间权衡取舍就是本论文研究的中心问题。</p><p>本论文提出了一个系统P2B（privacy-preserving bandits隐私保护赌博机）。该系统能在用户本地端运行，并能使中心模型通过特定的方式收集各个用户端的数据，同时提供一定程度的隐私保证。</p><h2 id="P2B系统架构和原理分析"><a href="#P2B系统架构和原理分析" class="headerlink" title="P2B系统架构和原理分析"></a>P2B系统架构和原理分析</h2><p>P2B系统的主要架构是：</p><ul><li>本地代理对用户的数据进行加密，并选择性地上传，</li><li>洗牌机（位于用户端和中心服务器之间）：收集一定数量的加密后的用户数据，进行匿名化处理，重新洗牌，并将达到阈值数量的数据上传到中心服务器。</li><li>中心服务器：利用洗牌机发来的数据进行模型更新，并将更新后的模型发回各个本地用户端。</li></ul><p>详情如图所示：<img src="p2b1.png" alt="P2B 系统架构"></p><p>在整个系统中，为了保证用户隐私，作者设计了多个精巧的操作。</p><ul><li>本地代理随机地上传数据。更准确地说，对于每一条加密后的用户数据，本地代理以概率p决定上传该数据。概率值p直接影响到模型最后的效果。参考差分隐私的定义，直观上说，即当输入数据集中的一个数据点发生改变时，模型输出会发生多大的改变。</li><li>本地编码方式：先将原有的d维用户特征向量归一化，用精度为q的数字表示，并将编码后的向量通过k-means聚类到k个类中，用{0,…,k-1}进行编码表示。这一操作可以让相似的用户有相同的编码。</li><li>洗牌机选择上传超过给定阈值数量l的编码数据。这一阈值的选择保证了群体混合隐私。</li></ul><p>对隐私分析的理论结果如图：</p><p><img src="p2b2.png" alt="隐私分析的理论结果"></p><p>对于上述$\epsilon$和$\sigma$直观上的理解是：对于所有与原数据集相邻的数据集（有一个数据点不同），以$1-\delta$的概率保证隐私的绝对损失在$\epsilon$限制内。</p><h2 id="实验结果-1"><a href="#实验结果-1" class="headerlink" title="实验结果"></a>实验结果</h2><p>论文中共设置了三种实验模式：冷启动（百分百隐私保证），热启动+无隐私（用户上传全部数据）和热启动+隐私（P2B系统的应用，用户上传部分编码后的隐私数据）。分别在多标签的分类任务和在线广告场景中进行对比实验。其中分类任务采用准确率作为衡量标准，在线广告场景中采用点击通过率（CTR）作为衡量标准。实验所使用的采样概率p为0.5.</p><p><img src="p2b3.png" alt="P2B 综合基准测试：（上）A=10，（中）A=20，（下）A=50."></p><p>上图展示了在用户可采取的行为数量（A）不同的环境下，平均回报与系统参与用户的数量的关系。可以看出，在冷启动（用户不分享数据的情况下），模型的平均回报与用户数量无显著关系。而在热启动的情况下，二者存在显著的正相关。</p>]]></content>
      
      
      <categories>
          
          <category> Reading Summary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Machine Learning </tag>
            
            <tag> Security </tag>
            
            <tag> Privacy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PAI7 Reinforcement Learning</title>
      <link href="/pai-07/"/>
      <url>/pai-07/</url>
      
        <content type="html"><![CDATA[<p>The data is assumed to be drawn from some distributions. In reinforcement learning, we learn by interacting with environment. For example, one agent could perform some actions, and these actions will give him different rewards. He wants to learn how to take actions. One big issue is that the reward is based on a sequence of actions, not only one action. Considering the case that a sequence of actions leads to some reward, how to figure out exactly which action is responsible for this reward. Generally, it is impossible. We need some assumptions.</p><h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>RL = planning in unknown MDPs. </p><ul><li>not know the transition probability</li><li>not know the rewards</li><li>may not even know the states.</li></ul><p>In this way, how to come up a policy to react?</p><p>A central object is the value function. In order to solve MDPs, we need to solve the value function.</p><p>Difference from supervised learning:</p><ul><li>in RL, the data we get depends on what we did. The data is not i.i.d.</li><li>what we do will affect what we learn</li><li>have rewards. Not only achieve to learn a good model, but also a good policy to how to act to get a good reward.</li></ul><p>Main tasks:</p><ul><li>explore: how to act to get more knowledge of the world?</li><li>exploit: once knowing the world, how to act to get a good reward?</li></ul><p>Types:</p><ul><li>on-policy RL: agents have full control over which actions to pick</li><li>off-policy RL: agents have no control over actions, only gets observational data. </li></ul><h1 id="Assumptions"><a href="#Assumptions" class="headerlink" title="Assumptions"></a>Assumptions</h1><ul><li><p>Markovian: the actions only depend on the current state, instead of past states.</p></li><li><p>finite states</p></li><li><p>finite actions</p></li></ul><h1 id="Approaches"><a href="#Approaches" class="headerlink" title="Approaches"></a>Approaches</h1><ul><li>model-based RL:<ol><li>learn the MDP<ul><li>estimate the transition probabilities $P(x’|x,a)$</li><li>estimate reward function $r(x,a)$</li></ul></li><li>optimize policy based on estimated MDP</li></ol></li><li>model-free RL:<ul><li>jump the transition probabilities, or reward function, but directly to estimate, what we need to learn to make a policy, <em>the value function</em></li><li>policy gradient methods: constraint to some specific families of policy. Turn into an optimization problem.</li><li>actor-critic methods: combine both of them: create values, limit to some families of policies.</li></ul></li></ul><h2 id="Model-based"><a href="#Model-based" class="headerlink" title="Model-based"></a>Model-based</h2><p>The data set looks like: $x_1,a_1,r_1,x_2,a_2,r_2,\cdots$  given an observation $x_i$, take an action $a_i$ and get a reward $r_i$, which leads to the next observation $x_{i+1}$.</p><p>Elements: $(x_i,a_i,r_i,x_{i+1})$ are independent from each other.</p><p>$D = {(x_i,a_i,r_i,x_{i+1})},$ expressed in this way, we can do counting on the elements.</p><p>MDP can be viewed as controlled Markov chain. </p><ul><li><p>estimate transitions MLE:</p><p> $$<br> \Pr[X_{t+1}|X_t,A]\simeq\frac{Count(X_{t+1},X_t,A)}{Count(X_t,A)}<br> $$</p></li><li><p>estimate rewards:</p><p> $$<br> r(x,a)\simeq\frac{1}{N_{x,a}}\sum_{t:X_t=   x,A_t=   a}R_t<br> $$</p></li></ul><p>How accurate could the estimation be? More data will give more accurate estimations.</p><h3 id="Trade-off-exploration-and-exploitation"><a href="#Trade-off-exploration-and-exploitation" class="headerlink" title="Trade-off exploration and exploitation"></a>Trade-off exploration and exploitation</h3><ul><li><p>pick a random action</p><ul><li>exploration: will eventually correctly estimate all probabilities and rewards.</li><li>exploitation: may do extremely poorly in terms of rewards. Because each action is independent from others, not a “good” policy</li></ul></li><li><p>pick the currently “best” action</p><ul><li>exploration: can get stuck in suboptimal actions, local best</li><li>exploitation: can yield some reward.</li></ul></li><li><p>combination these two, using <strong>randomized</strong> strategies, called epsilon-greedy.</p><ul><li>with probability epsilon: pick a random action</li><li>with probability 1-epsilon: pick the best action.</li></ul><p>If epsilon satisfies some condition, it will converge to optimal policy with probability 1.</p><p>Condition: <strong>Robbins Monro condition</strong> </p><ul><li>Potential issue: the random action doesn’t rule out purely bad actions.</li></ul></li><li><p>The Rmax algorithm: the principle is <em>optimism in the face of uncertainty</em>. When an action is unknown, try it!</p><p>Assume the reward has a upper bound Rmax</p><ul><li>if you don’t know $r(x,a)$: set it to Rmax. That means try this action.</li><li>if you don’t know $P(x’|x,a)$: set $P(x’|x,a)=1$. That means explore a new state.</li></ul></li></ul><h3 id="Complexity"><a href="#Complexity" class="headerlink" title="Complexity"></a>Complexity</h3><ul><li>memory:  store $P(x’|x,a)\Rightarrow O(|x|^2|A|)$, store $r(x,a)\Rightarrow O(|X||A|)$</li><li>time: solving once MDP requires $poly(|X|,|A|,1/\epsilon,\log(1/delta)$. Need to do this often. </li></ul><h2 id="Model-free"><a href="#Model-free" class="headerlink" title="Model-free"></a>Model-free</h2><p>According to Theorem Bellman, once we have the optimal value function, we can get a greedy policy, which is optimal.</p><p>$Q^{\pi}(x,a)$​ : the expected reward of a policy $\pi$​, given the state and action pair $(x,a)$</p><p>$$<br>Q^{\pi}(x,a)=   r(x,a)+\gamma\sum_{x’}\Pr[x’|x,a]V^{\pi}(x’)<br>$$<br>For the optimal policy $\pi^\ast$: It holds  </p><p>$$<br>V^*(x)=   \max_a Q^*(x,a)<br>$$<br>The key idea is to estimate $Q^\ast(x,a)$ from samples.</p><h3 id="Q-learning"><a href="#Q-learning" class="headerlink" title="Q-learning"></a>Q-learning</h3><p>To estimate the best policy’s Q function, which is  </p><p>$$<br>Q^*(x,a)=   r(x,a)+\gamma\sum_{x’}\Pr[x’|x,a]V^*(x’)<br>$$<br>instead of using transition probability to get the exact expectation, we estimate from on instance $(x,a,x’)$.<br>$$<br>Q(x,a)\gets r(x,a)+\gamma V^*(x’)=   r(x,a)+\gamma\max_{a’} Q(x’,a’)<br>$$</p><p>To trade-off huge variance from just one sample, we weight this update by alpha</p><p>$$<br>Q(x,a)\gets (1-\alpha_t)Q(x,a)+\alpha_t(r(x,a)+\gamma\max_{a’} Q(x’,a’))<br>$$<br>$\alpha$: usually decrease along the time. means: at the beginning we put much weight on a new sample. Later, we put less and less.</p><h4 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h4><p>Random version</p><ol><li>have initial estimate of $Q(x,a)$</li><li>observe transition $x,a,x’$ with reward $r$. Update $Q(x,a)$ for long enough times.</li></ol><p>Optimistic algorithm, similar to $R_{\max}$:</p><p>starting with an optimistic initialization. But only $R_{\max}$ is not enough, have to consider the discount effect and weight effect.</p><ol><li>initialize $Q(x,a)\gets\frac{R_{max}}{1-\gamma}\prod_{t=   1}^{T_{init}}(1-\alpha_t)^{-1}$</li></ol><h4 id="Convergence"><a href="#Convergence" class="headerlink" title="Convergence"></a>Convergence</h4><p><strong>Theorem</strong> for random: If learning rate alpha satisfies:</p><ul><li>never stops updating: $ \sum_t\alpha_t=   \infty$</li><li>later samples have smaller weights: $\sum_t\alpha_t^2&lt;\infty$</li><li>and actions are chosen at random</li></ul><p>Then</p><p>$Q$ learning converges to optimal $Q^\ast$ with probability 1.</p><p><strong>Theorem</strong> for optimistic: With probability $1-\delta$, optimistic Q-learning obtains an $\epsilon$​-approximation policy after a number of time steps that is polynomial in $|X|,|A|, 1/\epsilon$ and $\log(1/\delta)$.</p><h4 id="Complexity-1"><a href="#Complexity-1" class="headerlink" title="Complexity"></a>Complexity</h4><ul><li>memory: store the Q-table: $Q(x,a): O(|X||A|)$</li><li>time: <ul><li>update per sample: find the action which gives the maximum $Q(x’,a’)$, $O(|A|)$ </li><li>iterations: polynomial in $|X|,|A|, 1/\epsilon$ and $\log(1/\delta)$</li></ul></li></ul><h4 id="Parametric-Q-function-approximation"><a href="#Parametric-Q-function-approximation" class="headerlink" title="Parametric Q-function approximation"></a>Parametric Q-function approximation</h4><p>The general idea is that we don’t update the entries of $Q$ table one by one in the update, but use some parameters to calculate the the entries and update the parameters in each step. In this way, we turn the question into an optimization problem and can solve it by approximation. Also, this approach allows us to go from the finite tabular $Q$ to infinite $Q$.</p><p>At convergence, we want:</p><p>$$<br>Q(x,a)=   \mathbb{E}<em>{(r,x’)|x,a}(r+\gamma\max</em>{a’}Q(x’,a’))<br>$$</p><p>$$<br>\Rightarrow\mathbb{E}<em>{(r,x’,x,a)}(Q(x,a)-r-\gamma\max</em>{a’}Q(x’,a’))=   0<br>$$</p><p>$$<br>\Rightarrow\min_{\theta}\mathbb{E}<em>{(r,x’,x,a)}[Q(x,a)-r-\gamma\max</em>{a’}Q(x’,a’)]^2<br>$$</p><p>In this way, we can use mean to approximate expectation.</p><p>Example of parametric $q$-function: linear function approximation: $Q(x,a;\theta)=   \theta^T\phi(x,a)$ </p><p>Fit parameters to data: define the loss function on parameters as:</p><p>$$<br>L(\theta)=   \sum_{(x,a,r,x’)\in D}(r+\gamma\max_{a’}Q(x’,a’;\theta^{old})-Q(x,a;\theta))^2<br>$$</p><p>So, the goal is to find parameters to minimize the loss function:</p><p>$$<br>\theta^*=   \arg_{\theta}\min L(\theta)<br>$$</p><ul><li>label: the estimation of Q entry given the observed sample:$r+\gamma\max_{a’}Q(x’,a’;\theta^{old})$</li><li>prediction given theta: $ Q(x,a;\theta))$</li></ul><h4 id="Deep-learning"><a href="#Deep-learning" class="headerlink" title="Deep learning"></a>Deep learning</h4><p>Recall what deep learning does: deep learning is a tool to solve the loss minimization problem, given data:</p><p>$$<br>w^*=   \arg_w\min \sum_{i=   1}^N l(y_i,f(x_i;w))<br>$$<br>by fitting nested nonlinear function of $f(x;w)$</p><h4 id="Deep-Q-Networks"><a href="#Deep-Q-Networks" class="headerlink" title="Deep Q Networks"></a>Deep Q Networks</h4><p>this is a variant of Q-learning:</p><ul><li>use convolutional neural nets to approximate Q function</li><li>important empirical insights:<ul><li><p>maintain constant “target” values across episodes. save the initial labels as y, and use these ys throughout training, instead of calculating new label in each iteration.</p></li><li><p>double DQN: two networks, use old parameters to evaluate Q function, but new parameters for action selection. Want to use old parameters to calculate the value to avoid oscillations. Current parameters are more closed to the policy would do.</p><p> $$<br>L(\theta)=   \sum_{(x,a,r,x’)\in D}(r+\gamma Q(x’,\hat{a}(x,\theta);\theta^{old})-Q(x,a;\theta))^2<br>$$<br>where $ \hat{a}(x,\theta)=   \arg_{a’}\max Q(x,a’,\theta)$</p></li></ul></li></ul><h3 id="Policy-search-methods"><a href="#Policy-search-methods" class="headerlink" title="Policy search methods"></a>Policy search methods</h3><p>Learning a policy without the detour of learning a value function.</p><p>Given a policy, do forward sampling on the controlled Markov chain and evaluate this policy $J(\theta)$. Then, adjust the parameters by gradient descent or other methods to get a new policy.</p><h4 id="Bayesian-Learning-for-policy-search"><a href="#Bayesian-Learning-for-policy-search" class="headerlink" title="Bayesian Learning for policy search"></a>Bayesian Learning for policy search</h4><p>Go beyond point estimation, but the whole distribution.</p><p>Using the Bayesian, on the data domain, find which part we are not certain about and which part we are certain about and then guide the samples drawing procedure.</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>Model-based MDP and model-free RL are polynomial in $|A|$​​ and $|X|$​​. However, structured domains $(|A|,|X|$​​ exponential in Nr. agents $)$​ and continuous domains $(|A|$​ and $|X|$​​ are infinite$)$ are not applicable.</p><h1 id="Outlook"><a href="#Outlook" class="headerlink" title="Outlook"></a>Outlook</h1><h2 id="Bayesian-Deep-RL"><a href="#Bayesian-Deep-RL" class="headerlink" title="Bayesian Deep RL"></a>Bayesian Deep RL</h2><p>Express the uncertainty of the model itself, by maintaining multiple models, ensemble of models.</p><p>How to go beyond point estimate’s uncertainty?</p><h2 id="Improving-action-selection-by-planning"><a href="#Improving-action-selection-by-planning" class="headerlink" title="Improving action selection by planning"></a>Improving action selection by planning</h2><p>Beyond one-step transitions, multiple steps forward to plan. </p><h2 id="Risk-in-exploration"><a href="#Risk-in-exploration" class="headerlink" title="Risk in exploration"></a>Risk in exploration</h2><h3 id="Safe-Bayesian-optimization"><a href="#Safe-Bayesian-optimization" class="headerlink" title="Safe Bayesian optimization"></a>Safe Bayesian optimization</h3><p>not only consider the reward, but also maintains safety constraints. Try to never violate these constraints. Formally, $\max f(x), s.t. g(x)\geq\tau)$</p><p>One challenge is that none of $f(x), g(x)$ are given in closed form, access only via noisy black box.</p><p>Approach: </p><ol><li>find a safe start point</li><li>go to reachable optimal points, instead of global optimal.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Bayesian </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PAI4 Reasoning over Time</title>
      <link href="/pai-04/"/>
      <url>/pai-04/</url>
      
        <content type="html"><![CDATA[<p>Before, we talk about static models, which means variables don’t change possible values. For temporal models, in which variables’ value states can change over time, approaches are generated from static model:</p><p>The basic idea is to create “copies” of variables, one per time step.</p><p>??? How should we model dependence over time? That is the dependence between variables.</p><p>A very natural kind of model is Markov chain. </p><p>Markov chain can have orders: k-order means the current event depends only on the previous k events. k-order Markov chain can be easily reduced into 1-order Markov chain by creating k-length vectors.</p><h1 id="Inference-Tasks"><a href="#Inference-Tasks" class="headerlink" title="Inference Tasks"></a>Inference Tasks</h1><p>Settings:</p><ul><li>$X_1,X_2,\cdots,X_T$: unobserved or hidden variables, called states change over time.</li><li>$Y_1, Y_2,\cdots,Y_T$: observations</li></ul><p>Tasks:</p><ul><li>Filtering: given the observations till now, what is the current state? $P(X_t|y_{1:t})$</li><li>Prediction: given the observations, predict the ne$X_t$ state: $P(X_{t+\delta}|y_{1:t})$​</li><li>Smoothing: what is the probability of some event happened before given what are known now.$P(X_t|y_{1:T})$ for $1\leq t\leq T$</li><li>MPE: $\arg \max_{X_{1:T}} P(X_{1:T}|y_{1:T})$. Observing something, what is the most likely path?</li></ul><p>These tasks can be solved by previously learned methods, e.g. variable elimination/belief propagation. But one problem is if we want to calculate for $t$, we need to start from the beginning. The complexity grows with time. Therefore, we want some model much efficient. </p><h1 id="State-space-models"><a href="#State-space-models" class="headerlink" title="State space models"></a>State space models</h1><p>In general, a family of models that behave some Markovian process but not directly observed. We only observe some noisy estimates. Some examples: Hidden Markov model, Kalman Filter.</p><p>Particularly, we assume:</p><ul><li><p>Markov property holds over time: the current states only depends on the previous one, not the much older ones.</p></li><li><p>conditional independence: $y_t$ only depends on $x_t$, not the older $x_s$. </p></li><li><p>stationary: the transition probability </p><ol><li><p>$X_i$ to $X_{i+1}$ not dependent on $i$, and </p></li><li><p>$X_t$​ to $Y_t$​, not dependent on $t$</p><p>is the same over the time. </p></li></ol></li></ul><p>discrete HMM: $X_i$​ categorical, $Y_i$ can be an$Y_t$hing</p><p>continuous Kalman Filters: $X_i, Y_i$: continuous, follow Gaussian distributions</p><h2 id="HMM"><a href="#HMM" class="headerlink" title="HMM"></a>HMM</h2><h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><h4 id="Filtering"><a href="#Filtering" class="headerlink" title="Filtering"></a>Filtering</h4><p>Answer the question that how to efficiently update our belief of states given the previous states. Formally,</p><p>Given $P(X_t|y_{1\cdots t-1})$ and $y_t$, compute $P(X_t|y{1\cdots t})$</p><p>$$<br>\Pr[X_t|y_{1:t}]=\frac{1}{Z}\Pr[X_t|y_{1:t-1}]\Pr[y_t|X_t,y_{1:t-1}] =\frac{1}{Z}\Pr[X_t|y_{1:t-1}]\Pr[y_t|X_t]<br>$$</p><p>with $ Z=\sum_x\Pr[X_t=x|y_{1:t-1}]\Pr[y_t|X_t=x]$</p><h4 id="Smoothing"><a href="#Smoothing" class="headerlink" title="Smoothing"></a>Smoothing</h4><p>Run sum product to calculate the interested marginals.</p><h4 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a>Prediction</h4><p>$$<br>\Pr[X_{t+1}|y_{1:t}]=\sum_x\Pr[X_t=x,X_{t+1}|y_{1:t}]=\sum_x \Pr[X_t=x|y_{1:t}]\Pr[X_{t+1}|X_t=x,y_{1:t}]<br>$$</p><p>$$<br>=\sum_x\Pr[X_t=x|y_{1:t}]\Pr[X_{t+1}|X_t=x]<br>$$</p><p>The computation complexity of condition and prediction doesn’t grow with $t$. Reuse what are computed before.</p><h2 id="Kalman-Filter"><a href="#Kalman-Filter" class="headerlink" title="Kalman Filter"></a>Kalman Filter</h2><p>Employing Gaussian properties, encode two stuffs:</p><ul><li>transition between $X_{t+1}$ and $X_t$​ , Motion model, linear</li><li>transition between $Y_t$ and $X_t$​ , Sensor model, linear</li></ul><h3 id="Gaussian"><a href="#Gaussian" class="headerlink" title="Gaussian"></a>Gaussian</h3><p>Properties: </p><ul><li>marginalization: for Gaussian distribution, marginalization is nothing but indexing/selection.</li><li>conditioning: conditions of Gaussian’s are still Gaussian. The new mean is the original mean, linearly corrected by observations. The new variance is also the original variance, corrected by the covariance and the variance of observations. It shrinks. <em>Variance can only decrease</em>.</li><li>multiplication: a Gaussian random vector multiplied by a constant matrix is still Gaussian.</li><li>summation: sums of Gaussian are Gaussian. New mean: the sum of means. New variance: the sum of variances.</li></ul><h3 id="Inference-1"><a href="#Inference-1" class="headerlink" title="Inference"></a>Inference</h3><h4 id="Filtering-1"><a href="#Filtering-1" class="headerlink" title="Filtering"></a>Filtering</h4><p>How to do filtering fast? </p><p>Similar to HMM, because we utilize the Markov chain structure, which is not changed, change the summation to integral.</p><h4 id="Smoothing-1"><a href="#Smoothing-1" class="headerlink" title="Smoothing"></a>Smoothing</h4><h4 id="Prediction-1"><a href="#Prediction-1" class="headerlink" title="Prediction"></a>Prediction</h4><h4 id="MPE"><a href="#MPE" class="headerlink" title="MPE"></a>MPE</h4><h1 id="Dynamic-Bayesian-Networks"><a href="#Dynamic-Bayesian-Networks" class="headerlink" title="Dynamic Bayesian Networks"></a>Dynamic Bayesian Networks</h1><p>????</p><p>Generalized from state space models, now there are more than one variable in each time step. Also, one variable in the current time can be influenced by several variables previously.</p><h2 id="Particle-filtering"><a href="#Particle-filtering" class="headerlink" title="Particle filtering"></a>Particle filtering</h2><h2 id="Assumed-density-filtering"><a href="#Assumed-density-filtering" class="headerlink" title="Assumed density filtering"></a>Assumed density filtering</h2><p>The key idea is similar to variational inference, that is projecting marginals to simple ones.</p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Bayesian </tag>
            
            <tag> Markov </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PAI5 Probabilistic Planning</title>
      <link href="/pai-05/"/>
      <url>/pai-05/</url>
      
        <content type="html"><![CDATA[<p>How do we use inference we keep tracking over time in order to act? </p><h1 id="Markov-Decision-Process"><a href="#Markov-Decision-Process" class="headerlink" title="Markov Decision Process"></a>Markov Decision Process</h1><p>An essential model studied in the context of decision making under uncertainty. The most basic model in making inference is Markov chain. MDP is the most basic model in making decisions, which is controlled Markov chain.</p><p>An MDP is specified by:</p><ul><li>a set of states $X={1, 2, \cdots, n}$</li><li>a set of actions $A={1,2,\cdots,m}$</li><li>Transition probabilities: the next state not only depends on the current state, but also on the taken actions. $P(x’|x,a)=\Pr(\text{Next state} = x’|\text{Action } a \text{ in state } x)$​</li><li>A reward function $r(x,a)$: objective: state and action pair. <ul><li>where does the reward come from? An engineering choice. Many works on how to define a good reward function. For instance, reverse reinforcement learning, where I have an ideal series of actions, I want to define a kind of reward to make this series come true.</li><li>This reward function could be deterministic or random. If it is random, we look its expected value.</li></ul></li></ul><p>The problem is how to choose actions to maximize rewards. </p><h2 id="Planning-in-MDPs"><a href="#Planning-in-MDPs" class="headerlink" title="Planning in MDPs"></a>Planning in MDPs</h2><p>Currently, assuming that $r$ reward function and $P$ transition are known.</p><p><strong>Policy</strong> is a function from states to actions. It could be deterministic or stochastic. </p><p>How to compare policies? According to the reward function. Several strategies to use the reward function</p><ul><li>sum up the rewards and fix a certain number of future steps. <ul><li>if not fixing a certain step number, the summation could diverge, cannot be compared.</li><li>This is a generalization of naive greedy. Question: what is the certain number? why others?</li></ul></li><li>count more on the current step than those in future. Discount calculation. How to make discounts?<br>$$<br>\mathbb{E}[r(X_0,\pi(X_0))+\gamma r(X_1,\pi(X_1))+\gamma^2r(X_2,\pi(X_2))+\cdots]<br>$$</li></ul><p>Assuming that, we have a strategy to score policy, then, what is the optimal policy?</p><h3 id="Value-function"><a href="#Value-function" class="headerlink" title="Value function"></a>Value function</h3><p>Given the starting state x, try to evaluate a policy from a long term view:</p><p>$$<br>V^{\pi}(x)=J(\pi|X_0=x)=\mathbb{E}[\sum_{t=0}^{\infty}\gamma^t r(X_t,\pi(X_t))|X_0=x]<br>$$<br>This is a function on the state. Each state is mapped to one value.</p><p>It has <strong>recursive relation</strong>. What is recursion? </p><p>$$<br>V^{\pi}(x)=r(x,\pi(x))+\gamma\sum_{x’}\Pr[x’|x,\pi(x)]V^{\pi}(x’)<br>$$</p><h4 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h4><p>How to solve this function?</p><p>Supposing there are finite states with n states. Then, this is a group of n linear functions with n unknown variables, which have a unique solution when $\gamma&lt;1$. </p><ul><li>for any given start state, we can have the value of the policy</li><li>if the start state is random, we can take the expectation of the policy’s value.</li></ul><h3 id="Policy-finding"><a href="#Policy-finding" class="headerlink" title="Policy finding"></a>Policy finding</h3><p>So far, we know given a policy how to evaluate it. Then, how to find the best policy?</p><ul><li><p>A simple algorithm</p><ol><li>for every policy pi compute $J(\pi)=\sum_x\Pr[X_0=x]V^{\pi}(x)$  </li><li>pick the policy with the maximum expected value.</li></ol><p>The complexity is linear to the number of polices, which is the number of actions exponential to the number of states $O(m^n)$</p></li><li><p>A more efficient algorithm. Consider a new setting, we have been told the value of each state, which action to take? An intuition is greedy maximizing the trade-off between the immediate action and the future states. In this way, we achieve a “best” policy. Best under the meaning of our maximize standard.</p><p> $$<br>a^*\in\arg_a\max r(x,a)+\gamma\sum_{x’}\Pr[x’|x,a]V(x’)<br>$$</p><ul><li>the <strong>greedy police</strong> is with respect to the value of state.</li></ul></li></ul><p><strong>Theorem</strong> Bellman: A policy is optimal $\Leftrightarrow$ The greedy policy w.r.t its induced value function is itself.</p><p>How to use this theorem to find optimal policy?</p><h4 id="Policy-iteration"><a href="#Policy-iteration" class="headerlink" title="Policy iteration"></a>Policy iteration</h4><p>This is an intuitive way to perform the cycle in the theorem</p><ol><li>Start with an arbitrary, e.g. random policy $\pi$</li><li>until converge, do:<ol><li>compute value function $V^{\pi}(x)$</li><li>compute greedy policy  $\pi_G  w.r.tV^{\pi}$</li><li>set $ \pi\gets\pi_G$</li></ol></li></ol><p>Remark: it only converges to values, not actions. Because there could be several policies with an optimal value.</p><p>Guarantee:</p><ul><li>monotonically improve</li><li>converge to an exact optimal policy <ul><li>in polynomial iterations $O(n^2m/(1-\gamma))$</li><li>in every iteration, the complexity is $  O(n^2\cdot (n+m))$<ul><li>needs to solve a linear system in the number of states $n^2$ for each state n, which is expensive  $O(n^2\cdot n)$ </li><li>Also, for each state $n$, for each action $m$, needs to calculate the value $n$, which is $O(n^2\cdot m)$​</li><li>this complexity can be reduced if a state just reaches some of other states, called sparse MDPS</li></ul></li></ul></li></ul><h4 id="Value-iteration"><a href="#Value-iteration" class="headerlink" title="Value iteration"></a>Value iteration</h4><p>An alternative approach is to find the value of optimal policy first and then use the greedy policy. For the optimal policy $\pi\ast i_t$ holds</p><p>$$<br>V^*(x)=\max_a r(x,a)+\gamma\sum_{x’}\Pr[x’|x,a]V^*(x’)<br>$$</p><p>we can compute $\pi\ast$ using dynamic programming:</p><p>define $V_t(x)$: the maximum expected reward when starting in state $x$ and world ends in $t$ time steps</p><ul><li><p>$V_0(x)=\max_ar(x,a)$</p></li><li><p>$V_1(x)=\max_ar(x,a)+\gamma\sum_{x’}\Pr[x’|x,a]V_0(x’)$</p></li><li><p>$V_{t+1}(x)=\max_ar(x,a)+\gamma\sum_{x’}\Pr[x’|x,a]V_t(x’)$</p></li></ul><p>Iterate until convergence.</p><p>Algorithm:</p><ol><li>initialize $V_0(x)=\max_ar(x,a)$</li><li>For $t=1, \cdots, \infty$:<ol><li>For each $x, a$, let $Q_t(x,a)=r(x,a)+\gamma\sum_{x’}\Pr[x’|x,a]V_{t-1}(x’)$</li><li>For each $x$ let $V_t(x)=\max_a Q_t(x,a)$</li><li>Break if $ ||V_t-V_{t-1}||<em>{\infty}=\max_x|V_t(x)-V</em>{t-1}(x)|\leq\epsilon$</li></ol></li></ol><p>Guarantee:</p><ul><li><p>converge to $\epsilon$​-optimal policy. The proof is Bellman update, using $V_t$ to update $V_{t+1}$,  is a contraction.<br>$$<br>B:\mathbb{R}^n\to\mathbb{R}^n, B:V\to BV. (BV)(x)=\max_ar(x,a)+\gamma\sum_{x’}\Pr[x’|x,a]V(x’)<br>$$<br>There is a theorem:<br>$$<br>\forall V,V’\in\mathbb{R}^n, ||BV-BV’||<em>{\infty}\leq\gamma||V-V’||</em>{\infty}<br>$$<br>A contraction has two important properties:</p><ul><li>existence of a unique fixed point</li><li>convergence to the fixed point</li></ul><p>Convergence rate:</p><ul><li>number of iterations: depends a lot on initial  policy and epsilon.</li><li>in each iteration:  the complexity is $O(n^2\cdot m)$</li></ul></li><li><p><strong>no</strong> monotonical property.</p></li></ul><h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><p>In practice, which one is better depends on the application. Can combine both of them. Like take one greedy policy in some step of policy iteration as the initial policy for value iteration.</p><h1 id="POMDP"><a href="#POMDP" class="headerlink" title="POMDP"></a>POMDP</h1><p>Partially observed markov decision process = controlled HMM = Belief-state MDP</p><p>We have a series of observations $Y_1,\cdots,Y_t$. The key idea is the last belief $X_t$, including all information from the previous observations. In other words, if we have $X_t$, we can forget all of $Y_1,\cdots,Y_t$. Instead of solving markov decision process over the state space, we are going to solve MDP over the belief of state space. </p><p>Key idea: interpret POMDP as an MDP with enlarged state space: new states correspond to beliefs $P(X_t|y_{1:t})$ in the original POMDP.</p><p>Once we have the newest observation $Y_{t+1}$, applying Bayesian filtering, a deterministic function, to update on the observations</p><h2 id="Settings"><a href="#Settings" class="headerlink" title="Settings"></a>Settings</h2><ul><li>the set of state space: $X_1,X_2,\cdots,X_n$</li><li>the set of action space: $A_1,A_2,\cdots A_m$</li><li>the set of observation space: $Y_1,Y_2,\cdots Y_k$</li><li>Transition probability: $P(X_{t+1}|X_t,A_t)$</li><li>observation probability: $P(Y_t|X_t)$</li></ul><p>Consider at time $t$, </p><ul><li>we have the belief $B_t=b_t$​, where $b_t$​ is an instance of $n$-dimension probability vector.</li><li>Suppose we take the action at </li><li>and observe $y_{t+1}$.</li></ul><p>In this way,</p><p>$$<br>b_{t+1}(x)=\Pr[X_{t+1}=x|y_{1:t+1},a_{1:t}]<br>$$</p><p>$$<br>=\frac{1}{Z}\sum_{x’}\Pr[X_t=x’|y_{1:t},a_{1:t-1}]\Pr[X_{t+1}=x|X_t=x’,a_t]\Pr[Y_{t+1}=y_{t+1}|x]<br>$$</p><p>That means $  b_{t+1}=f(b_t,a_t,y_{t+1})$</p><h2 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h2><p>Transform into a new MDP problem:</p><ul><li><p>states: beliefs over states for original POMDP: $\mathcal{B}={b:{1,2,\cdots,n}\to[0,1],\sum_xb(x)=1}$</p></li><li><p>actions: same as original MDP</p></li><li><p>Transition model: </p><ul><li>stochastic observations: the observation of the next time only depends on our belief of the current time and the action we take. $\Pr[Y_{t+1}=y|b_t,a_t]=\sum_x b_t(x)\Pr[Y_{t+1}=y|X_t=x,a_t]$</li><li>state update Bayesian filtering: Given $b_t$, $a_t$, $y_{t+1}$: $b_{t+1}(x’)=\frac{1}{Z}\sum_x b_t(x)\Pr[X_{t+1}=x’|X_t=x,a_t]\Pr[y_{t+1}|x’]$​</li></ul></li><li><p>Reward function: $r(b_t,a_t)=\sum_x b_t(x)r(x,a_t)$</p><p>If we can solve the new MDP, we can solve the original MDP.</p></li></ul><h2 id="Approximate-solutions"><a href="#Approximate-solutions" class="headerlink" title="Approximate solutions"></a>Approximate solutions</h2><p>The belief state space could be exponential. We need some approximate solutions.</p><p>The key idea: most belief states never reached, we want to limit the belief space, approaches like:</p><ul><li>discretize the belief space by sampling</li><li>dimension reduction</li></ul><h3 id="Policy-gradient-method"><a href="#Policy-gradient-method" class="headerlink" title="Policy gradient method"></a>Policy gradient method</h3><p>Limit the policy space to some parametric family. Then transform the problem into an optimization problem.</p><h2 id="Planning"><a href="#Planning" class="headerlink" title="Planning"></a>Planning</h2><ul><li>use the inference model to do planning</li><li>condition not only on the past, but also on the future, find the action to lead me to that future. </li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Markov </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PAI6 Learning</title>
      <link href="/pai-06/"/>
      <url>/pai-06/</url>
      
        <content type="html"><![CDATA[<p>So far, we talk about how to use a given model to do some tasks, e.g. inference, planning. But where do these models come from? Now, we turn attention to learn models from training data.</p><h1 id="Learning-BN-from-data"><a href="#Learning-BN-from-data" class="headerlink" title="Learning BN from data"></a>Learning BN from data</h1><p>What to learn?</p><ul><li>the structure of BN</li><li>the parameters: conditional probability distributions</li></ul><p>Different case: </p><ul><li>all variables are observed</li><li>only part of variables can be observed.</li></ul><ol><li>first assume the structure is given, to learn the parameters</li><li>learn the structure as well</li></ol><h2 id="Parameter-learning"><a href="#Parameter-learning" class="headerlink" title="Parameter learning"></a>Parameter learning</h2><h3 id="MLE"><a href="#MLE" class="headerlink" title="MLE"></a>MLE</h3><p>A very basic estimation is MLE, maximum likelihood estimation.</p><p>$$<br>\theta^* = \arg_{\theta}\max\sum_{j=1}^n\sum_{i=1}^N\log\Pr[X_j^{(i)}|X_{Pa_j}^{(i)},\theta_{j|Pa_j}]<br>$$</p><p>We divide the whole parameters to individual sets on each variable. Global optimization can be composed of local optimization. Formally,</p><p>$$<br>\theta^*_{j|Pa_j} = \arg_{\theta}\max L_j(\theta_j|Pa_j)\Rightarrow\theta^*_{j|Pa_j}=\frac{Count(X_j,X_{Pa_j})}{Count(X_{Pa_j})}<br>$$<br>When $X_j$ follows Bernoulli distribution.</p><p>This strategy requires complete data, all variables are observable.</p><ul><li><p>If there are unobserved variables: EM-algorithm</p></li><li><p>if the count is small, the estimation could be imprecise. In this case, we can use <strong>pseudo-counts</strong>: make prior assumptions about parameters to correct the estimated parameters.</p><ul><li>for Bernoulli distribution, the prior is equivalent to make Beta prior over parameters. For instance,<br>$$<br>\theta\sim Beta(\alpha_c,\alpha_l) = \frac{1}{B(\alpha_c,\alpha_l)}\theta^{\alpha_c-1}(1-\theta)^{\alpha_l-1}<br>$$</li><li>Then observe $n_c$ and $n_l$ counts specifically,<br>$$<br>\Pr[\theta|n_c,n_l]=\frac{1}{Z}\frac{Beta(\alpha_c,\alpha_l)}\theta^{\alpha_c-1}(1-\theta)^{\alpha_l-1}\theta^{n_c}(1-\theta)^{n_l}\sim Beta(\alpha_c+n_c,\alpha_l+n_;)<br>$$</li></ul></li></ul><h3 id="MAP"><a href="#MAP" class="headerlink" title="MAP"></a>MAP</h3><p>Another view is to treat the parameters as shared variables. They are prior. Given data, which can be treated as evidence, we want to find which values of these variables are most possible. Solve via MAP.</p><p>$$<br>\hat{\theta}\in\arg_{\theta}\max\Pr[\theta|f^{(i)},w^{(i)}]<br>$$<br>In this way, if we want to query the conditional probability given data, we can use the MAP estimation to do that. For instance, $F,W$ are variables, $D$ are the dataset.</p><p>$$<br>\Pr[F|W=w,D]\simeq\Pr[F|w,\hat{\theta}]<br>$$</p><h3 id="Bayesian-learning"><a href="#Bayesian-learning" class="headerlink" title="Bayesian learning"></a>Bayesian learning</h3><p>Instead of learning the unknown parameters, just marginalize them, sum them out.</p><p>$$<br>\Pr[F|W=w,D]=\int\Pr[F,\theta|w,D]\mathrm{d}\theta=\int \Pr[F|w,\theta]\Pr[\theta|w,D]\mathrm{d}\theta<br>$$</p><h2 id="Structure-learning"><a href="#Structure-learning" class="headerlink" title="Structure learning"></a>Structure learning</h2><h3 id="Scoring"><a href="#Scoring" class="headerlink" title="Scoring"></a>Scoring</h3><p>How to score a graph structure?</p><p>Given a scoring strategy, how to find the “optimal” structure?</p><h3 id="MLE-1"><a href="#MLE-1" class="headerlink" title="MLE"></a>MLE</h3><p>Only mle will cause the children fully-connected to all of its parents $\to$Overfit</p><h4 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h4><ul><li>BIC</li><li>special family of graphs</li></ul><h3 id="MAP-1"><a href="#MAP-1" class="headerlink" title="MAP"></a>MAP</h3><p>The general idea is to condition on what we have, the dataset, and find the most probable explanation for the unknown variables, W.</p><p>Placing a prior distribution $P(W)$ on the parameters W</p><p>$$<br>\hat{w}=\arg_w\max\Pr[w|x_{1:n},y_{1:n}]=\arg_w\min-\log(\Pr[w])-\sum_{i=1}^N\log\Pr[y_i|x_i,w]<br>$$</p><ul><li><p>mini-batch SGD for MAP estimation to accelerate. The algorithm:</p><ol><li><p>initialize $w_0$</p></li><li><p>For $t=0,1,2,\cdots$ </p><p>$$<br> w_{t+1}=w_t-\frac{\epsilon_t}{2}(\nabla\log\Pr[w_t]+\frac{N}{k}\sum_{i=1}^k\nabla\log\Pr[y_{t,i}|x_{t,i},w_t])<br>$$</p></li></ol><ul><li>$(x_{t,i},y_{t,i})$ is the $i$-th data point in the $t$-th mini-batch of $k$ points</li><li>learning rate satisfies $\sum_t\epsilon_t\to\infty,\sum_t\epsilon_t^2:\infty$</li></ul></li></ul><h1 id="Bayesian-learning-1"><a href="#Bayesian-learning-1" class="headerlink" title="Bayesian learning"></a>Bayesian learning</h1><p>Different from MAP, Bayesian learning turns attention to prediction. Skip the unknown parameters and use them directly. That means given a new data point $x’$, what is the probability of $Y(x’)$? To perform this task, we sum out whatever we don’t know:</p><p>$$<br>\Pr[Y|x’,x_{1:N},y_{1:N}]=\int \Pr[w|x_{1:N},y_{1:N}]\Pr[Y|w,x’]\mathrm{d}w<br>$$</p><ul><li>the first item on the right side: calculate how likely of a model given our data</li><li>the second item: how likely is the prediction given the model and the new data point.</li><li>this model not only considers the most likely weight, which MAP chooses, but also all the other weights.</li><li>However, estimate the whole weight space may be undoable.</li></ul><p>Several algorithms can make this task doable.</p><h2 id="Bayesian-learning-with-Gaussian-process"><a href="#Bayesian-learning-with-Gaussian-process" class="headerlink" title="Bayesian learning with Gaussian process"></a>Bayesian learning with Gaussian process</h2><h3 id="Gaussian-process"><a href="#Gaussian-process" class="headerlink" title="Gaussian process"></a>Gaussian process</h3><p>It is a normal distribution over functions</p><p>Pin on these functions finite points and these finite marginals are multivariate Gaussians.</p><p>Particularly, the prediction of one data point follows one-dimension Gaussian distribution. We need to learn the mu function and kernel function.</p><p>$$<br>\Pr[f(x)]\sim \mathcal{N}(f(x);\mu(x),\sigma^2(x))<br>$$</p><h4 id="kernel-covariance-functions"><a href="#kernel-covariance-functions" class="headerlink" title="kernel(covariance) functions"></a>kernel(covariance) functions</h4><ul><li><p>symmetric: $k(x,x’)=k(x’,x)$ for all $x,x’$</p></li><li><p>positive semi-definite: for all A, Sigma_{AA} is positive semi-definite matrix $\Leftrightarrow$ all eigenvalues of </p><p>$$<br>\Sigma_{AA}\geq 0\Leftrightarrow \forall x, x\sum_{AA}x\geq 0<br>$$</p></li><li><p>Examples:</p><ul><li><p>squared exponential kernel: $\mathcal{K}(x,x’)=\exp(-||x-x’||_2^2/h^2))$ when $x=x’$, the covariance is 1. h smaller $\to$​ more punish on distance $\to$ more fluctuation</p></li><li><p>exponential kernel: $\mathcal{K}(x,x’)=\exp(-||x-x’||_1/h^2)$    very unsmooth.</p></li><li><p>linear kernel, Bayesian linear regression: </p><p>$$<br> \mathcal{K}(x,x’)=x^Tx’<br>$$</p></li></ul></li></ul><p>This kind of models gives us the ability to predict for the uncertainty. How much uncertain on some data points, estimate the variance.</p><h2 id="Bayesian-deep-learning"><a href="#Bayesian-deep-learning" class="headerlink" title="Bayesian deep learning"></a>Bayesian deep learning</h2><p>work on high-dimension data.</p><ul><li>SGLD: generate from mini-batch SGD, with a more random noise item:<br>$$<br>w_{t+1}=w_t-\frac{\epsilon_t}{2}(\nabla\log\Pr[w_t]+\frac{N}{k}\sum_{i=1}^k\nabla\log\Pr[y_{t,i}|x_{t,i},w_t])+\eta_t)<br>$$<br>where $\eta\sim\mathcal{N}(0,\epsilon^2)$To avoid being stuck on some local areas.</li></ul><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Why Bayesian learning are so popular? Because it captures two kinds of uncertainty:</p><ul><li>aleatoric uncertainty: noise in observations given perfect knowledge of the model. For instance, flipping a coin, even we know the coin is fair, the result is still uncertain.</li><li>epistemic uncertainty: uncertainty about parameters due to the lack of data. For instance, I don’t know what kind of coin I have when flipping it.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Bayesian </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PAI3 Bayesian Network 2Inference</title>
      <link href="/pai-03/"/>
      <url>/pai-03/</url>
      
        <content type="html"><![CDATA[<h1 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h1><h2 id="Typical-queries"><a href="#Typical-queries" class="headerlink" title="Typical queries"></a>Typical queries</h2><ul><li>What are these typical queries for?</li><li>what kinds of typical queries?<ul><li>conditional/marginal query: Given conditional variable $s$’ value, what is the probability of the objective variable $s$? $\Pr[X_i|X_S=x_s]=?$​</li><li>MPE, most probable explanation: a special case of MAP. given the values for some variables, compute most likely assignment to all remaining variables: $\arg\max x_{\bar{s}} \Pr[X_{\bar{s}}=x_{\bar{s}}|X_s=x_s]$</li><li>MAP, maximum a posterior: compute most likely assignment to some variables.  Two kinds of queries: 1. the arg giving the maximum, 2. just the maximum value $\arg\max_{x_a}\Pr[X_A=x_a|X_B=x_b]$</li></ul></li></ul><p>Formally, any probabilistic inference system is to compute the posterior probability distribution for a set of query variables, given some observed event, that is some assignment of values to a set of evidence variables.</p><p>Define three types of variables:</p><ul><li>evidence variables: the set of variables give the observed event, denoted as $E$</li><li>query variables, denoted as $X$</li><li>hidden variables: all the variables except for evidence or query variables, denoted as $Y$</li></ul><h2 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h2><ul><li><p>exact: exploit structure/conditional independence to efficiently perform exact inference. Variable elimination, factor graph</p></li><li><p>approximation: loopy factor graph</p></li></ul><h3 id="Variable-elimination"><a href="#Variable-elimination" class="headerlink" title="Variable elimination"></a>Variable elimination</h3><p>It is called variable elimination because it eliminates one by one variables which are irrelevant for the query.</p><p>It lies on some <strong>basic operations</strong> on a class of functions known as <strong>factors</strong>.</p><p>It uses an algorithmic technique called <strong>dynamic programming</strong>.</p><p>The general idea:</p><ul><li>push sums through products as far as possible</li><li>create new factor by summing out variables, intermediate solutions are distributions on fewer variables.</li></ul><h4 id="Factor"><a href="#Factor" class="headerlink" title="Factor"></a>Factor</h4><p><strong>Factor</strong> is a function over a set of variables. It maps each instantiation of these variables to a real number. For instance, CPT(conditional probability table)s  are factors. In other words, a factor is a matrix indexed by the values of its argument variables. It has three operations:</p><ul><li><p>product: the variables are the <em>union</em> of two factors’ variables, the result is the product of two factors.<br>$$<br>f(X_1,X_2,\cdots,X_n,Y_1,Y_2,\cdots,Y_k,Z_1,Z_2,\cdots,Z_m)<br>$$</p><p>$$<br>=f_1(X_1,X_2,\cdots,X_n,Y_1,Y_2,\cdots,Y_k)\cdot f_2(Y_1,Y_2,\cdots,Y_k,Z_1,Z_2,\cdots,Z_m)<br>$$</p></li><li><p>marginalization: $f(B,C)=\sum_{a}f(A=a,B,C)$</p></li></ul><h4 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h4><p>Case: marginal variables</p><p>Given BN and Query $P(X|E)$</p><ol><li>choose an ordering of $X_1,\cdots,X_n$ for all elements in $Y$.</li><li>set up initial factors: $f_i=P(X_i|Pa_i), Pa_i,$ the set of nodes who have edges pointing to $X_i$</li><li>For $i=1:n, X_i\in Y$<ol><li>collect and multiply all factors that include $X_i$</li><li>generate new factor by marginalizing out $X_i$, $g=\sum_{x_i}\prod_j f_j$</li><li>add $g$ to the set of factors.</li></ol></li><li>renormalize $P(X,E)$ to get $P(X|E)$</li></ol><p>Case: maximum arguments, similar to the former algorithm</p><p>Given BN and evidence $E=e$</p><ol><li><p>choose an ordering of $X_1,\cdots,X_n$​ for all elements in $Y$.</p></li><li><p>set up initial factors: $f_i=P(X_i|Pa_i), Pa_i,$​ the minimum parent  set subsetting to the set of ancestors of given variable $X_i$. Like the definition in the building BN algorithm</p></li><li><p>For $i=1:n, X_i\in Y$</p><ol><li>collect and multiply all factors that include $X_i$</li><li>generate new factor by marginalizing out $X_i$,  $g=\max_{x_i}\prod_j f_j$</li><li>add g to the set of factors.</li></ol></li><li><p>For $i = n:-1:1, X_i\in Y$</p><p>$$<br>\hat{x_i}=\arg\max_{x_i}g_i(x_i,\hat{x}_{i+1:n})<br>$$</p></li></ol><h4 id="Order"><a href="#Order" class="headerlink" title="Order"></a>Order</h4><p><strong>The order matters</strong>! But how does it matter?</p><p>In general, the time and space requirements of variable elimination are dominated by the size of the largest factor constructed during the operation of the algorithm. It turns out to be intractable to determine the optimal ordering, but several good heuristics are available.</p><ul><li>eliminate whichever variable minimizes the size of the next factor to be constructed. In general, we can remove any leaf node that is not a query variable or an evidence variable.$\to$ every variable that is not an ancestor of a query variable or evidence variable is irrelevant to the query.</li></ul><h4 id="Complexity"><a href="#Complexity" class="headerlink" title="Complexity"></a>Complexity</h4><ul><li>polytree: linear in the size of the network. The size is defined as the number of  CPT entries.<ul><li>if the number of parents of each node is bounded by a constant, then the complexity will also be linear in the number of nodes.</li></ul></li></ul><p><strong>polytree</strong>: a DAG, dropping edge directions is a tree.</p><ul><li>multiply connected networks: has exponential time and space complexity in the worst case, even when the number of parents per node is bounded. ???? Example???</li></ul><p>Special case of the Algorithm for a polytree:</p><ol><li>pick a root within Y</li><li>orient edges in the undirected tree towards root.</li><li>eliminate in topological order bottom up: first all the children, then the parent</li></ol><p>All intermediate factors will contain at most $1+\max|Pa_i|$ variables.</p><h3 id="Factor-graphs"><a href="#Factor-graphs" class="headerlink" title="Factor graphs"></a>Factor graphs</h3><p>Why we need factor graph?</p><p>what advantages of it?</p><p><a href="https://en.wikipedia.org/wiki/Factor_graph">from the wiki</a></p><h4 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h4><p>a factor graph is a <em>bipartite graph</em> representing the <em>factorization</em> of a function. Given a function and its factorization:</p><p>$$<br>g(X_1,X_2,\cdots,X_n)=\prod_{j}f_j(S_j), S_j\subset{X_1,X_2,\cdots,X_n},\forall j\in[m]<br>$$</p><p>The corresponding factor graph: $G=(X,F,E)$</p><ul><li>$X$: the set of variables. One variable node for each variable.</li><li>$F: f_1,f_2,…f_m$, the set of factors. One factor node for each factor.</li><li>$E$: <em>undirected edge</em> between a factor vertex $f_j$ and a variable vertex $X_i$ iff $X_i\in S_j$</li></ul><h4 id="Message-passing"><a href="#Message-passing" class="headerlink" title="Message passing"></a>Message passing</h4><p>Messages are real-valued <em>functions</em>. It contains the “influence” that one variable ,not a factor, exerts on others. There are two kinds of message: </p><ol><li><p>message from a variable to a factor and</p></li><li><p>message from a factor to a variable. </p><p>Messages are always denoted by variables, not factors. That is $\mu_{v\to u}(x_v) , \mu_{u\to v}(x_v)$.  All uses $x_v$.</p></li></ol><ul><li><p>message from a variable v to a factor u: the product of all message this variable receives from its neighbors/factors except for the one it sends to.</p><p>$$<br>\mu_{v\to u}(x_v)=\prod_{u’\in N(v)\setminus{u}}\mu_{u’\to v}(x_v)<br>$$</p><p>Upon convergence if convergence happened, the estimated <em>marginal  distribution of each variable</em> is proportional to the product of all messages from adjoining factors missing the normalization constant:<br>$$<br>\Pr[X_v=x_v]\propto \prod_{u\in N(v)} \mu_{u\to v}(x_v)<br>$$</p><p>In other words,<br>$$<br>\Pr[X_v=x_v]\propto \mu_{u\to v}(x_v)\mu_{v\to u}(x_v)<br>$$</p></li><li><p>message from a factor to a variable: </p><ul><li><p>the product of all message this factor receives from its neighbors variables except for the one it sends to </p></li><li><p>weighted by the value of the factor, fixed the objective variable.</p><p>$$<br>\mu_{u\to v}(x_v)=\sum_{x_u\sim x_v}f_u(x_u)\prod_{v’\in N(u)\setminus{v}}\mu_{v’\to u}(x_{v’})<br>$$</p><p>Max version, to get the arg of max, also needs to store the arg information for each factor.</p><p>$$<br>\mu_{u\to v}(x_v)=\max_{x_u\sim x_v}f_u(x_u)\prod_{v’\in N(u)\setminus{v}}\mu_{v’\to u}(x_{v’})<br>$$</p><p>Likewise, the estimated joint marginal distribution of the set of  variables belonging to <em>one factor</em> is proportional to the product of the factor and the messages from the variables:</p></li></ul><p>$$<br>\Pr[X_f=x_f]\propto f_f(x_f)\prod_{v\in N(f)} \mu_{v\to f}(x_v)<br>$$</p></li></ul><h4 id="Algorithm-1"><a href="#Algorithm-1" class="headerlink" title="Algorithm"></a>Algorithm</h4><ul><li>Exact algorithm for trees:</li></ul><p><strong>Sum-product (also called belief propagation) algorithm</strong>. It computes the functions on edges. <a href="https://www.doc.ic.ac.uk/~mpd37/teaching/ml_tutorials/2016-11-09-Svensson-BP.pdf">A detailed introduction</a> and <a href="http://mlg.eng.cam.ac.uk/teaching/4f13/1920/factor%20graphs.pdf">a demo</a></p><p>Given a factor graph, choose one node as root.</p><p>There are three phases.</p><ol><li>Initialization. Void product is set as 1. </li><li>message passing. Compute outgoing messages when incoming messages are available.</li><li>termination. A marginal distribution is the product of the incoming messages to the variable node.</li></ol><ul><li>approximate algorithms for loops</li></ul><ol><li>initialize all messages as uniform distribution, instead of void product as 1</li><li>until converged to<ol><li>pick some ordering on the factor graph edges +directions, because of loops</li><li>update messages according to this ordering</li><li>break once all messages change by at most epsilon</li></ol></li></ol><p>Remarks:</p><ul><li><p>Does loopy BP always converge?</p><ul><li>No. The more “deterministic” of the initial distribution, the less likely that this algorithm will converge.</li></ul></li><li><p>If it converges, is it closed to the true value?</p><ul><li>This convergence may <strong>not</strong> always equal to the true marginals. It is often <strong>overconfident</strong>, having a posterior bigger than the true posterior.</li></ul></li></ul><h4 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h4><p>Factor graph can be used to compute <strong>marginal</strong> probability with low computation complexity.</p><h3 id="Variational-inference"><a href="#Variational-inference" class="headerlink" title="Variational inference"></a>Variational inference</h3><p>Compared to factor graphs, this method always converges.</p><h4 id="Settings"><a href="#Settings" class="headerlink" title="Settings"></a>Settings</h4><p>Given unnormalized distribution P with the form of the product of factors, the idea is to try to find a “simple” (tractable distribution Q that approximates P well. Then, compute marginals under Q* instead of P</p><ul><li><p>$\Pr[X_{1:n}]=\frac{1}{Z}\prod_{j=1}^m \Phi_j(X_{A_j})$</p></li><li><p>$Q^*\in\arg\min_{Q\in\mathcal{Q}}KL(Q||P)$</p></li><li><p>Q is chosen from a distribution family. A simple instance: independent distributions: $\mathcal{Q}={Q:Q(X_{1:n})=\prod_{i=1}^n Q_i(X_i)}$</p></li></ul><p>A key question is when to do this? On the prior? Or on the posterior?<br>Typically, the distribution of prior may be terrible, hard to catch, could be a lot configurations to capture, but once you have evidence, the “localized probability” posterior is somehow simplified. Then, the approximation of the posterior is hopeful. <em>Posterior often much better approximated by simple distribution</em>. That means the posterior only needs to capture features on a very very limited, much smaller space.</p><h4 id="KL-Divergence"><a href="#KL-Divergence" class="headerlink" title="KL Divergence"></a>KL Divergence</h4><p>$$<br>KL(Q||P)=\sum_x Q(x)\log\frac{Q(x)}{P(x)}=\sum_xQ(x)\log Q(x)-\sum_xQ(x)\log P(x)<br>$$</p><p>Not a distance: not satisfying: (1)symmetricity, (2) triangle inequality.</p><p><strong>Entropy</strong> of a distribution:</p><p>$$<br>H(Q)=-\sum_xQ(x)\log Q(x)<br>$$<br>Entropy of a product distribution, where $Q(X_{1:n})=\prod_i Q_i(X_i),H(Q)=\sum_i H(Q_i)$</p><p>A proof ketch:</p><p>$$<br> H(Q)=-\sum_x\prod_i Q_i(X_i)\log\prod_i Q_i(X_i)<br>$$</p><p>$$<br>=-\sum_{x_j}Q_j(X_j)\sum_{x_k,k\neq j}\prod_{k\neq j}Q_k(X_k)\sum_{i}\log Q_i(X_i)<br>$$</p><p>$$<br>=-\sum_{x_j}Q_j(X_j)\log Q_j(X_j)\cdot 1+\sum_{x_j}Q_j(X_j)H(Q_{-j})<br>$$</p><p>$$<br>=H(Q_j)+H(Q_{-j})<br>$$</p><h4 id="ELBO"><a href="#ELBO" class="headerlink" title="ELBO"></a>ELBO</h4><p>evidence lower bound</p><p>$$<br>\arg\min_{Q\in\mathcal{Q}}KL(Q||P)=\arg\max_{Q\in\mathcal{Q}}\sum_{i=1}^nH(Q_i)+\sum_{i=1}^m\sum_{x_{A_i}}\prod_{j\in A_i} Q_j(x_j)\log\Phi(x_{A_i})<br>$$<br>Want to optimize this objective according to Q. Methods:</p><ul><li>gradient-based</li><li>mean-field algorithm, also called coordinate ascent. The idea is to optimize one variable at a time.</li></ul><p><strong>Mean-filed algorithm</strong></p><ol><li>initialize. Start with a guess, e.g. uniform distribution for each variable: $Q^{(0)}$</li><li>Operate until convergence:<ol><li>cycle throughout variables and update one each time. </li></ol></li></ol><h3 id="Marginal-as-Expectations"><a href="#Marginal-as-Expectations" class="headerlink" title="Marginal as Expectations"></a>Marginal as Expectations</h3><p>Before, there are all <em>deterministic</em> algorithms, now we turn to randomized algorithms. Using randomness to get a trade-off between computation time and accuracy.  The core idea is treat marginals as expectations and approximate expectation by sampling. </p><h4 id="Convergence"><a href="#Convergence" class="headerlink" title="Convergence"></a>Convergence</h4><p>The law of large numbers, valid on independent samples, gives a hope of convergence.<br>$$<br>\mathbb{E}_P[f(X)]=\sum_x P(x)f(x), \int P(x)f(x)\mathrm{d}x<br>$$<br>examples: </p><ul><li>marginals: $\Pr[X_i=x]=\mathbb{E}_P[[X_i=x]]$</li></ul><h4 id="Sampling-methods"><a href="#Sampling-methods" class="headerlink" title="Sampling methods"></a>Sampling methods</h4><p>How to sample from structured models, e.g. a Bayesian network?</p><ul><li>forward sampling Monte Carlo sampling, using the structure to sample step by step. Proceed according to the topological order.<ul><li>algorithm:<ol><li>sort variables in topological ordering $X_1,\cdots,X_n$</li><li>For $i = 1$ to n do<ol><li>sample $x_i$ according to the probability $P(X_i|X_1=x_1,…,X_{i-1}=x_{i-1})$</li></ol></li></ol></li><li>estimation of marginal: the mean of count of $X_i = x_i$</li><li>conditional: the joint divided by the marginal. one count divides another. <strong>Rejection sampling</strong>. Also, this algorithm can be <em>problematic</em> if the denominator event is very rare, could be 0 after sampling. </li></ul></li><li>sampling directly from posterior distribution to avoid the rare events effect, the case that the denominator almost 0, MCMC: ingenious idea: using some dependent variables to sample.</li></ul><h4 id="Complexity-1"><a href="#Complexity-1" class="headerlink" title="Complexity"></a>Complexity</h4><p>How many samples do we need?</p><ul><li>Hoeffding’s inequality: bound the relation between an estimation’s distance from the true expectation and its probability. </li></ul><p>We have two kinds of errors. Suppose $C=1$,</p><ul><li><p>absolute error: $\Pr[\hat{P}(x)\notin[P(x)-\epsilon, P(x)+\epsilon]]\leq 2\exp(-2N\epsilon^2)$</p></li><li><p>relative error: $\Pr[\hat{P}(x)\notin P(x)(1\pm\epsilon)]\leq 2\exp(-NP(x)\epsilon^2/3)$</p></li></ul><h3 id="MCMC"><a href="#MCMC" class="headerlink" title="MCMC"></a>MCMC</h3><p>The idea of MCMC is to directly sample from posterior distribution. Forward sampling couldn’t do this. Assuming that given evidences appear later than some variables according to the topological order, if we do forward sampling, we start from root/parents and may get only few of these samples with observed variables as the observed values. Forward sampling uses likelihood to sample, while MCMC uses posterior to sample.</p><h4 id="Settings-1"><a href="#Settings-1" class="headerlink" title="Settings"></a>Settings</h4><p>Given unnormalized distribution $Q(x)$, we want to sample from the normalized version $P(X) = Q(X)/Z$. For example, given $P(A,B,C)$ but we want to sample from $P(A|B,C)=P(A,B,C)/Z$, $Z$ is an unknown constant.</p><p>The solution is to create Markov chain from $Q(X)$, which has the stationary distribution $P(X)$ which we want to sample from.</p><p>An important statement: an</p><ul><li><em>ergodic</em> </li><li><em>Markov Chain</em><br>has a </li><li>unique </li><li>and positive stationary distribution $\pi(X)&gt;0$, such that for all $x$,$\lim_{t\to\infty}\Pr[X_t=x]=\pi(x)$</li></ul><h4 id="Detailed-Balance"><a href="#Detailed-Balance" class="headerlink" title="Detailed Balance"></a>Detailed Balance</h4><p>Detailed balance equation: $Q(x)P(x’|x)=Q(x’)P(x|x’)$ </p><p>In the our application, it builds the transfer from likelihood probability to posterior by the replacement in conditional distribution. The equation is<br>$$<br>Q(X_t=x)P(X_{t+1}=x’|X_t=x)=Q(X_{t+1}=x’)P(X_t=x|X_{t+1}=x’)<br>$$</p><h4 id="Algorithm-2"><a href="#Algorithm-2" class="headerlink" title="Algorithm"></a>Algorithm</h4><p>a framework</p><ol><li><p>provide a proposal distribution $R(X’|X)$​, this is chosen by ourselves. Performance of the algorithm will strongly depend on $R$. </p><p>What does the performance mean? Convergence? Complexity?</p><ul><li>bad proposal may cause alpha never been accepted. The state seldom moves.</li></ul></li><li><p>acceptance distribution:</p><ol><li>suppose $X_t=x$</li><li>accept the transition from R with probability $\alpha=\min{1,\frac{Q(x’)R(x|x’)}{Q(x)R(x’|x)}}$</li></ol></li></ol><p>Remarks:</p><ul><li>in the case that $R(x|x’)$ is symmetric, alpha is decided by $Q(x’)/Q(x)$. It means it will definitely transit to a value with higher probability $Q(x’)&gt;Q(x)$​. For a value with lower probability, it has some chance to transit to that $Q(x’)/Q(x)$.</li></ul><p>Theorem: the stationary distribution is $Z^{-1}Q(X).$</p><p>How to design the proposal? Why this proposal needs to satisfy the detailed balance equation?</p><h5 id="Gibbs-sampling"><a href="#Gibbs-sampling" class="headerlink" title="Gibbs sampling"></a>Gibbs sampling</h5><p>Algorithm:</p><ol><li>start with initial assignment $x(0)$ to all variables</li><li>fix observed variables $X_E$ to their observed values $x_E$</li><li>For t = 1 to infty do:<ol><li>set $x^{(t)}=x^{(t-1)}$</li><li>For each variable $X_i$ (not in E)<ol><li>set $v_i$=values of all $x^{(t)}$ except $x_i$</li><li>sample $x^{(t)}_i$ from $P(X_i|v_i)$</li></ol></li></ol></li></ol><p>In Gibbs sampling, we still use an unknown conditional distribution $P(X_i|v_i)$. Good news is this special type of conditional distribution, which conditions on everything except one variable, could be calculated efficiently.  Because when calculating the denominator, we focus on a small space where only the aimed variable takes different values. The space is $|V|$. The whole space’s size is $|V|^n$, hard to calculate.</p><p>Advantage:</p><ul><li>can do update parallel. </li></ul><p>Algorithm via Gibbs sampling</p><ol><li><p>use Gibbs sampling to obtain samples, $X^{(1)},\cdots, X^{(T)}$</p></li><li><p>ignore the first $t_0$ samples in “burn in” stage, and approximate</p><p>$$<br>\mathbb{E}<em>{x_E}[f(X)]\simeq\frac{1}{T-t_0}\sum</em>{\tau=t_0+1}^T f(X^{(\tau)}<br>$$</p></li></ol><h4 id="Convergence-1"><a href="#Convergence-1" class="headerlink" title="Convergence"></a>Convergence</h4><p>We want to use MCMC to answer the question, what is the expectation of some function $f(X)$ given the probability distribution. In the former, the law of large numbers works on the independent samples. Here, all of our samples are $x^{(t)}$​, sample at time t depends on sample at time $t-1$. How to calculate $E_p[f(X)]$ now?</p><p>Hopefully, we have <strong>ergodic theorem</strong>. This is a strong law of large numbers for Markov chain. </p><p>Ergodic theorem: </p><ul><li>suppose $X_1,X_2,\cdots,X_N, \cdots$ is an ergodic Markov chain </li><li>over a finite state space D, </li><li>with stationary distribution $\pi$. </li><li>$f$ is a function on D.</li></ul><p>Then, we have</p><p>$$<br>\lim_{N\to\infty}\frac{1}{N}\sum_{i=1}^N f(x_i)=\sum_{x\in D}\pi(x)f(x)=\mathbb{E}_{x\sim\pi}[f(x)]<br>$$</p><ul><li>how about the convergence rate?<ul><li>Establishing convergence rates generally very difficult. No Hoeffding for it</li></ul></li></ul><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><table><thead><tr><th>methods</th><th>Deterministic?</th><th>applicable cases</th><th>advantages</th><th>disadvantages</th></tr></thead><tbody><tr><td>variable elimination</td><td>Yes</td><td>tree-structured bayes net</td><td>exact marginals</td><td>not scalable to general models</td></tr><tr><td>belief propagation</td><td>Yes</td><td>tree-structed, loopy networks</td><td>efficiently compute all marginals</td><td>may not converge on loopy networks</td></tr><tr><td>variational inference</td><td>Yes</td><td>tree, loopy</td><td>fast, converge, good if having a lot of data</td><td>but the convergence may not be the exact solution</td></tr><tr><td>gibbs sampling</td><td>No</td><td>tree, loopy</td><td>converges to exact marginals</td><td>may take a long time</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Bayesian </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PAI1 Foundantion</title>
      <link href="/pai-01/"/>
      <url>/pai-01/</url>
      
        <content type="html"><![CDATA[<h2 id="Fundamental-Settings"><a href="#Fundamental-Settings" class="headerlink" title="Fundamental Settings"></a>Fundamental Settings</h2><p>Use Agent-environment model to represent all tasks.</p><h3 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h3><p>has a set $A$​ and a function $f$.</p><ul><li>$A$: the elements in $A$ are called actions.</li><li>$f$: map sequence of percepts to action $f: P\to A$</li></ul><h3 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h3><p>has a set $P$, a function $f$, a measure function $R$.</p><ul><li>$P$: the elements in $P$ are called percepts or environment states.</li><li>$f$: map sequence of actions to percept  $f:A\to P$</li><li>$R$: evaluates any given sequence of environment states: $R:S^\ast \to \mathbb{R}$ </li></ul><p>We want to design an agent to be rational, doing the right thing. How to define “right”?  Based on the evaluation of <strong>environment</strong> states. </p><p><strong>A rational agent</strong> is defined as: for each possible percept sequence, a rational agent should select an action that is expected to maximize its performance measure, given</p><ul><li>the evidence provided by the percept sequence </li><li>and whatever built-in knowledge the agent has.</li><li>? how to show this formally? How to mathematically evaluate the performance measurement related to agent’s built-in knowledge</li></ul><h1 id="Probability-Review"><a href="#Probability-Review" class="headerlink" title="Probability Review"></a>Probability Review</h1><h2 id="Basic-concepts"><a href="#Basic-concepts" class="headerlink" title="Basic concepts"></a>Basic concepts</h2><ul><li>Probability space: three elements: atomic events space Omega, can be continuous, sigma-algebra which is closed under complement and unions and probability measure. ${\Omega, F, P}, F \subseteq 2^{\Omega}, P:F\to [0,1]$ </li><li>probability axioms: <ul><li><p>normalization, making the probability of the whole set is 1: $\text{Pr}(\Omega)=1$ </p></li><li><p>non-negativity, all the probability is larger than 0: $\Pr[A]\geq 0,\forall A\in F$ </p></li><li><p>“add operation” sigma-additivity, the probability of the union of disjoint sets are the sum of the probability of each set:<br>$$<br>\Pr[\bigcup_{i=1}A_i]=\sum_{i=1}\Pr[A_i],\forall A_i\in F \text{ and } A_i\cap A_j=\phi, i\neq j<br>$$</p><ul><li>this axiom builds the relation between the “add” operation in the algebra and the “union” operation in the set theory.</li></ul></li><li><p>From the three axioms, we can deduct:</p><ul><li>“minus” operation: $\Pr[\Omega-A]=1-\Pr[A]$ </li><li>“empty”: $\Pr[\phi]=0$ </li><li>“minus” operation: $5CPr[A-B]=\Pr[A]-\Pr[A\cap B]$ since $A-B$ and $A\cap B$​ are disjoint. All minus operations are from add operations</li><li>“inclusion-exclusion principle” $\Pr[A\cup B]=\Pr[A]+\Pr[B]-\Pr[A\cap B]$​</li><li>“inequality”: $A\subset B\Rightarrow\Pr[A]\leq\Pr[B]$ </li></ul></li></ul></li></ul><h2 id="Derivatives"><a href="#Derivatives" class="headerlink" title="Derivatives"></a>Derivatives</h2><p>Based on the basic definitions, we can define more advanced concepts, such as independent events, conditional probability</p><h3 id="Independence"><a href="#Independence" class="headerlink" title="Independence"></a>Independence</h3><ul><li><p>independent events: two random events A, A’ are independent iff $P(A\cap A’)=P(A)P(A’)$ </p><ul><li>event is a subset of the sample space Omega.</li><li>the left side means the probability of the joint of two sets</li><li>the right side means the multiplication of two probabilities</li><li>this definition connects the calculation of sets with the calculation of numbers. In some way, map the “joint” operation to the “multiplication” operation. </li></ul></li><li><p>random variable: <strong>A random variable is a mapping.</strong> Denote it as $X$. Given a set  D, $X: \Omega\to D$ . How to define probability for the element(s) in $D$? Based on the corresponding elements in $\Omega$​​. That is<br>$$<br>x\in D, \Pr[X=x]=\Pr[{w: X(w)=x, w\in\Omega}]<br>$$</p><ul><li>the left side is the probability definition on a new set $D$</li><li>the right side is the corresponding probability on the on the original whole set $\Omega $​.</li><li>I would call the left side is a symbol for representation while right side is the essence. </li><li>??? Does it mean all elements in $\Omega $​ must have a corresponding element in $D$​? <ul><li>Yes!!! $X$ is defined on the <strong>whole</strong> $\Omega $. That implies $\sum_{x} \Pr[X=x]=1$</li></ul></li><li>??? Does it mean X must be deterministic???</li><li> How to interpret that in continuous settings? In continuous distribution, no “good” definition of the probability of a point.</li><li>From <a href="https://en.wikipedia.org/wiki/Elementary_event">this wiki</a>, “in a continuous distribution, individual elementary events must all have a probability  of zero because there are infinitely many of them— then non-zero  probabilities can only be assigned to non-elementary events.”</li><li>I think the definition may comes from a more advanced concept <a href="https://en.wikipedia.org/wiki/Borel_set">Borel-algebra</a>. Also in the first chapter in this book <a href="https://books.google.ch/books?id=uL7UBwAAQBAJ&amp;pg=PA1&amp;hl=zh-CN&amp;source=gbs_toc_r&amp;cad=4#v=onepage&amp;q&amp;f=false">Foundations of Modern Probability</a>, it says something about the Borel-algebra, which is beyond my understanding. But it convinces me that this kind definition of probability works.</li></ul></li><li><p>independent random variable: two random variables are independent iff $P(xy)=P(x)P(y),\forall x\in X(\cdot), y\in Y(\cdot)$ </p><ul><li><p>different from independent events, which could be represented easily be the set (Vien graph), independent random variables are not straightforward in the Vien, because both of them work on the whole sample space. But we can show the Vien graph of their specific values.</p></li><li><p> use $X\perp Y$​ to denote $X$​ and $Y$​ are independent. This notation is very descriptive. Taking the algebra  view, $X$​ and $Y$​ are “orthogonal” to each other. For instance, supposing the sample space Omega is a cube. $X$ maps it to the $z$ axis, and $Y$ maps it to the $y$ axis. Then for any pair of $(x,y), P(xy)$ , shown in the Vien graph is a rectangle in surface y-z,  is exactly $P(x)P(y)$, which are two orthogonal rectangles with an overlapped rectangle.</p></li></ul></li></ul><h3 id="Joint-distributions"><a href="#Joint-distributions" class="headerlink" title="Joint distributions"></a>Joint distributions</h3><p>Instead of random variable, using random vector of several variables. </p><p>$X=[X_1(w),X_2(w),\cdots, X_n(w)]$ and $\Pr[X=v_n]=\Pr[X_1(w)=v_1,X_2(w)=v_2,\cdots, X_n(w)=v_n]$</p><ul><li><p>Interpreted from the set theory view: supposing the Omega has high dimension and we use a n-dimension lense to inspect it to find the aimed subspace.</p></li><li><p>note that each item is a random variable, that means $\sum_{x} \Pr[X_i=x]&lt;1$, we cannot have $\sum_{x} \Pr[X_i=x,Y]=\Pr[Y]$</p></li></ul><h3 id="Conditional-probability"><a href="#Conditional-probability" class="headerlink" title="Conditional probability"></a>Conditional probability</h3><p>Define a new operator “|” in the probability theory<br>$$<br>\Pr[A|B]=\frac{\Pr[A\cap B]}{\Pr[B]},\Pr[B]&gt;0<br>$$</p><ul><li>Observation of the left-side (set theory view): it actually changes the event space to the set of $B$ from the original set $\Omega.$</li><li>calculation view: introduce the division in the probability theory.</li></ul><h2 id="Sum-rule-and-product-rule"><a href="#Sum-rule-and-product-rule" class="headerlink" title="Sum rule and product rule"></a>Sum rule and product rule</h2><ul><li><p>sum rule marginalization: an application of the add-operation of disjoint sets<br>$$<br>\Pr[X_{1: i-1}，X_{i+1: n}]=\sum_{x_i}\Pr[X_{1:i-1},x_i,X_{i+1: n}]<br>$$</p></li><li><p>product rule chain rule: an application of the definition of conditional probability.<br>$$<br>\Pr[X_{1:n}]=\Pr[X_n|X_{1:n-1}]\cdots\Pr[X_3|X_1X_2]\Pr[X_2|X_1]\Pr[X_1]<br>$$</p></li><li><p>Application: Bayes’ Rule: from the prior $P(X)$ and likelihood $P(Y|X)$ to compute the posterior $P(X|Y)$</p><p>$$<br>\Pr[X|Y]=\frac{\Pr[X]\Pr[Y|X]}{\sum_x\Pr[X]\Pr[Y|X]}<br>$$</p><ul><li>the nominator: product rule</li><li>the denominator: sum rule, then product rule</li></ul></li></ul><h2 id="Operations-in-Probability"><a href="#Operations-in-Probability" class="headerlink" title="Operations in Probability"></a>Operations in Probability</h2><h3 id="Operators"><a href="#Operators" class="headerlink" title="Operators"></a>Operators</h3><ul><li>and: $\cap$​  or $,$  or missed, e.g. $P(A\cap B) = P(A,B) = P(AB) $​</li><li>or: $\cup$, e.g. $P(A\cup B),P(A\cup B) = P(A) + P(B)-P(A\cap B)$​</li><li>conditional: $|$, e.g. $P(A| B)=\frac{P(AB)}{P(B)}$<ul><li>this operator is a little bit tricky, cause if considering the sample space, “and” and “or” operators are in the original sample space but “conditional” operator <strong>changes</strong> the sample space !!!</li></ul></li><li>conditional independence: $\perp$,e.g.$P((A\perp B)|C) = P(A|C)P(B|C)$</li></ul><p>Priorities from lowest to highest: $| &lt; \perp &lt; \cap, \cup$</p><p>For example, $P(A,B|C) = P((A,B)|C)\neq P(A,(B|C))$</p><ul><li><p>“and” could be viewed as “multiply” $\ast$​ in algebra operations in some way</p><ul><li>exchangeable: $P(A\cap B)= P(B\cap A)$</li></ul></li><li><p>“conditional” could be viewed as “plus” $+$, always the lowest</p><ul><li><p>but it is <strong>not exchangeable</strong>, that means $P(A| B)\neq P(B|A)$</p></li><li><p>it is <strong>ordered</strong>. I am not sure which order it exactly is. Just from my own understanding, the order should be from right to left,  which means $P(A|B|C) = P(A|(B|C))\neq P((A|B)|C)$</p><p>My explanation is as follows:</p><ul><li><p>suppose$P(A|B|C) = P(A|(B|C))$ We will have<br>$$<br>P(A|(B|C)) = \frac{P(A,(B|C))}{P(B|C)} = \frac{P((AB)|C)}{P(B|C)}<br>$$</p><p>$$<br>=\frac{P(ABC)P(C)}{P(C)P(BC)}=\frac{P(ABC)}{P(BC)}=P(A|(BC))<br>$$</p><ul><li><p>the second equality uses the “reducing rule”, explained in the next block.</p></li><li><p>this directly gives us the conclusion that $P(A|B|C) =P(A|(BC))$</p></li><li><p>generate it to the n cases, we will have </p><p>$$<br>P(A_n|A_{n-1}|\cdots|A_1) = P(A_n|(A_{n-1}(\cdots |A_1)))<br>$$</p><p>$$<br>= P(A_n|(A_{n-1}\cdots A_1))<br>$$</p><p>The proof is ignored here. Using induction will easily prove it.</p></li></ul></li><li><p>suppose $P(A|B|C) = P((A|B)|C)$​ We will have<br>$$<br>P((A|B)|C)=\frac{P((A|B),C)}{P(C)}=\frac{P(C(A|B))}{P(C)}<br>$$</p><p>$$<br>=\frac{P((AC)|B)}{P(C)}=\frac{P(ABC)}{P(B)P(C)}<br>$$</p><ul><li>also, the third equality uses the “reducing rule”</li><li>well, I couldn’t find error in the algebra calculation but from the definition of probability, using $P(B)P(C)$ as the denominator, I don’t know what the sample space becomes. Based on this aspect, I will refuse this assumption and take the former one.</li></ul></li></ul></li></ul></li></ul><h3 id="Rules"><a href="#Rules" class="headerlink" title="Rules"></a>Rules</h3><p>This part is based on my own deduction, I am not sure if they are true. Please contact me if you have other ideas! I would greatly appreciate it.</p><ul><li><p>“reducing rule”: $P(A(B|C)) = P((AB)|C)$</p><ul><li><p>just like the “conditional” operator, this rule is also tricky, cause $A$ and $B|C$ are in the different sample space. Here, I would reduce the larger sample space to the smaller sample space. That is reducing $A$ to $A|C$ actually.  By doing this, We will have </p><p>$$<br>P(A(B|C))=P((A|C)(B|C))=P((AB)|C)<br>$$</p></li></ul></li><li><p>“association rule”: $P(A(BC)) = P((AB)C)=P(ABC)$</p><ul><li>from the set view, the proof is trivial.</li></ul></li></ul><h1 id="Probabilistic-propositional-logic"><a href="#Probabilistic-propositional-logic" class="headerlink" title="Probabilistic propositional logic"></a>Probabilistic propositional logic</h1><p>So far, we define the “probability” from the set theory view and so for the operations, which could be interpreted as the set operations.</p><p>How to express uncertainty about logical propositions?</p><p>The probability of a proposition is the probability mass of all <strong>models</strong> of it.</p><ul><li>model: all <strong>events</strong> that make the proposition true</li><li>event: encode assignment to all propositional symbols.</li></ul><p>In the paper <a href="https://faculty.arts.ubc.ca/pbartha/p520w07/comp_logic.pdf">probability, logic and probability logic</a>, there is a definition of probability theory from the logic theory view.</p><p>S: a collection of sentences of a language, closed under finite truth-functional combinations, with the following axiomatization:</p><ul><li>normalization $\text{Pr}(T)=1$, If $T$ is a tautology</li><li>non-negativity: $\Pr[A]\geq 0,\forall A\in S$</li><li>“add operation”:  $\Pr[A\lor B]=\Pr[A]+\Pr[B]$ for all $A$ and $B$ in $S$, such that $A$ and $B$ are logically incompatible.</li></ul><h3 id="Examples-given-in-the-lecture"><a href="#Examples-given-in-the-lecture" class="headerlink" title="Examples given in the lecture"></a>Examples given in the lecture</h3><p>The method is:</p><ol><li>degrade the logical operations, e.g. imply,  to the most basic three operations: and, or and not</li><li>go to the set theory, find the corresponding set of the logical expression and calculate the probability of the set</li></ol><table><thead><tr><th></th><th>Toothache</th><th>Toothache</th><th>no toothache</th><th>no toothache</th></tr></thead><tbody><tr><td>-</td><td>catch</td><td>no catch</td><td>catch</td><td>no catch</td></tr><tr><td>cavity</td><td>0.108</td><td>0.012</td><td>0.072</td><td>0.008</td></tr><tr><td>no cavity</td><td>0.016</td><td>0.064</td><td>0.144</td><td>0.576</td></tr></tbody></table><p>$P(toothache)$​​​? find the corresponding set  the left two columns $P(toothache)=0.108+0.016+0.012+0.064=0.2$</p><p>$P(toothache=&gt;cavity)$?</p><ol><li><p>degrade into and, or and not: $A\Rightarrow B\Leftrightarrow \lnot A\vee B$</p></li><li><p>not toothache correspondents to the right two columnes, cavity correspondents to the first row. Then take the union of them.</p><p>$= 0.108+0.012+0.072+0.008+0.144+0.576=0.92$</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Probability Theory </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PAI2 Bayesian Network 1Basic</title>
      <link href="/pai-02/"/>
      <url>/pai-02/</url>
      
        <content type="html"><![CDATA[<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><ul><li>why to say the conditional independence is weaker than independence?</li><li>what are the properties of conditional independence? How to compare them with independence?</li><li>what is the definition of bayesian network? </li><li>what is the relation between conditional independence and bayesian network?</li><li>what are the advantages of bayesian network?</li></ul><h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><p>conditional independence, naive bayes models, bayesian networks</p><h1 id="Conditional-independence"><a href="#Conditional-independence" class="headerlink" title="Conditional independence"></a>Conditional independence</h1><p>Using independence in formula will greatly decrease the number of parameters from $O(2^n)$  to some smaller numbers, even $O(n)$ </p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>$A$ and $B$, two random variables, are conditional independence given $C$ iff for all $a,b,c$<br>$$<br>\text{Pr}(A=a\cap B=b|C=c) = \text{Pr}(A=a|C=c)\text{Pr}(B=b|C=c)$​<br>$$</p><ul><li>$\Pr[Y=y|Z=z]&gt;0, \Pr[X=x|Y=y,Z=z]=\Pr[X=x|Z=z]$</li></ul><p>It is denoted as$(X\perp Y) | Z$</p><h2 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h2><p>Claim: all of the following properties should have non-conditional version</p><ul><li><p>symmetry: $(X\perp Y)|Z \Leftrightarrow (Y\perp X)|Z$</p><ul><li>The proof is trivial</li></ul></li><li><p>decomposition: Given Z, X is conditional independent from Y and W. We can conclude that X is conditional independent from Y and X is conditional independent from W specifically.<br>$$<br>(X\perp (Y,W))|Z \Leftrightarrow (X\perp Y)|Z \wedge  (X\perp W)|Z<br>$$</p><ul><li><p>Proof left to right: Since Y and W are symmetric, I only prove for $Y$ in discrete version. The continuous version is similar<br>$$<br>(X\perp (Y,W))|Z\Leftrightarrow  P((XYW)|Z)=P((X(YW))|Z)<br>$$</p><p>$$<br> = P(X|Z)P((YW)|Z)<br>$$</p><p>$$<br>\Rightarrow P((XY)|Z) = \sum_W P((XYW)|Z) = \sum_W P(X|Z)P((YW)|Z)<br>$$</p><p>$$<br>= P(X|Z)\sum_W P((YW)|Z) = P(X|Z)P(Y|Z)<br>$$</p><p>$$<br>\Rightarrow (X\perp Y)|Z<br>$$</p></li><li><p>Proof  right to left: I <strong>don’t know</strong> how to prove it. ?????maybe it is not true??</p></li></ul></li><li><p>Contraction: $((X\perp Y)|Z)\wedge (X\perp W|(YZ))\Rightarrow (X\perp (WY))|Z$</p></li><li><p>weak union: $(X\perp (YW))|Z\Rightarrow (X\perp Y)|(ZW)$</p></li><li><p>intersection:$(X\perp Y)|(WZ)\wedge (X\perp W)|(YZ)\Rightarrow (X\perp(YW))|Z$</p></li></ul><h2 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h2><p>Example: In a naive bayes model, where: $Y$​ is the cause variable, $X_1,\cdots,X_n$​ are the effects variables. <img src="chap201.jpg" alt="A naive Bayes model example"></p><p>We can give a conditional independence assertion: </p><p>$$<br>X_A\perp X_{\bar{A}}|Y,\forall A\subset{1,2,\cdots,n}<br>$$<br>Where$ A={i_1,\cdots,i_k}\subset{1,2,\cdots,n}$ and $\bar{A}={1,2,\cdots,n}$ $A, X_A={X_{i_1},\cdots,X_{i_k}}$</p><p>In general, conditional independence can be used to transfer <strong>joint parameterization</strong> into <strong>conditional parameterization</strong>. In this way, we can greatly reduce the number of parameters. Formally,</p><p>$$<br>\Pr[X_{1:n}]=\prod_{i=1}^n\Pr[X_i|parents(X_i)]<br>$$</p><p>The number of parameters change: $\prod_{i=1}^n |X_i|\to \sum_{i=1}^n |X_i|^{\prod_{X_j\in parents(X_i)}|X_j|}$</p><h1 id="Bayesian-Network"><a href="#Bayesian-Network" class="headerlink" title="Bayesian Network"></a>Bayesian Network</h1><ul><li>Bayesian: uses the Bayes’ theorem, which specifies an event’s probability given some conditions.</li><li>network: represented by directed graph, as a network.</li></ul><h3 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h3><p>A Bayesian Network is a <em>directed acyclic graph</em> in which:</p><ul><li>node:<ul><li>each node corresponds to a random <em>variable</em></li><li>numeric parameters: each node has a <em>conditional</em> probability distribution $P(x|\text{parents}(x))$</li></ul></li><li>links:<ul><li>a link from node $X$ to node $Y, X$ is said to be a <em>parent</em> of $Y$.</li><li>intuitive meaning: $X$ is a <em>parent</em> of $Y\to X$ has a <em>direct impact</em> on $Y$. Causes should be parents of effects.</li></ul></li><li>No directed cycles. It is a DAG</li></ul><h4 id="Semantics"><a href="#Semantics" class="headerlink" title="Semantics"></a>Semantics</h4><p>Two ways to understand the semantics of Bayesian Network:</p><ol><li>as a representation of the joint probability distribution</li><li>as an encoding of a collection of conditional independence statements.</li></ol><h4 id="Structures"><a href="#Structures" class="headerlink" title="Structures"></a>Structures</h4><p>$$<br>X\perp Z|Y,\neg X\perp Z<br>$$</p><ul><li>$x\leftarrow y\to z$: common cause</li><li>$x\leftarrow y\leftarrow z$: indirect evidential effect</li><li>$x\to y\to z$: indirect causal effect</li></ul><p>$$<br> \neg X\perp Z|Y, X\perp Z<br>$$</p><ul><li>$x\to y \leftarrow z$: common effect</li></ul><h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><h3 id="Build-algorithm"><a href="#Build-algorithm" class="headerlink" title="Build algorithm"></a>Build algorithm</h3><ol><li><p>Nodes: </p><ol><li>determine the set of variables that are required to model the domain.</li><li>Order them ${X_1,\cdots,X_n}$. <strong>Any order will work</strong>. But the resulting network will be more compact if the variables are ordered such that causes precede effects.</li></ol></li><li><p>Links: For each $X_i$ do:</p><ol><li>find the <em>minimal parent subset A</em> from ${1,2,\cdots,i-1}$​, s.t. $P(X_i|{1,2,\cdots,i-1})=P(X_i|A)$​ <ul><li>in some way, minimal means direct influence.  For example, some variable in ${1,2,\cdots,i-1}$ may have indirect influence on $X_i$, through a variable $X_k$. Then, if we include $X_k$, they are excluded.</li></ul></li><li>for each parent $X_k$ in A, insert a link from $X_k$ to $X_i$ </li><li>write down the conditional probability table.</li></ol></li></ol><h3 id="Identification-of-conditional-independence"><a href="#Identification-of-conditional-independence" class="headerlink" title="Identification of conditional independence"></a>Identification of conditional independence</h3><p>Not independent/dependent can transmit conditions. That means if we know some condition, all variables not independent of it are known or partially known.</p><p>Given a Bayesian network, how to find the independence relationship between variables from the network structures?</p><p>An important theorem says:</p><p>$$<br>\text{d-sep}(X;Y|Z)\Rightarrow (X\perp Y)|Z<br>$$<br>converse does not hold in general, but for “almost” all distributions.</p><h4 id="d-separation"><a href="#d-separation" class="headerlink" title="d-separation"></a>d-separation</h4><p> This term describes a structural relation between variables in a given network. We can connect this structural relation with independence relation.</p><p>Given observed variables $O$​, any variables Xi and Xj for which there is <strong>no active trail</strong> are called <em>d-separated</em> by $O$​.  Written as $\text{d-sep}(X_i;X_j|O) $​</p><ul><li><p>active trail: an undirected path in BN structure G is called active trail for observed variables $O\subset{X_1,X_2,\cdots,X_n}$​, if for every consecutive triple of vars $X,Y,Z$ on the path</p><ul><li>$X\to Y\to Z,Y\notin O$</li><li>$ X\gets Y\gets Z,Y\notin O$</li><li>$ X\gets Y\to Z,Y\notin O$</li><li>$X\to Y\gets Z$, and $Y$ or any of $Y$’s descendants is observed.</li></ul></li><li><p>linear time algorithm for d-separation: find all nodes active trail reachable from $X$</p><ol><li><p>mark $Z$ and its ancestors</p></li><li><p>do breath-first search starting from $X$; stop if path is blocked</p></li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Bayesian </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PAI course notes</title>
      <link href="/pai-readme/"/>
      <url>/pai-readme/</url>
      
        <content type="html"><![CDATA[<p>I took part in the course <a href="https://las.inf.ethz.ch/pai-f19">Probabilistic Artifical Intelligence</a> in the autumn festival 2019, which is opened by the super star<span class="github-emoji"><span>🌟</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span><a href="https://las.inf.ethz.ch/krausea">Professor Andreas Krause</a>. This serie of notes was created during my review of the course  and contained the main ideas/concepts/methods of each lecture, my own thoughts/ideas/questions as well as out-of-class helpful materials. For more detailed information, please refer to the lecture notes posted on the course homepage.</p><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>The focus of this course is about <strong>reasoning and decision making under uncertainty</strong>.</p><ul><li>Probabilistic reasoning<ul><li>Bayes Net</li><li>graphical models</li></ul></li><li>Learning<ul><li>Bayesian deep learning</li></ul></li><li>Planning under uncertainty<ul><li>MDPs</li><li>POMDPs</li></ul></li><li>Deep reinforcement learning</li></ul><h1 id="Content"><a href="#Content" class="headerlink" title="Content"></a>Content</h1><ul><li><p><a href="../PAI-01/index.html">Foundamention</a></p></li><li><p><a href="../PAI-02/index.html">Bayesian Network 1 - Basic</a></p></li><li><p><a href="../PAI-03/index.html">Bayesian Network 2 - Inference</a></p></li><li><p><a href="../PAI-04/index.html">Reasoning over Time</a></p></li><li><p><a href="../PAI-05/index.html">Probabilistic Planning</a></p></li><li><p><a href="../PAI-06/index.html">Learning</a></p></li><li><p><a href="../PAI-07/index.html">Reinforcement Learning</a></p></li></ul><h1 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h1><p>Below is my cheatsheet for the final exam.</p><div class="row">    <embed src="2019.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
      
      
      <categories>
          
          <category> Sharing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Reinforcement Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Advanced algorithms review notes</title>
      <link href="/aa-review/"/>
      <url>/aa-review/</url>
      
        <content type="html"><![CDATA[<h1 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h1><p>In 2019 fall semester, I took part in the course <a href="https://people.inf.ethz.ch/gmohsen/AA19/">Advanced algorithms</a>, opened by <a href="https://people.inf.ethz.ch/gmohsen/">Mohsen Ghaffari</a>, ETH Zurich. Mohsen is a genius professor and he gives us a lot of help on this course outside the lectures. Honestly, this course is challenging for me but I have indeed learned a lot from that. Lecture notes, tutorials, graded homework and the programming projects all bring me a lot of fun. The feeling of taking this course is like playing a series of puzzles, both struggling and addictive. Eureka is a gift for brain storming. Thanks for professor Mohsen, the tutors and my colleagues David, Karolis and Rok. They make me enjoy this period very much. </p><p>This review generally gives a summary of important methodologies of each part of this course, covering few details. Although technical details matter a lot of an algorithm, methodologies work as a guide to create concrete algorithms.  From my experience, the order of creating an algorithm is contrary to the presentation in the notes, which prove each claim first then give the last conclusion. The real birth process of an algorithm could be: I want something, how to get it? If it satisfies these, I gonna make the algorithm. How to satisfy these conditions, we design this, this that… It is motivated by some methodology. </p><p>The order of this review follows the lecture notes, and parts are divided basically following the notes. Helpful references are also included.</p><p>There are totally four parts:</p><ul><li>approximation algorithms</li><li>streaming and sketching algorithms</li><li>graph sparsification</li><li>online algorithms and competitive analysis</li></ul><h1 id="Approximation-algorithms"><a href="#Approximation-algorithms" class="headerlink" title="Approximation algorithms"></a>Approximation algorithms</h1><h2 id="Greedy-algorithms"><a href="#Greedy-algorithms" class="headerlink" title="Greedy algorithms"></a>Greedy algorithms</h2><p>Mohsen’s summary:</p><p>from the first lecture, you should take away some idea about </p><ul><li>how to approach computational problems using natural “greedy” ideas and more importantly, </li><li>how to analyze the performance of your idea by comparing it to the best possible solution, even though we don’t know the latter. This often involves </li><li>understanding some structure of the problem and lower bounding the performance of OPT, by basic observations, </li><li>and relating your algorithm’s performance to these simple bounds on OPT.</li></ul><p>For me, I learn to know</p><ul><li>the meaning of “approximation algorithm” when dealing with hard problems, e.g. NP-hard problems. </li><li>how to design the algorithm: usually very intuitive. Greedy approach means local optimal, the best strategy for each step.</li><li>how to analyze the approximation ratio of the designed algorithm:<ul><li>formally write the objective function</li><li>build inequality (lower bound/upper bound) from the designed algorithm and the property of question for OPT and the designed algorithm</li><li>relates c(ALG) to c(OPT)</li></ul></li></ul><h2 id="Approximation-schemes"><a href="#Approximation-schemes" class="headerlink" title="Approximation schemes"></a>Approximation schemes</h2><p>Mohsen’s summary: </p><p>from the PTAS, FPTAS lectures, you take away the idea that,</p><ul><li> sometimes, by slightly changing the parameters of the problem (e.g., by rounding the input data), you can </li><li>turn the problem into a much easier one—computationally—</li><li>while still not sacrificing too much in the quality of the<br>solution. </li><li> Designing such schemes usually involves understanding what kind of instances are easier computationally (e.g., by building a corresponding Dynamic Programming) as well as</li><li> getting a feeling for the parameters that can be changed without introducing too much error — for instance, recall the intuitive discussion in the class about soft constraints and hard constraints.</li></ul><p>For me, I learn to:</p><ul><li><p>the framework of PTAS(FPTAS): transfer from an exact solution of a special problem to an approximate algorithm of a more general problem.</p><ol><li>design an exact solution of a special case</li><li>analyze the time complexity, find which part is computational expensive, beyond polynomial in other words</li><li>round the general problem to the special case to deal with expensive parts, may involve classifying the instances and process each of them by different approaches.</li></ol></li><li><p>Creative points lie on the round strategy. That is how to round to trade off the computational complexity and the precision. For instance, to deal with the minimum makespan problem, inspired by the 4/3-approximation algorithm, we get a general method:</p><ul><li>split the whole jobs as short jobs and long jobs<ul><li>for long jobs: we compute the optimal schedule for them</li><li>for short jobs: we extend that partial schedule by using FirstFit algorithm.</li><li>In this way, we trade off between the number of long jobs and the quality of solutions.</li></ul></li><li>bound the “polynomial” property on m: the key idea is that we didn’t really need the schedule for the long jobs to be optimal. We use the optimality of the schedule for the long jobs only when the last job to finish was a long job. If we have found a schedule for the long jobs that have makespan at most 1+1/k times the optimal value, that clearly would have been sufficient.</li></ul></li></ul><h2 id="Randomized-approximation-schemes"><a href="#Randomized-approximation-schemes" class="headerlink" title="Randomized approximation schemes"></a>Randomized approximation schemes</h2><p>Mohsen’s summary:</p><p>from the FPRAS lectures, you should </p><ul><li>recall the idea of Monte Cato sampling for estimating various problems. </li><li>Moreover, you can get an understanding of why this natural and frequently used idea, on its own, might be insufficient for some problems, when the quantity that is to be estimated is only a tiny fraction of the whole (sampling) space. </li><li>Then, we saw some schemes that allow us to view the target quantity as a simple function of other quantities that can be computed/estimated more efficiently. For instance, for DNF counting, the number of satisfying assignments for each clause is easy to compute and we saw how to estimate the total number of satisfying assignments of the whole formula by, roughly speaking, estimating for each clause the fraction of satisfying assignments for which this clause can take the credit (i.e., is the first satisfied clause), weighted by the number of satisfying assignments for each clause.</li></ul><p>For me, I learn:</p><ul><li>the sampling trick when the whole space is “much larger” (e.g. in exponential level) than the goal space<ul><li>redefine the whole space with some properties.</li><li>sample step by step </li></ul></li><li>express the objective by newly defined random variable to make the expectation of this expression as our objective.</li><li>design sampling times to satisfy the approximation requirement.</li></ul><h2 id="Rounding-ILPs"><a href="#Rounding-ILPs" class="headerlink" title="Rounding ILPs"></a>Rounding ILPs</h2><p>Mohsen’s summary:</p><p>from the LP rounding lecture, you should take away the idea of </p><ul><li>how to formulate some optimization problems as a linear programs (with a linear objective function and linear constraints<br>on your variables) </li><li>and how you can transform a fractional solution of this LP to an integral solutions by, e.g., randomized rounding. </li><li>You should also start building an intuition for when just<br>a deterministic rounding suffices-e.g., think about the minimum-weight vertex cover problem, and</li><li>moreover, how to use probabilistic analysis to argue about the performance of your randomly rounded integral solutions, in comparison with the corresponding fractional solution.</li></ul><p>For me, I also learn:</p><ul><li>the way to round back the integer solution to the original problem, by virtue of probability interpretation of the solution.</li></ul><h2 id="Tree-Embedding"><a href="#Tree-Embedding" class="headerlink" title="Tree Embedding"></a>Tree Embedding</h2><p>Mohsen’s summary:</p><p>from the tree imbedding lectures you can take away </p><ul><li>the existence of a tree that “approximates” distances in a general graph (actually, a random tree or formally a probability distribution over a collection of trees) and </li><li>how this enables us to build approximation algorithm for some graph problems, by <ul><li>first transforming the input graph to a tree—via tree embeddings—, </li><li>then solving the problem on that tree, </li><li>and finally projecting the solution back to the original graph.</li></ul></li><li>We then have to argue about the quality of the solution. Often, we just lose an O(logn) factor in the approximation, because of how much the tree stretches the distances, in expectation.</li></ul><p>The summary is enough for me.</p><h1 id="Streaming-and-sketching-algorithms"><a href="#Streaming-and-sketching-algorithms" class="headerlink" title="Streaming and sketching algorithms"></a>Streaming and sketching algorithms</h1><p>In this chapter, we discuss the algorithms under the “streaming data” situation, where exact and deterministic algorithms may not work. I have learnt how to save memory space by randomization and  how to build proper data summary with limited size to approximate the objective, and some tricks to increase the success probability. </p><h2 id="Streaming-algorithms"><a href="#Streaming-algorithms" class="headerlink" title="Streaming algorithms"></a>Streaming algorithms</h2><p>The general framework for the streaming algorithms:</p><ul><li>randomize the “original” expression (the  trick is called “<strong>random projection</strong>“ )and update summary when some condition satisfied. For instance<ul><li>in estimating the zero-th moment, each number is uniformly hashed to an unary expression</li><li>in estimating the first moment, we take a uniform distributed variable for each element (not number)</li><li>in estimating the second moment, each number is mapped randomly to a predefined label {+1,-1}.</li></ul></li><li>design a summary whose expectation is our objective</li><li>make the probability of being away from the objective is smaller than a “big enough” number (e.g. any little constant is enough)</li><li>increase the success probability by some trick:<ul><li>mean trick: to reduce the variance. If we can limit the probability of the variable being away from the expectation by using Chebyshev inequality (involving variance in the proof process), we can make it very low. Make new X’ as the mean of T independent X. If we want the probability less than \delta, T = O(1/\sqrt{\delta})</li><li>median trick: if one single event’s success probability is larger than 0.5, we can take the median of T independent events, whose success probability could be as large as we want. T = O(log 1/\delta)</li></ul></li><li>A useful trick: logarithmic trick.  For some upper bound M, consider the sequence (1+\epsilon), (1+\epsilon)^2, \cdots, (1+\epsilon)^{log_{1+\epsilon}M}. We can approximate by log M turns of experiment instead of M turns.</li></ul><h2 id="Graph-sketching"><a href="#Graph-sketching" class="headerlink" title="Graph sketching"></a>Graph sketching</h2><p>In this lecture, we learn to use limited-memory algorithms to store graph information presented by an edge stream and to keep some desired properties.</p><p>From the survey <a href="http://alpha.luc.ac.be/~lucg5503/sr/mcg.pdf">Graph Stream Algorithms: A Surve</a>, the algorithms of graph streaming data must do the following things:</p><ul><li>process the input stream in the order it arrives</li><li>use a limited amount memory</li></ul><p>In other words, these algorithms should solve the following questions:</p><ul><li>how to trade-off size and accuracy when constructing data summaries</li><li>how to quickly update these summaries</li></ul><p>A classic algorithm is called “semi-streaming model”, which uses O(n polylogn) memory to store the graph.</p><p>The common framework is to </p><ol><li>find a trivial algorithm on the offline whole graph</li><li>represent the graph using suitable trick and apply the algorithm on newly representations.</li></ol><h1 id="Graph-Sparsification"><a href="#Graph-Sparsification" class="headerlink" title="Graph Sparsification"></a>Graph Sparsification</h1><p>The learning objective is to sparsify a graph with fewer edges but still keep the distance between pairs of nodes not very long. Different approaches are applied corresponding to different constraint of lengths.</p><ul><li>multiplicative constraint: use a family of graph with girth larger than a constant k. Such a graph has the property of trade-off between girth and edge numbers. The approach is to build such a graph from the original graph.</li><li>additive constraint: classify the nodes as light nodes and heavy nodes according to their degree. <ul><li>Light nodes could not have too many edges </li><li>For heavy nodes, we can do some sampling on nodes and add BFS tree (promise the distance between the root and other nodes) rooted at sampled nodes. Since they are heavy, they have a large probability of having a sampled neighbor. </li></ul></li></ul><h1 id="Online-algorithms-and-competitive-analysis"><a href="#Online-algorithms-and-competitive-analysis" class="headerlink" title="Online algorithms and competitive analysis"></a>Online algorithms and competitive analysis</h1><p>In this chapter, we learn to design algorithms with incomplete information, how to compare its performance with algorithms with complete information and how to design adversary against an online algorithm to prove the competitive ratio.  There are several important concepts/ideas in this chapter, basically refered from <a href="https://www.icsi.berkeley.edu/pubs/techreports/TR-92-044.pdf">on-line algorithms versus off-line algorithms: how much is it worth to know the future?</a>.</p><h2 id="Online-VS-offline-algorithms"><a href="#Online-VS-offline-algorithms" class="headerlink" title="Online VS offline algorithms:"></a>Online VS offline algorithms:</h2><ul><li>online: <ul><li>receive a sequence of requests</li><li>perform an immediate action in response to each request</li></ul></li><li>offline:<ul><li>receive the entire sequence of requests in advance</li><li>take an action in response to each request, but the choice of each action can be based on the entire sequence of requests.</li></ul></li></ul><p>Deterministic online algorithms: suppose there is a function f from the sequence of requests to an action, such that the function is deterministic. Then the algorithm A(r=r1r2…rt) = f(r1)f(r1r2)…f(r1r2…rt) is a deterministic online algorithm.</p><h2 id="Competitive-analysis"><a href="#Competitive-analysis" class="headerlink" title="Competitive analysis"></a>Competitive analysis</h2><p>It is a method to analyze the performance of an online algorithm compared with the optimal offline algorithm</p><p>Bounds the ratio between the worst case behavior of the algorithm on a problem instance and the behavior of the optimal algorithm (not necessarily well defined) on the same problem instance.</p><ul><li>competitive ratio of an algorithm: the worst case ratio of its cost divided by the optimal cost over all possible inputs</li><li>competitive ratio of an online problem: the best competitive ratio achieved by an online algorithm</li></ul><h3 id="Potential-function"><a href="#Potential-function" class="headerlink" title="Potential function"></a>Potential function</h3><p>It is used to do competitive analysis. Where does it come from? We want to compare the performance between the designed algorithm and the optimal. We want to quantify the potential of the OPT to outperform the online algorithm.</p><p>There are two cases for the performances of OPT and the online algorithm:</p><ul><li>at a step in which the algorithm’s actions sequence coincide with the optimal action sequence, the two will have the same cost</li><li>when these two take different actions, the OPT has the potential to outperform the online algorithm. So, it is usually defined related to the difference between the OPT and the online one.</li></ul><p>Potential function is defined to measure the extent to which the two sequences differ, and hence the potential for OPT to outperform the online algorithm.</p><h2 id="Adversary-constructions"><a href="#Adversary-constructions" class="headerlink" title="Adversary constructions"></a>Adversary constructions</h2><p>It is a main approach to prove the lower bounds on the competitive ratio achievable of an online deterministic algorithm for a given problem. The framework:</p><ul><li>given any deterministic online algorithm as input</li><li>produce an infinite family R of request sequences such that as the length of the sequence r\in R increases, the ratio c(A(r))/c(OPT(r)) eventually exceeds every number less than k (a constant, the lower bound of the competitive ratio)</li></ul><p>There are three types of adversary. They can be used to test if a randomized online algorithm could be better than a deterministic online algorithm. In other words, to test if randomization could bring any advantage. These three have the same power to a deterministic algorithm but may have different power to a randomized algorithm. So, when speaking the competitivity of a randomized algorithm, we should point out which kind of adversary is used.</p><p>Three types of adversary:</p><ul><li>oblivious</li><li>adaptive</li><li>fully adaptive</li></ul><p>Two important theorems:</p><ul><li>if there is a C-competitive randomized algorithm against fully adaptive adversary, then there is a C-competitive deterministic algorithm. In other words, there is no advantage to randomize when playing against fully adaptive adversaries.</li><li>If there is a C-competitive randomized algorithm against oblivious adversaries and a D-competitive randomized algorithm against adaptive adversaries, then there is a  CD-competitive deterministic algorithm. It follows that the competitive ratio achievable by a randomized algorithm against adaptive online adversary is at least the square root of the best competitive ratio achievable by a deterministic algorithm.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Sharing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CIL review notes</title>
      <link href="/cil-readme/"/>
      <url>/cil-readme/</url>
      
        <content type="html"><![CDATA[<p>Here are my review notes of course <a href="http://www.da.inf.ethz.ch/teaching/2019/CIL/">Computational Intelligence Lab</a> opened by ETH Zurich, 2019 Spring.</p><p>These notes are my questions/understandings/new findings of related topics, instead of detailed lecture notes. <strong>Not all</strong> knowledge points are covered, which you may refer to the <a href="http://www.da.inf.ethz.ch/teaching/2019/CIL/">lecture slides</a>/notes/videos or other resources. </p><p>The values of these notes are my questions and thoughts. I believe question is the best teacher.</p><h1 id="Content"><a href="#Content" class="headerlink" title="Content"></a>Content</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h2 id="Autoencoder"><a href="#Autoencoder" class="headerlink" title="Autoencoder"></a>Autoencoder</h2><ul><li><a href="../CIL-1LA/index.html">Linear autoencoder</a></li><li><a href="../CIL-2MC/index.html">Matrix completion</a></li><li><a href="../CIL-3TM/index.html">Non-negative matrix factorization</a></li></ul><h2 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h2><ul><li><a href="../CIL-4WE/index.html">Word Embedding</a></li></ul><h2 id="Data-Clustering"><a href="#Data-Clustering" class="headerlink" title="Data Clustering"></a>Data Clustering</h2><ul><li><a href="../CIL-5MM/index.html">Clustering</a></li></ul><h2 id="Neural-Network"><a href="#Neural-Network" class="headerlink" title="Neural Network"></a>Neural Network</h2><ul><li><a href="../CIL-6CNN/index.html">Neural Network</a></li></ul><h2 id="Generative-Model"><a href="#Generative-Model" class="headerlink" title="Generative Model"></a>Generative Model</h2><ul><li><a href="../CIL-7GM/index.html">Generative Model</a></li></ul><h2 id="Sparse-Learning"><a href="#Sparse-Learning" class="headerlink" title="Sparse Learning"></a>Sparse Learning</h2><ul><li><a href="../CIL-8SC/index.html">Sparse coding</a></li><li><a href="../CIL-9DL/index.html">Dictionary learning</a></li></ul><h1 id="Other-Resources"><a href="#Other-Resources" class="headerlink" title="Other Resources"></a>Other Resources</h1><p>I also wrote the last minute summary and cheatsheet for this course.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><br><div class="row">    <embed src="CILSummary.pdf" width="100%" height="550" type="application/pdf"></div><br><h2 id="Cheatsheet"><a href="#Cheatsheet" class="headerlink" title="Cheatsheet"></a>Cheatsheet</h2><p><br></p><div class="row">    <embed src="CILCheatSheet.pdf" width="100%" height="550" type="application/pdf"></div><p></p><br>]]></content>
      
      
      <categories>
          
          <category> Sharing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Computational Statistics course notes</title>
      <link href="/compstat/"/>
      <url>/compstat/</url>
      
        <content type="html"><![CDATA[<p>Here are my review notes of course Computational Statistics opened by <a href="https://stat.ethz.ch/~maathuis/">Dr. Marloes H. Maathuis</a>, Seminar of Statistics, ETH Zurich, 2019 Spring. The course was amazing with clearly explained theories and matched coding practices. The professor preferred to writing on the blackboard. So I organized my course notes as a PDF file as well as the final exam cheatsheet.</p><h1 id="All-course-notes"><a href="#All-course-notes" class="headerlink" title="All course notes"></a>All course notes</h1><div class="row">    <embed src="notes.pdf" width="100%" height="550" type="application/pdf"></div><br><br><h2 id="Exam-Cheatsheet"><a href="#Exam-Cheatsheet" class="headerlink" title="Exam Cheatsheet"></a>Exam Cheatsheet</h2><div class="row">    <embed src="cheatsheet.pdf" width="100%" height="550" type="application/pdf"></div><br>]]></content>
      
      
      <categories>
          
          <category> Sharing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Statistics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Complex Network review notes</title>
      <link href="/cnreadme/"/>
      <url>/cnreadme/</url>
      
        <content type="html"><![CDATA[<p>Here are my review notes of course Complex Network opened by <a href="https://www.sg.ethz.ch/team/frank_schweitzer/">Professor Frank Schweitze</a>, Chair of Systems Design, ETH Zurich, 2019 Spring.</p><p>These notes include important points based on lecture notes.</p><h1 id="Content"><a href="#Content" class="headerlink" title="Content"></a>Content</h1><h2 id="Introduction-to-Networks-Basic-and-Advanced-Metrics"><a href="#Introduction-to-Networks-Basic-and-Advanced-Metrics" class="headerlink" title="Introduction to Networks: Basic and Advanced Metrics"></a>Introduction to Networks: Basic and Advanced Metrics</h2><ul><li><a href="../cn01/index.html">Motivation</a></li><li><a href="../cn02/index.html">Introduction to Networks</a></li></ul><h2 id="Stochastic-Models-of-Complex-Networks"><a href="#Stochastic-Models-of-Complex-Networks" class="headerlink" title="Stochastic Models of Complex Networks"></a>Stochastic Models of Complex Networks</h2><ul><li><a href="../cn03/index.html">Ensemble perspective</a></li><li><a href="../cn04/index.html">Small-world networks</a></li><li><a href="../cn05/index.html">Generating function</a></li><li><a href="../cn06/index.html">Generating function applications</a></li><li><a href="../cn07/index.html">Scale-Free Network and limitations of Ensemble Studies</a></li></ul><h2 id="Dynamic-Processes-on-Complex-Networks"><a href="#Dynamic-Processes-on-Complex-Networks" class="headerlink" title="Dynamic Processes on Complex Networks"></a>Dynamic Processes on Complex Networks</h2><ul><li><a href="../cn08/index.html">Random Walks and Diffusion</a></li><li><a href="../cn09/index.html">Spectral properties</a></li></ul><h2 id="Generative-Models-and-Statistical-Inference"><a href="#Generative-Models-and-Statistical-Inference" class="headerlink" title="Generative Models and Statistical Inference"></a>Generative Models and Statistical Inference</h2><ul><li><a href="../cn10/index.html">Statistical Inference</a></li><li><a href="../cn11/index.html">Model selection</a></li><li><a href="../cn12/index.html">Exponential random graph model</a></li></ul><h2 id="Network-Dynamics"><a href="#Network-Dynamics" class="headerlink" title="Network Dynamics"></a>Network Dynamics</h2><ul><li><a href="../cn13/index.html">Growing network</a></li><li><a href="../cn14/index.html">Time series data on networks</a></li></ul><p><img src="mindmap.png" alt="the whole mindmap"></p><h1 id="Other-Resources"><a href="#Other-Resources" class="headerlink" title="Other Resources"></a>Other Resources</h1><p>I also wrote a summary of difficult/important knowledge points of this course.</p><br><div class="row">    <embed src="CNSummary.pdf" width="100%" height="550" type="application/pdf"></div><br>]]></content>
      
      
      <categories>
          
          <category> Sharing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Complex System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CN14 Time series data on networks</title>
      <link href="/cn14/"/>
      <url>/cn14/</url>
      
        <content type="html"><![CDATA[<h1 id="Objectives"><a href="#Objectives" class="headerlink" title="Objectives"></a>Objectives</h1><ul><li>patterns in time series data.</li></ul><h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><ul><li>when is important to consider network dynamics in the study of dynamical processes on networks with changing topologies?<ul><li>to understand its formulation and change mechanism, find significant factors.</li></ul></li><li>what is the difference between a growing network and a general temporal network?<ul><li>growing: links appear</li><li>temporal: links appear and disappear???</li></ul></li><li>Define what a temporal network is. Give an example for two different temporal networks that give rise to the same weighted, time-aggregated network.<ul><li>$t_1:a\to b, t_2:b\to c$​​</li><li>$t_1: b\to c, t_2: a\to b$​​</li></ul></li><li>What is a second-order time-aggregated network? For the two temporal networks created above, construct the second-order time-aggregated networks and argue whether they are different.</li><li>Give the definition of a causal path. When are causal paths transitive?</li><li>How would you define a shortest and a fastest causal paths? Are these two notions the same? Provide an example temporal network that supports your answer.</li></ul><h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><ul><li>temporal networks</li><li>time-aggregated network<ul><li>second-order</li></ul></li><li>higher-order network models</li><li>representation learning</li><li>betweenness preference</li><li>causal path<ul><li>shortest</li><li>fastest</li></ul></li></ul><h1 id="Research-fields"><a href="#Research-fields" class="headerlink" title="Research fields"></a>Research fields</h1><ul><li>multi-layer networks: capture multiple relations between nodes.</li><li>dynamic(temporal) network: study the sequence of links.<ul><li>time-aggregated network: assume that a link to exist whenever it occurs at any time.</li></ul></li></ul><h1 id="Temporal-network"><a href="#Temporal-network" class="headerlink" title="Temporal network"></a>Temporal network</h1><p>We study temporal network to capture the complex effects introduced by the temporal dynamics of links</p><h2 id="Components"><a href="#Components" class="headerlink" title="Components"></a>Components</h2><ul><li>nodes</li><li>time-stamped links (v,w;t)</li></ul><p>We can represent it by a directed, acyclic graph.</p><h2 id="Causal-paths"><a href="#Causal-paths" class="headerlink" title="Causal paths"></a>Causal paths</h2><p>$(v_0,v_1;t_1)\to(v_1,v_2;t_2)\to (v_2,v_3;t_3)\to \cdots\to(v_{l-1},v_l,t_l)$</p><p>the ordering of links matters!</p><h3 id="Maximum-time-difference"><a href="#Maximum-time-difference" class="headerlink" title="Maximum time difference"></a>Maximum time difference</h3><p>\delta: we only consider the causal paths with time difference smaller than the maximum time difference.</p><p>It actually restricts the links we study.</p><h2 id="Time-aggregated-network"><a href="#Time-aggregated-network" class="headerlink" title="Time-aggregated network"></a>Time-aggregated network</h2><p>the static representation of temporal network.</p><ul><li>weight: the number of times a time-stamped link was active.</li><li>transitive: paths in time-aggregated networks are transitive.</li><li>by <strong>changing the ordering</strong>: we can get a same time-aggregated network from different temporal networks.</li></ul><h3 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h3><ul><li>A false sense of transitivity: since we discard all information on the ordering of links in the dynamic network, which influences causal paths.<ul><li>we use the time-aggregated network as <strong>a maximum entropy model</strong>.</li></ul></li><li>The power of its adjacency matrix doesn’t indicate the causal paths of length k.</li></ul><h2 id="Betweenness-preference"><a href="#Betweenness-preference" class="headerlink" title="Betweenness preference"></a>Betweenness preference</h2><p>it is </p><ul><li><p>to identify for which paths differ from the expectation in the <strong>aggregate network</strong>.</p></li><li><p>to quantify how much they differ.</p></li><li><p>to measure the amount of information in terms of the ordering of links which is discarded when studying the time-aggregated network</p></li></ul><h3 id="Matrix-based-on-directed-acyclic-graph"><a href="#Matrix-based-on-directed-acyclic-graph" class="headerlink" title="Matrix based on directed, acyclic graph"></a>Matrix based on directed, acyclic graph</h3><p>$P^v: Nr.|S|\ast Nr.|D|$: dimension: the number of sources passing through node v times the number of destinations passing through node v, all $s\to v\to d$​​​ </p><p>$P^v_{sd}$: the joint probabilities of $S$ and $D$.</p><p>It should be defined under some given maximum time difference.</p><p>A <strong>null matrix</strong> can be built from the time-aggregated network.<br>$$<br>\hat{P}^v_{sd}=\frac{w(s,v)}{\sum_{s’}w(s’,v)}\cdot\frac{w(v,d)}{\sum_{d’}w(v,d’)}a<br>$$</p><h3 id="Index-mutual-information"><a href="#Index-mutual-information" class="headerlink" title="Index: mutual information"></a>Index: mutual information</h3><p>$$<br>I^v(S;D)=\sum_{s,d}P^v_{sd}\log_2(\frac{P^v_{sd}}{P^v(S=s)P^v(D=d)})<br>$$</p><ul><li><p>captures how much bits of information the sources provide for destinations when aggregating interactions around $v$.</p></li><li><p>if s and d are uncorrelated, the measure should be 0.</p></li><li><p>interpretation: does $v$ prefer to mediate paths between particular pairs of its neighbors.</p></li></ul><h2 id="Markovian"><a href="#Markovian" class="headerlink" title="Markovian"></a>Markovian</h2><p><strong>Markovian</strong>: the next step only depends on the current nostate, no more previous status.</p><p>if the betweenness preference of any node in the network is around 0, we call it Markovian temporal network.<br>$$<br>I^v(S;D)\simeq 0,\forall v\in V<br>$$<br>It means the time-respecting paths do not differ from what is expected from the time-aggregated network.</p><h3 id="Transitivity"><a href="#Transitivity" class="headerlink" title="Transitivity"></a>Transitivity</h3><p>Paths in real systems are non-Markovian, thus <strong>breaking transitivity</strong>.</p><h3 id="Betweenness-preference-1"><a href="#Betweenness-preference-1" class="headerlink" title="Betweenness preference"></a>Betweenness preference</h3><p>It can be judged by betweenness preference. In real network, many of them are far from 0.</p><p>A study of the betweenness preference distribution of nodes in real temporal networks confirms that time-respecting paths cannot be modeled as a simple memoryless stochastic process</p><h3 id="Diffusion"><a href="#Diffusion" class="headerlink" title="Diffusion"></a>Diffusion</h3><p>temporal characteristics of dynamic networks alone can both <strong>slow down or speed up</strong> dynamical processes</p><ul><li>Non-markovianity slows down diffusion. </li></ul><p>A simulation of ant colony indicates the slow-down factor of 2. That means the process in the temporal<br>network is about two times slower than in the static network.</p><p>the reason for that are that time-respecting paths in the real temporal network are longer than what one would expect in the static network</p><ul><li>London Tube: speeds up $S=0.25$</li></ul><h2 id="High-order-model"><a href="#High-order-model" class="headerlink" title="High-order model"></a>High-order model</h2><p>It is to capture the length k of causal paths, for a given maximum time difference \delta.</p><ul><li>nodes: the links in the lower-orders model</li><li>links (weights): the number of times the causal path occurs in the underlying sequence. </li></ul><h4 id="Expected-2-nd-order-topology-matrix"><a href="#Expected-2-nd-order-topology-matrix" class="headerlink" title="Expected 2-nd order topology/matrix"></a>Expected 2-nd order topology/matrix</h4><p>We can get the expected 2-nd order matrix based on the time-aggregated 1-st order network.</p><p>From this matrix and the actual number of outer-links of each node in the original 2nd order network, we can get the expected 2nd order topology. </p><h3 id="Sensitive-to-ordering"><a href="#Sensitive-to-ordering" class="headerlink" title="Sensitive to ordering"></a>Sensitive to ordering</h3><p>the second-order network changes when time-stamped links are reordered while the first-order topology stays the same</p><h3 id="Diffusion-1"><a href="#Diffusion-1" class="headerlink" title="Diffusion"></a>Diffusion</h3><p>The second eigenvalue of the transition matrix of the 2nd order network.<br>$$<br>S\simeq \frac{\ln|\lambda_2(\tilde{T})|}{\ln|\lambda_2(T)|}<br>$$</p><h3 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h3><p>From the node construction from a lower-order model, can we construct 3-order???? I think we can only construct $2^k$ order……. </p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Complex System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CN13 Growing network</title>
      <link href="/cn13/"/>
      <url>/cn13/</url>
      
        <content type="html"><![CDATA[<h1 id="Objectives"><a href="#Objectives" class="headerlink" title="Objectives"></a>Objectives</h1><ul><li>growth models for complex network</li><li>feedback in network growth: preferential attachment</li></ul><h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><ul><li>what is a master equation? How can it be used to analyze network growth models?</li><li>consider the uniform attachment model and write down the master equation for $P(k,s,t)$ and $P(k,t)$.</li><li>consider the preferential attachment model and write down the differential equation for the evolution of $k_i(t)$</li><li>what are the final degree distributions for a growth model with uniform attachment and preferential attachment?<ul><li>uniform: normal distribution</li><li>preferential: zipf distribution?</li></ul></li><li>in the preferential attachment model, how does the number of links m added in each step affect the final degree distribution?<ul><li>affect the peak?</li></ul></li><li>explain why the random walk model gives rise to preferential attachment</li><li>explalin why the copying model gives rise to preferential attachment.</li></ul><h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><ul><li><p>attachment strategy</p><ul><li>preferential attachment</li></ul></li><li><p>master equation</p></li><li><p>time-dependent degree distribution</p></li></ul><h1 id="Attachment-rules"><a href="#Attachment-rules" class="headerlink" title="Attachment rules"></a>Attachment rules</h1><h2 id="Uniform-attachment"><a href="#Uniform-attachment" class="headerlink" title="Uniform attachment"></a>Uniform attachment</h2><p>new nodes form links to existing nodes chosen uniformly at random</p><h3 id="degree-distribution"><a href="#degree-distribution" class="headerlink" title="degree distribution"></a>degree distribution</h3><p>exponentially shaped</p><p>e.g. much like those generated by Erdos-Renyi random graph models</p><h2 id="Preferential-attachment"><a href="#Preferential-attachment" class="headerlink" title="Preferential attachment"></a>Preferential attachment</h2><p>new nodes preferentially form links to highly connected nodes. </p><h3 id="degree-distribution-1"><a href="#degree-distribution-1" class="headerlink" title="degree distribution"></a>degree distribution</h3><p>scale-free degree distribution, log-log plot a line</p><h1 id="Analytical-Approaches"><a href="#Analytical-Approaches" class="headerlink" title="Analytical Approaches"></a>Analytical Approaches</h1><p>Two main tools:</p><ul><li>master equation: for discrete perspective</li><li>continuum limit approximation: for continuous perspective</li></ul><h2 id="Master-equation-Rate-equation"><a href="#Master-equation-Rate-equation" class="headerlink" title="Master equation/Rate equation"></a>Master equation/Rate equation</h2><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>the first-order differential equations that describe the evolution of probabilities over time.</p><h2 id="Case-uniform-attachment"><a href="#Case-uniform-attachment" class="headerlink" title="Case: uniform attachment"></a>Case: uniform attachment</h2><h3 id="Settings"><a href="#Settings" class="headerlink" title="Settings"></a>Settings</h3><ul><li>node: each time, add a new node into the system. That is at time $t$, there are $t$ nodes.</li><li>link: each newly added node uniformly chooses a random existing node. $p=\frac{1}{t}$​ <ul><li>observation: for an existing node, its probability to receive a new link decays over time. </li></ul></li></ul><h3 id="Formula"><a href="#Formula" class="headerlink" title="Formula"></a>Formula</h3><p>The probability of a node added at time s has the degree $k$ at time $t+1$​<br>$$<br>p(k,s,t+1)=\frac{1}{t}p(k-1,s, t)+(1-\frac{1}{t})p(k,s,t)<br>$$</p><ul><li><p>the first item: the node has degree $k-1$ at time $t$</p></li><li><p>the second: the node has degree $k$ at time $t$.</p></li></ul><p>the initial condition<br>$$<br>p(k,1,1)=\delta_{k,0}<br>$$</p><ul><li>$k=0$, the value is 1</li><li>otherwise, the value is 0.</li></ul><p>the boundary condition<br>$$<br>p(k,t,t)=\delta_{k,1}<br>$$</p><h3 id="Degree-distribution-time-dependent"><a href="#Degree-distribution-time-dependent" class="headerlink" title="Degree distribution, time-dependent"></a>Degree distribution, time-dependent</h3><p>$$<br>P(k,t)=\frac{1}{t}\sum_{s}P(k,s,t)<br>$$</p><h4 id="Change-over-time"><a href="#Change-over-time" class="headerlink" title="Change over time"></a>Change over time</h4><p>$$<br>(t+1)p(k,t+1)-(t-1)p(k,t-1)=p(k-1,t)+\delta_{k,1}<br>$$</p><h4 id="limiting-value"><a href="#limiting-value" class="headerlink" title="limiting value"></a>limiting value</h4><p>$$<br>p(k)=\frac{p(k-1)+\delta_{k,1}}{2}=2^{-k}<br>$$</p><ul><li>$p(0)=0$</li><li>$\delta_{1,1}=1$</li><li>exponentially-shape degree distribution, <strong>not</strong> like ER networks.<ul><li>because there is a dependence of the average degree on the birth time of a node.</li></ul></li></ul><h4 id="Mean-degree"><a href="#Mean-degree" class="headerlink" title="Mean degree"></a>Mean degree</h4><p>$$<br>\langle k\rangle = \sum_{i=1}^{\infty}\frac{k}{2^k}=2<br>$$</p><p>how to calculate?<br>$$<br>|x|&lt;1: f(x)=\sum_{n=1}^{\infty}x^n=\frac{x}{1-x},<br>$$</p><p>$$<br>\Rightarrow xf’(x)=\sum_{n=1}^{\infty}nx^n=\frac{x}{(1-x)^2}<br>$$</p><h2 id="Case-Preferential-attachment"><a href="#Case-Preferential-attachment" class="headerlink" title="Case: Preferential attachment"></a>Case: Preferential attachment</h2><h3 id="Settings-1"><a href="#Settings-1" class="headerlink" title="Settings"></a>Settings</h3><ul><li><p>node: each time, add a new node into the system. That is at time $t_i$, there are $i$ nodes.</p></li><li><p>link: each newly added node forms <strong>m</strong> links to existing nodes and the probability to each exsiting node is <strong>Positive feedback</strong><br>$$<br>p(v_i)=\frac{k_i(t)}{\sum_jk_j(t)}<br>$$</p></li></ul><h3 id="Formula-1"><a href="#Formula-1" class="headerlink" title="Formula"></a>Formula</h3><p>For each existing node $x_i$, the expectation of its degree increase  at time t is m\times the probability of one link to it.</p><p>Generating to continuous time, we have<br>$$<br>\frac{\mathrm{d}k_i(t)}{\mathrm{d}t}=m\cdot\frac{k_i(t)}{\sum_jk_j(t)=2mt}=\frac{k_i(t)}{2t}<br>$$</p><ul><li>initial condition: $k_i(t_i)=m$ </li></ul><p>We get<br>$$<br>k_i(t)=m(\frac{t}{t_i})^{\frac{1}{2}}<br>$$</p><ul><li>node degrees grow as square root of time</li><li>node degrees are age-dependent.</li></ul><h3 id="Degree-distribution"><a href="#Degree-distribution" class="headerlink" title="Degree distribution"></a>Degree distribution</h3><p>After a series of complex calculation,<br>$$<br>p(k)=2m^2k^{-3}\propto k^{-3}<br>$$</p><ul><li>degree distribution follows a power-law distribution with parameter 3.</li></ul><h4 id="Matthew-effect"><a href="#Matthew-effect" class="headerlink" title="Matthew effect"></a>Matthew effect</h4><p>A dynamics by which “the rich get richer”, first-mover advantage. i.e. the degree of those nodes that already have the most links will grow fastest.</p><h1 id="Preferential-attachment-1"><a href="#Preferential-attachment-1" class="headerlink" title="Preferential attachment"></a>Preferential attachment</h1><h2 id="Simple-attachment-model"><a href="#Simple-attachment-model" class="headerlink" title="Simple attachment model"></a>Simple attachment model</h2><p>limitation: </p><ul><li>global knowledge. The newly added node needs to have the global knowledge.</li><li>Preferential attachment here is an <strong>observation</strong> not <strong>mechanism</strong>.</li></ul><h2 id="Copying-model"><a href="#Copying-model" class="headerlink" title="Copying model"></a>Copying model</h2><p>This is a local mechanism model. </p><p>A newly  introduced node randomly selects a target node and links to it, as well as to all/some ancestor nodes of the target node.</p><h2 id="Random-walk-model"><a href="#Random-walk-model" class="headerlink" title="Random walk model"></a>Random walk model</h2><p>new nodes start random walk at random node and form a link every l steps</p><ul><li>produce different clusters depending on the distance l: small l will lead to higher clustering</li></ul><h2 id="Heterogenous-node-fitness"><a href="#Heterogenous-node-fitness" class="headerlink" title="Heterogenous node fitness"></a>Heterogenous node fitness</h2><p>$$<br>p(v_i)=\frac{\eta_ik_i(t)}{\sum_j\eta_jk_j(t)}<br>$$</p><h2 id="Relation-with-Scale-free-network"><a href="#Relation-with-Scale-free-network" class="headerlink" title="Relation with Scale-free network"></a>Relation with Scale-free network</h2><p>Preferential attachment is a <strong>sufficient condition</strong> of scale-free network, <strong>not</strong> a <strong>necessary condition</strong>.</p><p>Not all scale-free network are generated by preferential attachment.</p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Complex System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CN12 Exponential random graph model</title>
      <link href="/cn12/"/>
      <url>/cn12/</url>
      
        <content type="html"><![CDATA[<h1 id="Objectives"><a href="#Objectives" class="headerlink" title="Objectives"></a>Objectives</h1><p>using ERGM model to generate statistical ensembles with arbitrary fixed properties.</p><h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><ul><li>For which microstate probabilities is the entropy of a statistical ensemble maximized?<ul><li>the one best describe the given knowledge</li></ul></li><li>How is the microstate probability in the exponential random graph model defined?</li><li>What is the basic underlying assumption behind this microstate probability?</li><li>How is the $G(n,p)$ model related to ERGM?<ul><li>using p as the expected property.</li></ul></li><li>How can we maximize the likelihood function in the ERGM?<ul><li>derivative the log-likelihood function</li></ul></li><li>How can the parameters of an ERGM fit be interpreted?<ul><li>the positive/negative effect of the factors</li></ul></li></ul><h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><ul><li>microstate probabilities</li><li>statistical ensemble, e.g. $G(n,p)$​​ model</li><li>ERGM</li></ul><h1 id="Microstate-probability"><a href="#Microstate-probability" class="headerlink" title="Microstate probability"></a>Microstate probability</h1><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>The probability of each microstate, e.g. a network of a network generation model,  in the ensemble model.</p><p>For instance, in $G(n,m)$ model, each microstate has the same probability $P=\frac{1}{T}$ where $T={D\choose m}$ and $D = {n+1\choose 2}$</p><h2 id="Maximum-entropy-principle"><a href="#Maximum-entropy-principle" class="headerlink" title="Maximum entropy principle"></a>Maximum entropy principle</h2><p>The <strong>probability distribution</strong> which maximizes the entropy is the best one to describe the given state of knowledge.</p><p>Use $\Pi $​ to denote a probability distribution. The MEP gives<br>$$<br>\Pi^*=\arg_{\Pi}\max H(\Pi)=\arg_{\Pi}\max -\sum_{G\in\Omega} P(G)\log(P(G))<br>$$</p><ul><li>$\Omega$ denotes the given state of knowledge.  For example \Omega restricts all the networks have m edges.</li><li>each $\Pi$​ gives  a set of $P()$</li></ul><p><a href="https://www.statisticshowto.datasciencecentral.com/maximum-entropy-principle/">refer to this website</a>This will be the system with the <strong>largest remaining uncertainty</strong>, and by choosing it you’re making sure you’re not adding any extra <a href="https://www.statisticshowto.datasciencecentral.com/what-is-bias/">biases </a>or uncalled for assumptions into your analysis. </p><h1 id="ERGM"><a href="#ERGM" class="headerlink" title="ERGM"></a>ERGM</h1><h2 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h2><ul><li>maximizing the entropy</li><li>preserving the expected properties</li></ul><h3 id="Grand-canonical-ensemble"><a href="#Grand-canonical-ensemble" class="headerlink" title="Grand canonical ensemble"></a>Grand canonical ensemble</h3><p>Grand canonical means the overall features of all the microstates keep unchanged, which can be shown by the expected values of all the microstates.</p><p>For example, G(n,p) model gives us a lot of random networks. Taking the expectation of the edge number over these networks, we will get a fixed value np/2. The edge number is a grand canonical feature for this model.</p><h2 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h2><ul><li><p>fix the expected values of our interested properties:</p><ul><li>$$<br>\langle f_i\rangle = \sum_G p(G)f_i(G)<br>$$</li></ul></li><li><p>the model is </p><ul><li><p>to maximize $H(\Omega)$</p></li><li><p>under the constraint  of probability sum 1 and the expected property value</p></li><li><p>take derivative for each microstate and set as 0<br>$$<br>\frac{\partial}{\partial p(G)}{H+\alpha(1-\sum_G p(G)+\sum_i\theta_i(\langle f_i\rangle-\sum_Gf_i(G)p(G))}=0<br>$$</p></li></ul><p>we can get<br>$$<br> p(G)=\frac{\exp(-\sum_i\theta_if_i(G))}{Z}<br>$$</p><p>$$<br>Z=\sum_G\exp(-\sum_i \theta_if_i(G))<br>$$</p><p>$$<br>\frac{\partial Z}{\partial \theta_i} = \sum_G-f_i(G)\exp(-\sum_j\theta_jf_j(G))<br>$$</p><p>$$<br>=-\sum_G f_i(G) Z\frac{\exp(-\sum_j\theta_jf_j(G))}{Z} = -Z\langle f_i\rangle<br>$$</p><p>$$<br>\langle f_i\rangle=-\frac{1}{Z}\frac{\partial Z}{\partial \theta_i}<br>$$</p></li><li><p>we need to estimate theta</p></li></ul><h2 id="Simulation-algorithms"><a href="#Simulation-algorithms" class="headerlink" title="Simulation algorithms"></a>Simulation algorithms</h2><h3 id="Random-walk"><a href="#Random-walk" class="headerlink" title="Random walk"></a>Random walk</h3><ol><li>construct the transition matrix $T: T_{ij}$: the transition probability from microstate $G_i$ to $G_j$<ol><li>walking sufficiently long such that visitation probabilities are close to stationary distribution</li></ol></li><li>start with random network $G_i$</li><li>for random nodes $v,w$: <ul><li>if link $(v,w)$ exists: remove</li><li>else, add</li><li>accept change with probability $T_{v,w}$</li></ul></li><li>repeat large enough steps to generate a new network</li><li>calculate the expected properties on the newly generated networks, compared with the empirical network.</li></ol><h3 id="MCMCMLE"><a href="#MCMCMLE" class="headerlink" title="MCMCMLE"></a>MCMCMLE</h3><ol><li>choose initial value $\theta_0$</li><li>compute $P(G|\theta_0)$ by generating enough microstates</li><li>randomly disturb $\theta_0$ to get $\theta_1$</li><li>repeat step 2 for $\theta_1$</li><li>compare the results of step 2 and 4. Keep the better parameter.</li><li>repeat step 2-5 until convergence.</li></ol>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Complex System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CN11 Model selection</title>
      <link href="/cn11/"/>
      <url>/cn11/</url>
      
        <content type="html"><![CDATA[<h1 id="Objectives"><a href="#Objectives" class="headerlink" title="Objectives"></a>Objectives</h1><ul><li>how <strong>information theoretic concepts</strong> can be used to solve the overfitting problem in community detection.<ul><li>only in community detection? Can it be generalized to other fields?</li></ul></li></ul><h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><ul><li><p>how is the entropy of a probability mass function defined?</p><ul><li>$H(x)=-\sum_i p(x_i)\log p(x_i)$</li></ul></li><li><p>how is the entropy of a statistical ensemble defined?</p><ul><li>using the distribution</li></ul></li><li><p>What is the entropy of a micro-canonical statistical ensemble? </p><ul><li>the log of the microstates number</li></ul></li><li><p>how can entropy be used for community detection based on the stochastic block model?</p><ul><li>define description length and minimize it.</li></ul></li><li><p>how is the description length of stochastic block model defined?<br>$$<br>H(M,z)=\log Z(M,z) = \log \Pi_{1\leq k\leq l\leq B}{N_{kl}\choose M_{kl}}<br>$$</p><p>$$<br>=\sum_{1\leq k\leq l\leq B}\log P{N_{kl}\choose M_{kl}}<br>$$</p></li><li><p>Explain the basic idea behind flow compression.</p><ul><li>minimize description length and random walk.</li></ul></li><li><p>How is the MapEquation defind? How is it used in InfoMap?</p><ul><li>$L(z) = qH(Q)+\sum_ip_iH(P_i)$</li><li>as a guidance</li></ul></li><li><p>How can we calculate the MapEquation for an undirected and unweighted network?</p><ul><li>stationary probability of edge, $1/m$</li></ul></li><li><p>How can we generalize InfoMap to directed and weighted network?</p><ul><li>eigenvectors</li></ul></li><li><p>How can we quickly discover a community mapping that minimizes the MapEquation?</p><ul><li>heuristic algorithms, e.g. simulated annealing, greedy optimization.</li></ul></li></ul><h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><ul><li>entropy</li><li>description length</li><li>flow compression</li><li>InfoMap</li></ul><h1 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a>Entropy</h1><h2 id="Definition-of-Shannon-entropy"><a href="#Definition-of-Shannon-entropy" class="headerlink" title="Definition of Shannon entropy"></a>Definition of Shannon entropy</h2><p>$$<br>H(x)=-\sum_{i} P(X=i)\log P(X=i)<br>$$</p><ul><li>meaning: describe the amount of information needed to know the value of $x$.<ul><li>the higher $H(x)$ is, the more bit of information, except the $x$’s own distribution, we need to know the value of $x$.</li></ul></li></ul><h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><h3 id="G-n-p-model"><a href="#G-n-p-model" class="headerlink" title="$G(n,p)$ model"></a>$G(n,p)$ model</h3><p>$$<br>H(n,p)=-\sum_{m=1}^{T}T p(n, m)\log p(n,m)<br>$$</p><p>where $T={D \choose m}$ and $D ={n+1\choose 2} $<br>$$<br>p(n,m)=p^m(1-p)^{D-m}<br>$$</p><h3 id="G-n-m-model"><a href="#G-n-m-model" class="headerlink" title="$G(n,m)$ model"></a>$G(n,m)$ model</h3><p>$$<br>H(n,m)=-T p_0\log p_0<br>$$</p><p>$$<br>p_0=\frac{1}{T}<br>$$</p><p>$$<br>\Rightarrow H(n,m)=-\log p_0=\log T<br>$$</p><h4 id="Micro-canonical-ensemble"><a href="#Micro-canonical-ensemble" class="headerlink" title="Micro-canonical ensemble"></a>Micro-canonical ensemble</h4><ul><li><p>All microstates are equiprobable.</p></li><li><p>The entropy of the ensemble is the logarithm of the partition function, i.e. the number of possible microstates.</p></li><li><p>the likelihood is simply the inverse of the number of realizations.</p><ul><li><p>the smaller the number</p></li><li><p>the larger the likelihood</p></li><li><p>the smaller the entropy</p></li><li><p>MLE = minimize entropy<br>$$<br>H(\theta)=\log Z(\theta)<br>$$</p></li><li><p>$Z(\theta)$ is the number of instances.</p></li></ul></li></ul><h3 id="stochastic-block-model"><a href="#stochastic-block-model" class="headerlink" title="stochastic block model"></a>stochastic block model</h3><p>Modify the block matrix M by $M_{ij}$ representing the number of edges between block i and block j, not the probability of edges appearing. Hence, we <strong>change the stochastic block model as a micro-canonical ensemble</strong>.</p><p>We have two parameters: M and z. They are independent.</p><ul><li><p>$N_{kl}$ are decided by the vector z, the block assignment vector. When we know z, we can know how many nodes in each block and calculate N.</p></li><li><p>$E_{kl}$ are decided by the vector z and the topology of the network. We need combine the block assignment of a node and its link to others to count.</p></li><li><p>M: note that <strong>not all M and z match</strong> each other. There exists contradiction, e.g. $M_{ij} &gt; N_{ij}$</p></li><li><p>the likelihood is based on three objects:</p><ul><li>the block matrix $M$</li><li>the block assignment vector $z$</li><li>the known network (with link information)</li></ul><p>$$<br>H(M,z)=\log Z(M,z)= \log \Pi_{1\leq k\leq l\leq B}{N_{kl}\choose M_{kl}}<br>$$</p><p>$$<br>=\sum_{1\leq k\leq l\leq B}\log P{N_{kl}\choose M_{kl}}<br>$$</p></li></ul><p>The maximum likelihood given $z$ is<br>$$<br>\hat{H}(z)=\sum_{1\leq k\leq l\leq B}\log p{N_{kl}\choose E_{kl}}<br>$$</p><h1 id="Description-length"><a href="#Description-length" class="headerlink" title="Description length"></a>Description length</h1><p>This is a trade-off between explanatory power and complexity, like AIC (interesting, AIC is also based on the information theory). It works by adding punishment of parameters. The good thing of this criterion is the number can be directly interpreted as bit of information.</p><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>$$<br>\lambda(z)=H(z)+\Delta(z)<br>$$</p><ul><li>$\Delta(z)$: the bits of information needed for parameters.</li></ul><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>For stochastic block model, the approximation solution is<br>$$<br>\lambda(z)=\Delta(z)+m\cdot h(x),h(x)=(1+x)\log(1+x)-x\log(x)<br>$$</p><p>$$<br>x= \frac{B(B+1)}{2m}+n\cdot\log(B)<br>$$</p><h1 id="Flow-compression"><a href="#Flow-compression" class="headerlink" title="Flow compression"></a>Flow compression</h1><h2 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h2><p>using the cluster to compress the flow description sequence</p><h2 id="Hierarchy-coding-scheme"><a href="#Hierarchy-coding-scheme" class="headerlink" title="Hierarchy coding scheme"></a>Hierarchy coding scheme</h2><h2 id="Huffman-code"><a href="#Huffman-code" class="headerlink" title="Huffman code"></a>Huffman code</h2><p>pre-fix coding</p><h2 id="Source-coding-theorem"><a href="#Source-coding-theorem" class="headerlink" title="Source coding theorem"></a>Source coding theorem</h2><p>the minimum pre-symbol length of lossless code given by Shannon entropy</p><p>Hoffman code is asymptotically optimal for n i.i.d symbols with known prob. mass function $P$​<br>$$<br>L_n\to n\cdot H(p)<br>$$</p><h1 id="MapEquation"><a href="#MapEquation" class="headerlink" title="MapEquation"></a>MapEquation</h1><h2 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h2><p>The minimal code length for mapping nodes to $k$​ communities<br>$$<br>L(\vec{z_k})=qH(Q)+\sum_{i=1}^k p_i H(P_i)<br>$$</p><ul><li>q: the per-step probability that random walker switches between communities</li><li>p_i: the per-step probability that random walker switches within community $i$. <ul><li><p>$$<br>q+\sum_{i=1}^kp_i=1<br>$$</p></li><li><p>Not  $\sum_{i=1}^kp_i=1$</p></li></ul></li><li>$H(Q)$: the bits needed to encode clusters.</li><li>$H(P_i)$: the bits needed to encode nodes within cluster $P_i$</li></ul><h2 id="Example-1"><a href="#Example-1" class="headerlink" title="Example"></a>Example</h2><h3 id="undirected-and-unweighted-network"><a href="#undirected-and-unweighted-network" class="headerlink" title="undirected and unweighted network"></a>undirected and unweighted network</h3><p>each edge has the same visit probability $\frac{1}{m}$ </p><p>node with degree $d_v$ has the stationary visit probability $\frac{d_v}{2m}$ </p><p>so we can get $q$ and $p_i$</p><h2 id="generalized-to-directed-weighted-network"><a href="#generalized-to-directed-weighted-network" class="headerlink" title="generalized to directed/weighted network"></a>generalized to directed/weighted network</h2><p>Instead of using the relative frequencies of links within and across communities, we now actually have to calculate eigenvectors to find the stationary visitation probabilities of nodes and communities.</p><h2 id="Detection-algorithms"><a href="#Detection-algorithms" class="headerlink" title="Detection algorithms"></a>Detection algorithms</h2><h3 id="InfoMap"><a href="#InfoMap" class="headerlink" title="InfoMap"></a>InfoMap</h3><p>find community assignment (with any number of communities) s.t.<br>$$<br>\hat{\vec{z}}=\arg_{\vec{z}}\min L(\vec{z})<br>$$</p><h3 id="Heuristic-to-find-to-discover-algorithms"><a href="#Heuristic-to-find-to-discover-algorithms" class="headerlink" title="Heuristic (to find/to discover) algorithms"></a>Heuristic (to find/to discover) algorithms</h3><ul><li>Simulated annealing</li><li>Greedy optimization</li><li>Genetic algorithms</li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Complex System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CN10 Statistical Inference</title>
      <link href="/cn10/"/>
      <url>/cn10/</url>
      
        <content type="html"><![CDATA[<h1 id="Objectives"><a href="#Objectives" class="headerlink" title="Objectives"></a>Objectives</h1><ul><li>use ensemble perspective on complex networks</li><li>focus on community detection.</li></ul><h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><ul><li>what is the difference between supervised and unsupervised machine learning?<ul><li>whether we have the labelled y</li></ul></li><li>what is the goal of statistical inference?<ul><li>study properties of our observed network based on already studied statistical ensemble.</li></ul></li><li>what is a probabilistic generative model?<ul><li>generate the new objects according to the probability.</li></ul></li><li>what is the likelihood function?<ul><li>$P(A|B)$</li></ul></li><li>why is the maximization of the likelihood function equivalent to the maximization of the log-likelihood function?<ul><li>because the log function is monotonic.</li></ul></li><li>Can you explain the parameters in the stochastic block model?<ul><li>$E_{kl}$: the actual number of edges between block $k$​​ and block $l$​</li><li>$N_{kl}$: the maximal number of edges between block $k$​ and block $l$​.</li><li>$M_{kl}$: the probability of an edge in block $k$​ linked to one in block $l$​.</li></ul></li><li>How can we calculate the maximum likelihood of a stochastic block model for a given block assignment vector $\vec{z}$?<ul><li>first, find the most likely block matrix.</li><li>second, calculate the likelihood on that matrix.</li></ul></li><li>Explain how we can use the stochastic block model to infer community structures in networks<ul><li>for each block number, find the optimal block assignment</li><li>compare the likelihood under different block number and choose the one best balances the complexity and fitting.</li></ul></li><li>Give an example for overfitting in the context of the stochastic block model.<ul><li>each node has its own block.</li></ul></li><li>What is “Occam’s razor” and what does it tell us about “overfitting”?<ul><li>More things should not be used than are necessary.</li><li>try to find the balance between complexity and explanatory power.</li></ul></li></ul><h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><ul><li>community detection</li><li>statistical inference</li><li>stochastic block model</li></ul><h1 id="Statistical"><a href="#Statistical" class="headerlink" title="Statistical"></a>Statistical</h1><h2 id="Statistical-ensemble"><a href="#Statistical-ensemble" class="headerlink" title="Statistical ensemble"></a>Statistical ensemble</h2><h3 id="Probabilistic-generative-model"><a href="#Probabilistic-generative-model" class="headerlink" title="Probabilistic generative model"></a>Probabilistic generative model</h3><p>A stochastic model that generates networks G with probability $P(G)$</p><ol><li> consider aggregate statistics (macrostates)</li><li><strong>define statistical ensemble</strong> of microstates</li><li>study <strong>expected properties</strong> of microstates based on macrostate.</li></ol><p>We start from abstract to numerous concrete cases and back to abstract.</p><p>Our objective is to <strong>study statistical ensemble</strong>.</p><h3 id="Reverse-way"><a href="#Reverse-way" class="headerlink" title="Reverse way"></a>Reverse way</h3><ol><li>consider empirical network $G_e$</li><li>from <strong>numerous statistical ensembles</strong>,  <strong>select</strong> the most plausible one</li><li>using our knowledge of that statistical model to make some conclusion of our network.</li></ol><p>We start from one empirical observation, and go to abstract models and back to the empirical case finally.</p><p>Our objective is to <strong>study properties of our observed network</strong> based on already studied statistical ensemble.</p><p>In some way, the probabilistic generative model should be studied first.</p><h2 id="Liklihood"><a href="#Liklihood" class="headerlink" title="Liklihood"></a>Liklihood</h2><p>the probability of a model to generate this given observation $G_e$<br>$$<br>L(\theta|G_e)=P_{\theta}(G_e)<br>$$</p><h3 id="Maximum-likelihood-estimator"><a href="#Maximum-likelihood-estimator" class="headerlink" title="Maximum likelihood estimator"></a>Maximum likelihood estimator</h3><p>the estimation of parameters that maximize the likelihood of our observation.</p><h3 id="log-likelihood-function"><a href="#log-likelihood-function" class="headerlink" title="log-likelihood function"></a>log-likelihood function</h3><p>turn the exponents into factors. A simplified calculation method.</p><ul><li>what decides the likelihood?<ul><li>observation (object)</li><li>generative model</li><li>studied statistical index</li></ul></li></ul><h1 id="Community-Detection"><a href="#Community-Detection" class="headerlink" title="Community Detection"></a>Community Detection</h1><h2 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h2><ul><li><p>optimization of partition quality/modularity $Q$​.</p></li><li><p>spectral partitioning based on Fiedler vector of Laplacian matrix </p><ul><li>This is hard partition right? means we can only partition on disconnected network, instead of finding subclusters in any network.</li></ul></li><li><p>statistical inference</p><ul><li>we define a space of statistical ensembles, each encoding different community structures.</li><li>choose the ensemble which maximizes our empirical network</li><li>decide our community structure based on the chosen ensemble. </li></ul><p>Question: what kind of statistical ensembles do we have?</p></li></ul><h1 id="Stochastic-Block-Model"><a href="#Stochastic-Block-Model" class="headerlink" title="Stochastic Block Model"></a>Stochastic Block Model</h1><h2 id="idea"><a href="#idea" class="headerlink" title="idea"></a>idea</h2><p>using <strong>latent variable</strong>: assign a node to a block.</p><ul><li>stochastic: the block assignment is stochastic</li><li>block: the final matrix is based on blocks, not nodes as common seen in network. In other way, the basic entry is block.</li><li>it is a <strong>generalization</strong> of  $G(n,p)$​ model</li><li>we can <ul><li>use the stochastic block matrix and block assignment  vector to generate a network,</li><li>use the block assignment and a network to find the maximum likelihood stochastic block matrix.</li></ul></li></ul><h2 id="Comparison-with-other-statistical-ensembles"><a href="#Comparison-with-other-statistical-ensembles" class="headerlink" title="Comparison with other statistical ensembles"></a>Comparison with other statistical ensembles</h2><ul><li>the ensembles what we have learnt:<ul><li>given some statistical index, e.g. $p$ in $G(n,p)$ model</li><li>generates new networks</li><li>For each network, it will have a corresponding likelihood.</li><li>here, network is a variable.</li></ul></li><li>stochastic block:<ul><li>given an observed network, and block number</li><li>generates new cluster assignments</li><li>For each assignment, it will have a corresponding likelihood.</li><li>here, network is a parameter.</li></ul></li></ul><h2 id="Calculation"><a href="#Calculation" class="headerlink" title="Calculation"></a>Calculation</h2><p>For given number of blocks B, the likelihood for a block assignment vector $\vec{z}$:<br>$$<br>L(M,\vec{z})=\Pi_{(i,j)\in E}M_{z_iz_j}\cdot\Pi_{(i,j)\notin E}(1-M_{z_iz_j})<br>$$</p><p>$$<br>=\Pi_{1\leq k\leq l\leq B}M_{kl}^{E_{kl}}\cdot (1-M_{kl})^{N_{kl}-E{kl}}<br>$$</p><ul><li>the matrix $M$: is an independent parameter given in ahead, not relying on others, e.g. block assignment. Different $M$ will give different likelihood. However, given $z$ ,we can find a $M_z$ returning the maximum likelihood.</li><li> $N_{kl}$ are decided by the vector $z$, the block assignment vector.</li><li> $E_{kl}$ are decided by the vector $z$ and the topology of the network.</li></ul><p>We redefine </p><p>$$<br>\hat{L}(\vec{z})=L(\hat{M}, \vec{z})=\Pi_{1\leq k\leq l\leq B}\frac{E_{kl}}{N_{kl}}^{E_{kl}}(1-\frac{E_{kl}}{N_{kl}})^{N_{kl}-E_{kl}}<br>$$</p><p>optimal block assignment definition:<br>$$<br>\hat{\vec{z}}=\arg_{\vec{z}}\max \hat{L}(\vec{z})<br>$$<br>This block detection method is still based on the edge relationship.</p><h2 id="Optimal-number-of-communities"><a href="#Optimal-number-of-communities" class="headerlink" title="Optimal number of communities"></a>Optimal number of communities</h2><p>The above likelihood is calculated given the number of blocks. But what is the optimal number of blocks?</p><h3 id="Special-case"><a href="#Special-case" class="headerlink" title="Special case"></a>Special case</h3><p>Each node is in its own cluster. In this situation, the block number is the same as the node number. The likelihood is 1. It can be interpreted that the assignment is the only possible one given the block number.</p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>We need to find a balance between the model complexity and fitting level.</p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Complex System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CN9 Spectral properties</title>
      <link href="/cn09/"/>
      <url>/cn09/</url>
      
        <content type="html"><![CDATA[<h1 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h1><ul><li>how does the topology of a network influence diffusion speed?</li><li>how fast the stationary distribution can be reached?</li><li>eigenvalues of transition matrix: captures the influence of a network on diffusion process</li><li>eigenvectors: define feedback centrality</li></ul><h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><ul><li>what is the largest eigenvalue of a transition matrix?<ul><li>1.</li></ul></li><li>what can we learn from the second-largest eigenvalue of a transition matrix?<ul><li>the speed of convergence to stationary distribution</li><li>the influence of the network topology on the diffusion speed.</li></ul></li><li>how is the diffusion speed related to the eigenvalues of the transition matrix?<ul><li>the second largest eigenvalue.</li></ul></li><li>what is the minimum time $t_\epsilon$, s.t. $\delta(\pi^{(t)}, \pi^{(0)})\leq \epsilon, \forall\epsilon&gt;0$<ul><li>$t\propto\frac{\log\epsilon}{\log \lambda_2}$</li></ul></li><li>what is the spectrum of a transition matrix? <ul><li>the sequence of ascending ordered eigenvalues</li></ul></li><li>what is the spectral gap? what does it tell us about the underlying network?<ul><li>1-second largest eigenvalue.</li><li>the speed of diffusion</li></ul></li><li>what is the spectral gap of a network that is not strongly connected?<ul><li>much less than 1.</li></ul></li><li>what is the algebraic connectivity of a network?<ul><li>the second smallest eigenvalue of the Laplacian matrix.</li></ul></li><li>what is the Fiedler vector of a network? What does it tell us about the topology?<ul><li>the second smallest eigenvectors.</li><li>the cluster belonging.</li></ul></li></ul><h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><p>diffusion speed, Laplacian spectrum, algebraic connectivity, Fiedler vector</p><h1 id="Eigen-decomposition"><a href="#Eigen-decomposition" class="headerlink" title="Eigen-decomposition"></a>Eigen-decomposition</h1><p><strong>For aperiodic and irreducible stochastic matrix T</strong></p><p>$$<br>|\lambda_i|&lt;1%2C\forall i\geq 2<br>$$</p><ul><li>is the transition matrix always has a eigenvalue of 1?<ul><li>I think so. Even i haven’t proved this.</li></ul></li></ul><h2 id="Rewrite-the-t-th-step-distribution"><a href="#Rewrite-the-t-th-step-distribution" class="headerlink" title="Rewrite the t-th step distribution"></a>Rewrite the t-th step distribution</h2><p>$$<br>\pi^{(t)}=\pi^{(0)}\cdot T^t<br>$$</p><p>$$<br>T = U^{-1}DU, T^t = U^{-1}D^tU<br>$$</p><p>$$<br>\pi^{(t)}=\pi^{(0)}\cdot U^{-1}D^t U=\sum_{i=1}^n\alpha_i\lambda_i^tu_i=\pi,\sum_{i=2}^n\alpha_i\lambda_i^tu_i<br>$$</p><p>we set $\pi^{(0)}U^{-1}=\alpha$</p><p>The last equation is the property of eigenvalue 1’s eigenvector.</p><h2 id="Total-variation-distance"><a href="#Total-variation-distance" class="headerlink" title="Total variation distance"></a>Total variation distance</h2><p>Compared to the final stable distribution<br>$$<br>\delta(\pi^{(t)},\pi)=\frac{1}{2}\sum_{j=1}^n|\pi_j-\pi^{(t)}_j|<br>$$</p><p>$$<br>=\frac{1}{2}\sum_{j=1}^n|(\sum_{i=2}^n\alpha_i\lambda_i^tu_i)_j|<br>$$</p><p>To control the distance by epsilon and use approximation,<br>$$<br>\delta(\pi, \pi^{(t)})&lt;\epsilon\sim \frac{1}{2}\sum_{j=1}^n|\lambda_2^t \alpha_2(u_2)_j|&lt;\epsilon<br>$$</p><p>$$<br>t\propto\frac{\log\epsilon}{\log \lambda_2}<br>$$</p><p><strong>The second largest eigenvalue captures the influence of network topology on diffusion speed</strong></p><h1 id="Spectrum"><a href="#Spectrum" class="headerlink" title="Spectrum"></a>Spectrum</h1><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>the descending-ordered sequence of the absolute value of eigenvalues of the transition matrix.</p><h2 id="Spectral-eigenvalue-gap"><a href="#Spectral-eigenvalue-gap" class="headerlink" title="Spectral/eigenvalue gap"></a>Spectral/eigenvalue gap</h2><p>$$<br>1-|\lambda_2|<br>$$</p><ul><li>the value range is (0,1)</li><li>the larger the spectral gap, the faster the diffusion, $t$​ is smaller</li><li>the smaller, the slower, $t$ is larger​​</li></ul><p>Allows to study the efficiency of network topologies.</p><h1 id="Laplacian-matrix"><a href="#Laplacian-matrix" class="headerlink" title="Laplacian matrix"></a>Laplacian matrix</h1><h2 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h2><p>$$<br>L=D-A<br>$$</p><ul><li>$D$ is a diagonal matrix, with the total degree of node $i$ as the $i$-th diagonal.</li><li>$A$: the adjacency matrix</li><li>the row of $L$ is 0.</li></ul><h2 id="Continuous-time-differential-model"><a href="#Continuous-time-differential-model" class="headerlink" title="Continuous time differential model"></a>Continuous time differential model</h2><p>$$<br>\frac{dx^{(t)}}{dt}=C(A-D)x^{(t)}<br>$$</p><p>Which is from<br>$$<br>\frac{\mathrm{d}x_i^{(t)}}{\mathrm{d}t}=C\sum_{j=1}^nA_{ij}[x^{(t)}_j-x^{(t)}_i]<br>$$</p><p>Written by Laplacian matrix is<br>$$<br>\frac{\mathrm{d}x^{(t)}}{\mathrm{d}t}=-CLx^{(t)}<br>$$<br>Using the knowledge of ODE, we will get<br>$$<br>x^{(t)}=\sum_{i=1}^n \alpha_i e^{-C\lambda_i t}\vec{v}_i<br>$$</p><ul><li>$C&gt;0$</li><li>eigenvalues must be larger than or equal to 0.</li></ul><h3 id="Eigenvalues"><a href="#Eigenvalues" class="headerlink" title="Eigenvalues"></a>Eigenvalues</h3><p>sort eigenvalues in <strong>ascending order</strong></p><p>smallest eigenvalue is 0. And its eigenvector is $(1,\cdots,1)$. Because $(1,\cdots,1)L=0L$​ , the sum of each column/row of $L$ is 0 </p><h4 id="Algebraic-connectivity"><a href="#Algebraic-connectivity" class="headerlink" title="Algebraic connectivity"></a>Algebraic connectivity</h4><p>the second eigenvalue of Laplacian matrix is called algebraic connectivity</p><ul><li><p>$\lambda_2=0\Leftrightarrow$ the network is disconnected.</p></li><li><p>number of 0 eigenvalues is the number of components</p></li><li><p>Diffusion speed</p></li></ul><p>if we hold $\lambda t$​ as fixed, the larger $\lambda$​ is, the smaller $t$​ is required, which means faster diffusion.<br>$$<br>x^{(t)}=\sum_{i=1}^n \alpha_i e^{-C\lambda_i t}\vec{v}_i<br>$$</p><p>$$<br>=\alpha_1\vec{v_1}+\sum_{i=2}^n \alpha_i e^{-C\lambda_i t}\vec{v}_i<br>$$</p><p>The second smallest eigenvalue will control the $t$​.</p><ul><li>$\lambda_2$ captures how well connected the network is.</li><li>$\lambda_2$ captures the influence of network topology on diffusion speed.</li></ul><h4 id="Fiedler-vector"><a href="#Fiedler-vector" class="headerlink" title="Fiedler vector"></a>Fiedler vector</h4><p>$\vec{v_2}$ is called Fiedler vector</p><p>the eigenvector of the <strong>Laplacian matrix</strong> corresponding to the second smallest eigenvalue.</p><ul><li>sign of this vector allows to detect communities. <strong>Bi</strong>sect the network. <ul><li>It can be applied recursively to detect more than two communities.</li></ul></li></ul><h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><table><thead><tr><th>matrix</th><th>Adjacency A</th><th>Transition T</th><th>Laplacian L</th></tr></thead><tbody><tr><td>meaning</td><td>simple representation of networks</td><td>transition probabilities</td><td>generalization of Laplacian operator</td></tr><tr><td>eigenvalue</td><td></td><td>largest: 1, second-largest: diffusion speed, spectral gap</td><td>smallest: 0, second smallest: algebraic connectivity, connectedness/diffusion speed</td></tr><tr><td>eigenvector</td><td>largest: eigenvector centrality, not necessarily</td><td>largest :1,  stable distribution</td><td>second-smallest: Fiedler vector</td></tr><tr><td>suitable network</td><td>undirected/directed/weighted</td><td>directed/undirected/weighted</td><td>undirected, more complicated for directed</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Complex System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CN8 Random Walks and Diffusion</title>
      <link href="/cn08/"/>
      <url>/cn08/</url>
      
        <content type="html"><![CDATA[<h1 id="Objectives"><a href="#Objectives" class="headerlink" title="Objectives"></a>Objectives</h1><ul><li>topology’s influence on dynamical process</li><li>model and analyze diffusion process in complex networks.</li><li>random walk model for diffusion</li><li>Markov chain convergence theorem</li><li>Feedback centrality measures</li></ul><h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><ul><li>how is the transition matrix of a random walk defined for weighted and unweighted networks?<ul><li>what is the entry in the transition matrix</li><li>what is the effect of weight?</li><li>$T_{ij}=\frac{A_{ij}}{\sum_k A_{ik}}$</li></ul></li><li>When does a random walk in a network converge to a unique stationary distribution?<ul><li>the transition matrix: irreducible, aperiodic</li></ul></li><li>How can we compute the stationary distribution of a random walk?<ul><li>multiply the transition matrix many times enough.</li><li>calculate the eigenvector corresponding to the eigenvalue1 of the transition matrix.</li></ul></li><li>How is total variation distance defined? What is its maximum value?<ul><li>the half of the sum of absolute difference in each dimension.</li><li>1</li></ul></li><li>For a right-stochastic transition matrix T and an initial distribution $\pi^{(0)}$, how can we compute the visitation probabilities after t steps of a random walk?<ul><li>$\pi^{(0)}T^t$</li></ul></li><li>Can you give an example for a network in which a random walk never reaches a stationary distribution?<ul><li>$\pi^{(0)}=(1,0,0)$</li><li>$P(1\to2)=1,P(2\to3)=1,P(3\to1)=1$</li></ul></li><li>Can you give an example for a network in which a random walk reaches multiple stationary distributions for different initial distributions?<ul><li>separated network with many clusters, within each cluster it will reach a stable distribution.</li></ul></li><li>How can a periodic transition matrix be made aperiodic?<ul><li>add small random values on the diagonal entries.</li></ul></li></ul><h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><p>dynamic process, total variation distance, transition matrix</p><h1 id="Dynamic-Process"><a href="#Dynamic-Process" class="headerlink" title="Dynamic Process"></a>Dynamic Process</h1><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><ul><li>Dynamic: means the nodes’ states changing with <strong>time</strong>. The network topology is <strong>static</strong>.</li></ul><h2 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h2><ul><li>Four classes:<ul><li>synchronization: the purpose of the common wave length or rhythm is to strengthen the group bond, like homophily. Property’s effect on network evolution<ul><li>e.g: people sharing the same culture work together</li></ul></li><li>consensus: nodes adopt state of neighbors.  Network evolution’s effect on property change.<ul><li>e.g.: opinion formation</li></ul></li><li>propagation: a process by which some initial quantities <strong>multiply or proliferate</strong> throughout the network. <strong>Non-conserved quantity</strong>: spreading to others doesn’t reduce the original quantity.<ul><li>e.g.: disease broadcast, rumours proliferation. </li></ul></li><li>diffusion:  net movement of anything (e.g., ideas, ions, molecules) from a region of <strong>higher</strong> concentration to a region of <strong>lower</strong> concentration. <strong>Conserved quantity</strong>.<ul><li>e.g.: water, gas, electricity transportation.</li></ul></li></ul></li></ul><h1 id="Diffusion-process"><a href="#Diffusion-process" class="headerlink" title="Diffusion process"></a>Diffusion process</h1><ul><li>the topology’s influence</li><li>the role of nodes</li></ul><h2 id="Random-Walk"><a href="#Random-Walk" class="headerlink" title="Random Walk"></a>Random Walk</h2><h3 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h3><p>using <strong>probability</strong> to model <strong>lack of knowledge</strong>.</p><p>generate <strong>random paths</strong> through a <strong>state space</strong>.</p><h3 id="Markov-Chains"><a href="#Markov-Chains" class="headerlink" title="Markov Chains"></a>Markov Chains</h3><p>If we use the <strong>Markov property</strong> (memoryless) to build random walk, we get <strong>a kind of random walk</strong>, <strong>memoryless Markov process</strong>.<br>$$<br>P(X_{t+1=s_{t+1}}|X_t=s_t)<br>$$</p><h3 id="Transition-Matrix"><a href="#Transition-Matrix" class="headerlink" title="Transition Matrix"></a>Transition Matrix</h3><p>$A$​ is the adjacency matrix of the network. We can define transition matrix as<br>$$<br>T_{ij}=\frac{A_{ij}}{\sum_k A_{ik}}<br>$$</p><ul><li>weighted/unweighted is decided by $A$.</li><li>the $T_{ij}$​​ is normalized, so we can scale out all the outgoing weights of a node without any change of $T$.</li></ul><h4 id="Row-stochastic-right-stochastic"><a href="#Row-stochastic-right-stochastic" class="headerlink" title="Row-stochastic/right-stochastic"></a>Row-stochastic/right-stochastic</h4><p>the row sum of stochastic vector is 1.</p><p><strong>Right</strong> means we multiply $T$ at the right side of a vector $vT$​. Here $v\in\mathbb{R}^{1\times N}$ </p><h4 id="Aperiodicity"><a href="#Aperiodicity" class="headerlink" title="Aperiodicity"></a>Aperiodicity</h4><p>State i is said to be periodic with period t iff</p><ul><li>$T_{ii}^{(n)} = 0, \forall n\neq t, 2t, 3t, \cdots$</li><li>$T_{ii}^{(n)} \neq 0, \forall n= t, 2t, 3t, \cdots$</li></ul><p>Write in another way<br>$$<br>r(s_i)= \text{gcd}{t\geq 1: (T^t)_{ii}&gt;0}<br>$$</p><ul><li>aperiodic: $r(s_i)=1,\forall i\in V$ </li><li>periodic: otherwise</li></ul><p>How to make a matrix aperiodic?</p><ul><li>add small random value on the diagonal items. </li><li>$T_{ii}=\epsilon,\forall v\in V$</li><li>a random walk with such a transition matrix is called lazy.</li><li>a network with self-loop</li></ul><h4 id="Irreducibility"><a href="#Irreducibility" class="headerlink" title="Irreducibility"></a>Irreducibility</h4><p>Reducible:<br>$$<br>\exists (i,j), \delta,\forall t&gt;\delta, (T^t)_{ij}=0<br>$$<br>Means </p><ul><li><strong>strong connectivity</strong> of directed networks.</li><li>connectivity of undirected networks.</li></ul><h4 id="Markov-Chain-Convergence-theorem"><a href="#Markov-Chain-Convergence-theorem" class="headerlink" title="Markov Chain Convergence theorem"></a>Markov Chain Convergence theorem</h4><p>$T$: irreducible and aperiodic</p><p>for any initial distribution $\pi^{(0)}$​<br>$$<br>\exists| \pi,\delta(\pi^{(t)},\pi)\to 0 (t\to \infty)<br>$$<br>the stable distribution is <strong>independent</strong> from the initial distribution.</p><h4 id="Existence"><a href="#Existence" class="headerlink" title="Existence"></a>Existence</h4><p>if there is a <strong>periodic</strong> behavior, the network doesn’t have a stationary distribution.</p><p><strong>Lazy</strong></p><h4 id="Uniqueness"><a href="#Uniqueness" class="headerlink" title="Uniqueness"></a>Uniqueness</h4><p>means for all possible initial distribution, have only one final stable distribution. Requires irreducibility.</p><p>Initial Distribution<br>$$<br>\pi^{(0)}\in\mathbb{R}^{1\times N}<br>$$</p><ul><li>the sum is 1.</li><li>all entries are non-negative.</li></ul><p>$$<br>\pi^{(t)}=\pi^{(0)}\cdot T^t<br>$$</p><h3 id="Stationary-distribution"><a href="#Stationary-distribution" class="headerlink" title="Stationary distribution"></a>Stationary distribution</h3><p>$$<br>\pi^{(t)}= \pi^{(t+1)}\cdot 1=\pi^{(t)}\cdot T<br>$$</p><ul><li>the left eigenvector of $T$ corresponding to eigenvalue $v=1$.</li><li>gives a notion of node centrality, feedback centrality.</li></ul><p>View from another point:</p><p>$T^{t}_{ij}$: the probability of node $i$​​​ goes to node $j$​​​​​ after $t$​​​​ steps. </p><p>It should be unchanged when $t$​​ is large enough. </p><p>That is, there is a $t_0$​​​,</p><p>$$<br>\forall t&gt;t_0 \forall k&gt;0 T^{t+k}<em>{ij}=T^t</em>{ij}<br>$$</p><ul><li>That means, $T^{t+1} = T^t =T^t\cdot T$ Each row of $T^t$ is the eigenvector of $T$, with the eigenvalue 1.</li><li>The stationary distribution is also the eigenvector of $T$ with the eigenvalue 1.</li><li>Each row of $T^t$ is the same, which is exactly the stationary distribution $\pi$.</li></ul><h4 id="To-network"><a href="#To-network" class="headerlink" title="To network"></a>To network</h4><ul><li>undirected network: $\pi_i=\frac{d_i}{2m}$ directly related to the node degrees</li><li>directed network: <ul><li>the number of nodes pointing to  a node</li><li>the importance of these pointing nodes</li></ul></li></ul><h2 id="Total-Variation-distance"><a href="#Total-Variation-distance" class="headerlink" title="Total Variation distance"></a>Total Variation distance</h2><p>$$<br>\delta(\pi_1,\pi_2)=\frac{1}{2}\sum_i |\pi_{1,i}-\pi_{2,i}|<br>$$</p><ul><li>normalized by 2: to restrict the value less than or equal to 1. The biggest value of the sum of differences for each dimension is 2, with the 1-sum restriction. </li><li>used to measure if a sequences of vectors converges.</li></ul><h1 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h1><h2 id="Connectivity-of-directed-networks"><a href="#Connectivity-of-directed-networks" class="headerlink" title="Connectivity of directed networks"></a>Connectivity of directed networks</h2><ul><li>strongly connected: all pairs of nodes $i,j$​ have a path from $i$​ to $j$​ and from $j$​ to $i$.</li><li>weakly connected: if the corresponding undirected network is connected.</li></ul><h2 id="Feedback-Centrality"><a href="#Feedback-Centrality" class="headerlink" title="Feedback Centrality"></a>Feedback Centrality</h2><p>$$<br>\pi = \pi \cdot T<br>$$</p><p>$$<br>\pi_j = \sum_i \pi_i T_{ij}<br>$$</p><ul><li><p>feedback: the centrality of those nodes that point to a node influence the node’s centrality.</p></li><li><p>a node that is pointed to by “important” nodes should be “intuitively” more important than those pointed by “unimportant” nodes.</p></li><li><p>a node’s importance transition on others will be reduced with more outgoing links.</p></li></ul><h3 id="Zero-indegree"><a href="#Zero-indegree" class="headerlink" title="Zero-indegree"></a>Zero-indegree</h3><p>  Since a node’s eigenvector, feedback centrality, is determined by its in-going nodes, a node with indegree 0 has 0 centrality.</p><p>  <strong>Useless</strong> for <strong>directed acyclic graphs</strong>.</p><h4 id="Solution-PageRank"><a href="#Solution-PageRank" class="headerlink" title="Solution: PageRank"></a>Solution: PageRank</h4><p>  assign constant amount of one unit of centrality “for free”<br>$$<br>\alpha x= x\cdot T+\vec{1}<br>$$</p><p>$$<br>x_j =\frac{1}{\alpha}\sum_i x_i\frac{A_{ij}}{d_{out}(i)}+1<br>$$</p><h2 id="Eigenvector-Centrality"><a href="#Eigenvector-Centrality" class="headerlink" title="Eigenvector Centrality"></a>Eigenvector Centrality</h2><p>$$<br>\alpha x= x\cdot A<br>$$</p><p>$$<br>x_j=\frac{1}{\alpha}\sum_i x_iA_{ij}<br>$$</p><ul><li>$\alpha$ is the largest eigenvalue of  $A$<ul><li>usually, we take the largest one, but not necessarily.</li></ul></li><li>$T$ is replaced by the adjacency matrix $A$. The difference is whether to normalize the degrees. In another way, whether “conserve quantity”. <ul><li>$T$: conserve</li><li>$A$: not conserve</li><li>The importance of a node will keep even with more outgoing links.</li></ul></li></ul><h2 id="Centrality-comparison"><a href="#Centrality-comparison" class="headerlink" title="Centrality comparison"></a>Centrality comparison</h2><ul><li>degree: local measure</li><li>Betweenness, closeness, eigenvector, and PageRank: global characteristics</li></ul><p>​    </p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Complex System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CIL9 Dictionary Learning</title>
      <link href="/cil-9dl/"/>
      <url>/cil-9dl/</url>
      
        <content type="html"><![CDATA[<h1 id="Compressive-Sensing"><a href="#Compressive-Sensing" class="headerlink" title="Compressive Sensing"></a>Compressive Sensing</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Compress data while gathering. This will save a lot of storage memory.</p><p>The problem is we also need to decompress the signals.</p><h2 id="Concept"><a href="#Concept" class="headerlink" title="Concept"></a>Concept</h2><ul><li><p>original signal:  $x\in\mathbb{R}^D$</p></li><li><p>“root signal”:  $z\in\mathbb{R}^D$</p><p>This signal tells something essence of $x$. For example, we have 5 clusters in a 20-D data points. The  $z$ shows which cluster  $x$ belongs to. So,  $z$ can be very simple, $K$-sparse, here $K\ll D, K=5$ , but  may $x$ <strong>look</strong> complex.  We view  $z$ as the root of the signal $x$​.<br>$$<br>x=Uz<br>$$</p></li><li><p>measured signal, also compressed signal: $y\in\mathbb{R}^M, M&lt;D$​. It is what we get after compression. $y=Wx$</p></li><li><p>reconstructed signal: $\hat{x}=U\hat{z}$ . We get the reconstructed signal by find the “optimal” $\hat{z}$​.</p><ul><li>does it assume that we have already known $U$ and $W$?</li></ul></li></ul><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h3><p>Recover a sparse signal $x$ from measurements $y$. However, we cannot directly use the inversion of matrix. Because the matrix is invertible due to the rank. How should we do? We try to use the condition of the sparsity. Instead of find  $x$ directly, we find  $\hat{z}$​<br>$$<br>\hat{z}\in\arg_z\min |z|_0, \text{s.t. } y=WUz<br>$$</p><h3 id="Sufficient-conditions"><a href="#Sufficient-conditions" class="headerlink" title="Sufficient conditions"></a>Sufficient conditions</h3><p>Given any orthonormal basis $U$ we can obtain a stable reconstruction for any $K$-sparse, compressible signal.</p><p>two conditions to be satisfied:</p><ul><li> $W$ = Gaussian random projection, i.e. $w_{ij}\sim\mathcal{N}(0,\frac{1}{D})$</li><li>$M\geq cK\log \frac{D}{K}$</li></ul><h3 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h3><p>using (1) convex optimization or (2) matching pursuit to solve the objective.</p><h1 id="Dictionary-Learning"><a href="#Dictionary-Learning" class="headerlink" title="Dictionary Learning"></a>Dictionary Learning</h1><p>In traditional encoding, we are given a basis $U\in\mathbb{R}^{D\times D}$ and directly code the “root” signal by $Uz$ to get $x$. However, it is not problem-specific. We try to learn a $U\in\mathbb{R}^{D\times L}$  to do sparse encoding and more problem-specific. </p><p>Mathematically, it is to find $U\in\mathbb{R}^{D\times L}$​, s.t. $X\simeq U\cdot Z$</p><ul><li>subject to sparsity on $Z\in\mathbb{R}^{L\times N}$</li><li>subject to column/atom norm constraint on $U\in\mathbb{R}^{D\times L}$</li></ul><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>$$<br>(U^\ast, Z^\ast)\in\arg\min_{U,Z}|X-U\cdot Z|_F^2<br>$$</p><ul><li>not convex jointly in $U$ and $Z$, but separately</li></ul><h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><p>Using <strong>iteratively greedy algorithm</strong> to solve, like EM algorithm</p><ul><li>coding step:<br>$$<br>Z^{(t+1)}=\arg\min_Z|X-U^{(t)}Z^{(t)}|_F^2<br>$$</li></ul><p>This is <strong>column separable</strong> problem. </p><p>$$<br>z_j^{(t+1)}=\arg\min_{z_j}|x_j -U^{(t)}z_j^{(t)}|_F^2, j\in 1,2,\cdots, N<br>$$</p><p>it is a sparse coding problem. Change the Frobenius norm as non-zero norm:<br>$$<br>z_n^{(t+1)}=\arg\min_{z_n}|z_n|_0<br>$$<br>s.t.<br>$$<br>|x_n - U^tz_n|_2\leq \sigma\cdot |x_n|_2<br>$$<br>​    - are these two equivalent???        </p><ul><li><p>dictionary update step:<br>$$<br>U^{(t+1)}=\arg\min_U|X-U^{(t)}Z^{(t+1)}|_F^2<br>$$<br>it is <strong>not separable</strong> for U. We use <strong>approximation</strong> strategy, updating one atom at a time</p><ol><li>Set $U=[u_1^t,u_2^t,\cdots, u_l^t, \cdots, u_L^t]$,  fix all other atoms except $u_l$</li><li>Isolate $R_l^t$, the residual that is due to atom $u_l$</li><li>Find $u_l^\ast$​ that minimizes $R_l^t$​, subject to $|u_l^\ast|_2=1$. </li></ol></li></ul><h4 id="Precise-Solution-of-U"><a href="#Precise-Solution-of-U" class="headerlink" title="Precise Solution of U"></a>Precise Solution of U</h4><p>Actually, $u_l^\ast$​​ can be exactly calculated. The objective can be rewritten into<br>$$<br>u_l^\ast = \arg\min_{u_l} |R_l - u_l z_l^\top |_F^2<br>$$</p><p>Here, $z_l$ is the $l$-th row of the matrix $Z$. $|R_l - u_l z_l^\top |<em>F^2$<br>$$<br>=\sum |R</em>{l(\cdot, n)}-u_l z_{l,n}|_F^2<br>$$</p><p>$$<br>=\sum_{n=1}^N\sum_{i=1}^L[R_{l(i,n)}-u_{l(i)}z_{l,n}]^2<br>$$</p><p>$$<br>=\sum_{i=1}^L\sum_{n=1}^N[R_{l(i,n)}-u_{l(i)}z_{l,n}]^2<br>$$</p><p>Using Lagrange equation and derivative by $u_{l(i)}$​, we get<br>$$<br>u_{l(i)}=\frac{\sum_{n=1}^N R_{l(n,i)}z_n}{\lambda + \sum_{n=1}^N z_n^2}<br>$$<br>Normalized to replace $\lambda$​, we can get<br>$$<br>u_{l(i)}^\ast = \frac{\sum_{n=1}^N R_{l(n,i)}z_n}{\sum_{n=1}^N\sum_{i=1}^L R_{l(n,i)}z_n}<br>$$<br>After getting $u_l^\ast$, we still need to update $z_l$.</p><p>Compared to the below approximate solution, this method is much computation consuming, needing multiple times iterations. But the SVD solution directly catches the essence of the matrix, only needing one time computation.</p><h4 id="Approximate-solution-of-U"><a href="#Approximate-solution-of-U" class="headerlink" title="Approximate solution of U"></a>Approximate solution of U</h4><p>We can also solve $u_l^\ast$ by approximate K-SVD update. K means the sparsity is $K$.<br>$$<br>|Z^\ast|_0\leq K<br>$$<br>Since our objective is to minimize the residual:<br>$$<br>|R_l - u_lz_l^\top|_F^2<br>$$<br>Actually, it is to approximate $R_l$ by a rank-1 matrix $u_lz_l^\top$</p><p><strong>SVD can be viewed as decompose a matrix by the sum of several rank-1 matrices.</strong><br>$$<br>E_l = \sum_{i}\sigma u_i v_i^\top<br>$$<br>The framework is:</p><ol><li>we do SVD decomposition of $R$</li><li>take the first left-singular vector $u_l^\ast = u_1$</li><li>update $z=\sigma_1v_1^\top$ </li></ol><p>The 1st singular value realization is: </p><ol><li><p>we extract the active data points from the whole $N$ points at $l$​.<br>$$<br>\mathcal{N}\leftarrow {n|Z_{ln}\neq 0, 1\leq n\leq N}<br>$$</p></li><li><p>calculate $R$​​, by $R\leftarrow X_{:,\mathcal{N}} - UZ_{(:,\mathcal{N})}$​</p></li><li><p>define $g\leftarrow z_{l,\mathcal{N}}^\top$ </p></li><li><p>$u_l^\ast\leftarrow\frac{Rg}{|Rg|}$</p></li><li><p>$z_{l,\mathcal{N}}\leftarrow g^\top$</p><p>In the step 4, we use the power iteration, the power is only 1 here. $\frac{R^kg}{|R^kg|}$</p><p>The theory basis is if we do SVD for $R_l$, </p><ul><li>$u_l^\ast$ is the first left-singular vector.<ul><li>any proof</li><li>from the above solution. The “precise” solution is not a good solution. We should use SVD approximation. Since the precise solution of u is based on z, it is only optimal given z. However, we will update z after getting u. So, u will not be good enough under the new z. We need to iterate multiple times until convergence.</li><li>But in SVD, we directly use the 1st singular value, no need to iterating.</li></ul></li></ul></li></ol><h4 id="Initialization"><a href="#Initialization" class="headerlink" title="Initialization"></a>Initialization</h4><ul><li>random atoms. Normal distribution and scale to unit</li><li>samples from $X$: sample $L$ times  from $X$,  according to the uniform distribution of index. Then scale to the unit.</li><li>fixed overcomplete dictionary, such as DCT.</li></ul><h2 id="Adaptation"><a href="#Adaptation" class="headerlink" title="Adaptation"></a>Adaptation</h2><h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h2><h2 id="image-reconstruction"><a href="#image-reconstruction" class="headerlink" title="image reconstruction:"></a>image reconstruction:</h2><ul><li>train a lot of data to get the dictionary</li><li>learn a sparse code $z$ for a given data $x$</li><li>modify $z$ and get $\hat{z}$</li><li>reconstruct $\hat{x}=U\hat{z}$</li></ul><h2 id="Speech-denoise"><a href="#Speech-denoise" class="headerlink" title="Speech denoise"></a>Speech denoise</h2><p>The record is composed of the original speech and interferer. We want to remove the interferer and leave the original speech.</p><h3 id="Method-1"><a href="#Method-1" class="headerlink" title="Method"></a>Method</h3><ol><li>learn dictionaries for speech $U_c$ and interferer  $U_n$ specifically.</li><li>Encoding the measured signal $x$on these two dictionaries $[z_c, z_n]$​.</li><li>Drop the encoded signals on the interferer dictionary, only keep the speech encoded signals $[z_c, 0]$. </li><li>Recover the “pure”  signal $\hat{x}=U_c z_c$</li></ol><h4 id="Learning-step"><a href="#Learning-step" class="headerlink" title="Learning step"></a>Learning step</h4><p>learn the two dictionaries</p><p>$$<br>(U^\ast, Z^\ast)\in\arg\min_{U,Z}|X-U\cdot Z|_F^2<br>$$</p><p>s.t. $|u^\ast_{(:,d)}|_2=1,\forall d=1,2,\cdots, L$ , $|Z^\ast|_0\leq K$</p><h4 id="Enhancement-step"><a href="#Enhancement-step" class="headerlink" title="Enhancement step"></a>Enhancement step</h4><p>Using the learned dictionaries to encode the signals and drop noise signals.<br>$$<br>(z^{(s)\ast}, z^{(i)\ast})\leftarrow \arg\min |X-[U^{(s)}U^{(i)}]\cdot [z^{(s)}z^{(i)}]^\top|_2<br>$$<br>s.t. $|z_s^\ast|_0 + |z_i^\ast|_0\leq K$, $\hat{x}=U_s^\ast z_s^\ast$ </p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CN7 Scale-Free Network and limitations of Ensemble Studies</title>
      <link href="/cn07/"/>
      <url>/cn07/</url>
      
        <content type="html"><![CDATA[<h1 id="Objectives"><a href="#Objectives" class="headerlink" title="Objectives"></a>Objectives</h1><ul><li>analyzing robustness with generating functions</li><li>robustness of scale-free network</li><li>limitations of ensemble-based approach</li><li>AS-level Internet topology</li></ul><h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><ul><li>what is the critical failure probability $q_c$ for random networks with arbitrary degree distribution?<ul><li>the failure probability making the average clustering size goes to finite.</li></ul></li></ul><p>$$<br>q_c=1-(\frac{\langle k^2\rangle}{\langle k\rangle}-1)^{-1}<br>$$</p><ul><li>what is $q_c$ for $G(n,p)$ model?</li></ul><p>$$<br>q_c=1-\frac{1}{np}<br>$$</p><ul><li>what are scale-free network? How can we characterize their degree distribution in the finite and infinite case?<ul><li>the degree distribution follows power-law distribution</li><li>finite: $P(k)=k^{-\gamma}(\sum_{i=1}^N i^{-\gamma})^{-1}=\frac{k^{-\gamma}}{\sum_{i=1}i^{-\gamma}}$​ </li><li>infinite: $P(k)=\frac{k^{-\gamma}}{\zeta(\gamma)}$</li></ul></li><li>what is $q_c$ for a scale-free network with exponent $\gamma$ in the limit of infinite size?<ul><li>$q_c= 1-(\frac{\zeta(\gamma-2)}{\zeta(\gamma-1)}-1)^{-1}$</li></ul></li><li>what is the reason for the discrepancy between the predicted and the empirical surviving lcc for random failures in scale-free networks?<ul><li>degree distribution</li><li>finite nodes</li><li>different ensemble methods.</li></ul></li><li>what is the robust-yet-fragile nature of random scale-free network?<ul><li>critical failure rate approximates to 1.</li><li>relies heavily on few important nodes.</li></ul></li><li>explain three possible fallacies that can occur when applying the ensemble perspective to real systems?<ul><li>degree distribution</li><li>finite/infinite</li><li>ensemble methods</li></ul></li></ul><h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><ul><li>critical failure probability</li><li>scale-free network</li><li>ensemble methods fallacies</li></ul><h1 id="Robustness"><a href="#Robustness" class="headerlink" title="Robustness"></a>Robustness</h1><p>Related to the <strong>giant connected components</strong>: at which point does the removal of nodes destroy the giant connected component of a network system?</p><p><strong>Topological robustness</strong>: the robustness of a system’s connectedness against the loss of nodes and/or links</p><h2 id="Assumptions"><a href="#Assumptions" class="headerlink" title="Assumptions"></a>Assumptions</h2><ul><li>stochastic node failure model<ul><li>each node has the uniform failure probability $q$</li><li>failed nodes and all adjacent links are removed.</li><li>node failures are independent.</li></ul></li></ul><h2 id="Generating-functions"><a href="#Generating-functions" class="headerlink" title="Generating functions"></a>Generating functions</h2><p>We try to model the distribution of the survived connected component size. Then, see the mean size of connected components.</p><h3 id="H-0"><a href="#H-0" class="headerlink" title="$H_0$"></a>$H_0$</h3><p>distribution of surviving component size for a randomly chosen node $v$</p><p>Think of the original expand form of $H_0$​<br>$$<br>H_0(x)= P(K=0)x^0+\sum_{i=1}^{\infty}P(K=i)x^i<br>$$</p><ul><li>$P(K=0)$ means the node $v$ fails. The probability is $q$</li><li>consider the second part. Following our past method, we consider the distribution of the neighbor of node $v$. Here, we define two other generating functions:<ul><li>$H_1$: the distribution of surviving component size of a node $w$ as a neighbor of another node $v$</li><li>$F_0$: like $G_0$, which describes the degree distribution of a node $v$, describe the degree distribution of a node $v$ with the failure probability $q$.</li></ul></li><li>Then, we can rewrite $H_0$ as </li></ul><p>$$<br>H_0=q+xF_0(H_1(x))<br>$$</p><p>$$<br>H_0’(x)=F_0(H_0(x))+xF_0’(H_1(x))H_1’(x)<br>$$</p><p>$$<br>\Rightarrow H_0’(1)=1-q+F_0’(1)H_1’(1)<br>$$</p><h3 id="H-1"><a href="#H-1" class="headerlink" title="$H_1$"></a>$H_1$</h3><p>the distribution of surviving component size of a node $w$ as a neighbor of another node $v$</p><p>like $H_0$,$H_1$ can also be decomposed by two parts, </p><ul><li>the node fails, the probability is $q$</li><li>the node doesn’t fail</li></ul><p>like we calculate the surviving component size, there is “self-consistency”.<br>$$<br>H_1=q+xF_1(H_1(x))<br>$$</p><ul><li>we include $F_1(X)$, also denote “direction”, the “children neighbor” of node $w$​.</li></ul><p>$$<br>H_1’(x)=F_1(H_1(x))+F_1’(H_1(x))H_1’(x)<br>$$</p><p>$$<br>\Rightarrow H_1’(1) =1-q+F_1’(1)H_1’(1)<br>$$</p><p>$$<br>\Rightarrow H_1’(1) =\frac{1-q}{1-F_1’(1)}<br>$$</p><h3 id="F-0"><a href="#F-0" class="headerlink" title="$F_0$"></a>$F_0$</h3><p> **Part of ** the distribution of a node degree, with the node failure probability $q$ what we know is a fixed degree distribution, that is $G_0$. So, we want to know $F_0$ from $G_0$ and $q$​</p><p>The probability that a node $v$​ has degree $k$​ and survives is generated by<br>$$<br>F_0(x)=\sum_{k=0}^{\infty}(1-q)P(k)x^k = (1-q)G_0(x)<br>$$<br>Note that $F_0(1)=1-q$, not 1. It is due to we only consider the surviving part of the network, not the whole part.</p><h3 id="F-1"><a href="#F-1" class="headerlink" title="$F_1$"></a>$F_1$</h3><p>similarly,  $F_1(x)=(1-q)G_1(x)$</p><h3 id="langle-s-rangle-​"><a href="#langle-s-rangle-​" class="headerlink" title="$\langle s\rangle$​"></a>$\langle s\rangle$​</h3><p>$$<br>\langle s\rangle=H_0’(1) = 1-q+1\cdot F_0’(1)H_1’(1)<br>$$</p><p>$$<br>=1-q+\frac{(1-q)F_0’(1)}{1-F_1’(1)}=( 1+\frac{(1-q)G_0’(1)}{1-(1-q)G_1’(1)})(1-q)<br>$$</p><h3 id="Critical-failure-rate"><a href="#Critical-failure-rate" class="headerlink" title="Critical failure rate"></a>Critical failure rate</h3><p>When the denominator is closed to 0, is the key point.</p><p>That is<br>$$<br>G_1’(1)\to \frac{1}{1-q}<br>$$<br>and<br>$$<br>G_1’(1)=\frac{\langle k^2\rangle}{\langle k\rangle}-1<br>$$<br>we have<br>$$<br>q_c =1-(\frac{\langle k^2\rangle}{\langle k\rangle}-1)^{-1}<br>$$</p><h2 id="Remark"><a href="#Remark" class="headerlink" title="Remark"></a>Remark</h2><p>Since we use whether the average component size is finite to judge the robustness, it hides the assumption that $n\to\infty$</p><p> This formula gives an upper bound of the failure rate.</p><h2 id="E-R-Model"><a href="#E-R-Model" class="headerlink" title="E-R Model"></a>E-R Model</h2><p>In ER model, we have<br>$$<br>\frac{\langle k^2\rangle}{\langle k\rangle}=\frac{np+n^2p^2}{np}= 1+np<br>$$<br>So,<br>$$<br>q_c= 1-\frac{1}{np}<br>$$<br>According to the Molloy-Reed criterion, when $np&gt;1$​, we have a giant connected component. That is $\langle k\rangle&gt;1$</p><h2 id="K-regular-network"><a href="#K-regular-network" class="headerlink" title="$K$-regular network"></a>$K$-regular network</h2><p>In K-regular model all nodes have the same degree $k$​.<br>$$<br>\frac{\langle k^2\rangle}{\langle k\rangle}=\frac{k^2}{k}=k<br>$$<br>So,<br>$$<br>q_c= 1-\frac{1}{k-1}<br>$$<br>According to the Molloy-Reed criterion, we need $\langle k\rangle=k&gt;2$</p><p>It is different from the E-R, due to the variance of nodes. It tells us the <strong>variance makes networks more robust!!</strong></p><h2 id="Broad-distribution-network"><a href="#Broad-distribution-network" class="headerlink" title="Broad distribution network"></a>Broad distribution network</h2><p>Explanations are below:<br>$$<br>\frac{\langle k^2\rangle}{\langle k\rangle}=\frac{\zeta(\gamma-2)}{\zeta(\gamma-1)}<br>$$</p><ul><li><p>when $\gamma\in(2,3)$, the denominator is finite and the nominator is infinite.</p></li><li><p>so,  $q_c=1-(\frac{\zeta(\gamma-2)}{\zeta(\gamma-1)}-1)^{-1}$</p></li><li><p>when  $\gamma\in(2,3),q_c\to\infty$.</p><p>This shows the scale-free network is <strong>super-robust</strong> against random failures. </p><ul><li>In the limit of <strong>infinite</strong> network size, the scale-free network cannot be destroyed by any random failure probability.</li></ul></li></ul><h1 id="Scale-free-network"><a href="#Scale-free-network" class="headerlink" title="Scale-free network"></a>Scale-free network</h1><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><ul><li>power law distribution<ul><li><p>scale invariance: $P(\alpha k)\propto P(k)$</p></li><li><p>$$<br>P(k)=k^{-\gamma}(\sum_{i=1}^N i^{-\gamma})^{-1}=\frac{k^{-\gamma}}{\sum_{i=1}i^{-\gamma}}<br>$$</p></li><li><p>this is one kind of <strong>broad distribution</strong>. Other broad distribution examples: Zipf distribution.</p></li><li><p>$\gamma$ decides how quickly the distribution drops. The lager the quicker.</p></li></ul></li></ul><h2 id="Approximation"><a href="#Approximation" class="headerlink" title="Approximation"></a>Approximation</h2><p>We use <strong>Zeta distribution</strong> to imitate power-law distribution degrees with $n\to\infty$</p><p>The formula of Zeta distribution:</p><p>$$<br>P(k) =\frac{k^{-\gamma}}{\zeta(\gamma)}<br>$$</p><p>where<br>$$<br>\zeta(\gamma) =\sum_{i=1}i^{-\gamma}<br>$$<br>It is valid for $\gamma&gt;1$ </p><ul><li><p>$\zeta(\gamma\to 1) %3D \to\infty$</p></li><li><p>$\langle k^m\rangle=\frac{\zeta(\gamma-m)}{\zeta(\gamma)}$</p></li></ul><h2 id="Diameter"><a href="#Diameter" class="headerlink" title="Diameter"></a>Diameter</h2><p>$$<br>D\simeq\frac{\log\log(n)}{\log(\gamma-2)}<br>$$</p><ul><li>for $\gamma\in(2,3)$, $\gamma-2\in(0,1)$<ul><li>the smaller $\gamma$​, the larger the absolute value of $\log(\gamma)$ will be, the smaller D (the diameter) will be</li></ul></li></ul><p>Conclusion:</p><ul><li>networks where the degree distribution has an infinite second raw moment have a very small diameter.</li><li>the more heterogeneous the degree distribution (smaller $\gamma$) is, the smaller diameter will be.</li></ul><h2 id="Robustness-1"><a href="#Robustness-1" class="headerlink" title="Robustness"></a>Robustness</h2><p>Super robust. See above.</p><p>Different from ER model, the limitation of finite size matters a lot here.</p><h2 id="Fragility"><a href="#Fragility" class="headerlink" title="Fragility"></a>Fragility</h2><h3 id="Degree-dependent-failure-ratio"><a href="#Degree-dependent-failure-ratio" class="headerlink" title="Degree-dependent failure ratio"></a>Degree-dependent failure ratio</h3><p>the nodes with high degree are more likely to be attacked, or to fail.</p><p>it could be true, considering</p><ul><li>targeted attack</li><li>load-dependent failures of nodes</li><li>…</li></ul><p>The random scale-free networks are</p><ul><li>robust, against random failures</li><li>fragile, against degree-dependent failure.</li></ul><h1 id="Limitations-of-ensemble-studies"><a href="#Limitations-of-ensemble-studies" class="headerlink" title="Limitations of ensemble studies"></a>Limitations of ensemble studies</h1><ul><li>analytical form of <strong>degree distribution</strong> is foundation for theoretical claims.<ul><li>e.g. log-normal distribution looks quite similar to zeta distribution.</li></ul></li><li>finite or infinite. <ul><li>the theoretical assumption is infinite</li><li>the real case is finite, even large.</li></ul></li><li>microstates vs real system<ul><li>different choice of ensemble methods, based on different microstates of the given systems. may generate quite different statistical results.<ul><li>our statistical findings are based on our assumptions.</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Complex System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CIL8 Sparse Coding</title>
      <link href="/cil-8sc/"/>
      <url>/cil-8sc/</url>
      
        <content type="html"><![CDATA[<h1 id="Sparse-Coding"><a href="#Sparse-Coding" class="headerlink" title="Sparse Coding"></a>Sparse Coding</h1><p>Encode an entity by fewer digits. What we need: a dictionary to encoding and the input signal. We will return the output signal.</p><ul><li>how to build the dictionary or find the suitable basis?<ul><li>Fixed ahead: Fourier, wavelet</li><li>Build according to the data: PCA.</li></ul></li></ul><h2 id="Key-idea"><a href="#Key-idea" class="headerlink" title="Key idea"></a>Key idea</h2><p>the dictionary should be orthogonal!</p><h2 id="Advantage"><a href="#Advantage" class="headerlink" title="Advantage"></a>Advantage</h2><p><a href="https://blog.csdn.net/YZXnuaa/article/details/80054179">csdn</a></p><p>Using as little resource as possible to learn as much knowledge as possible and accelerate the speed.</p><h2 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h2><h3 id="Fourier"><a href="#Fourier" class="headerlink" title="Fourier"></a>Fourier</h3><p>basis functions:<br>$$<br>f(k)=\sum_na_n\sin(\omega_n k)<br>$$</p><ul><li><p>continuous: $a_n=\frac{1}{\pi}\int_{-\pi}^\pi f(x)\sin nx \mathrm{d}x$</p></li><li><p>discrete: $a_n = \sum_{k=1}^N x_k\sin(\omega_n k)$<br>$$<br>f(x)=\sum_{n=1}\frac{4}{(2n-1)\pi}\sin(2n-1)x<br>$$</p></li><li><p>not sufficient for localized signals</p></li></ul><h4 id="In-2-D"><a href="#In-2-D" class="headerlink" title="In 2-D"></a>In 2-D</h4><ul><li>procedure:<ul><li>first take FT of the columns then FT of the rows. can be interchanged</li></ul></li><li>Interpretation:<ul><li>large changes in the pixel values: high frequency, e.g. edges, background objects.</li></ul></li></ul><h3 id="Discrete-cosine-transform"><a href="#Discrete-cosine-transform" class="headerlink" title="Discrete cosine transform"></a>Discrete cosine transform</h3><ul><li><p>1-D: $z_k=\sum_{n=0}^{N-1}x_n\cos\frac{(2n+1)\pi k}{2N}$​​​​</p></li><li><p>2-D: $z_{k_1, k_2}=\sum_{n_1=0}^{N_1-1}\sum_{n_2=0}^{N_2-1}\cos\frac{(2n_1+1)\pi k_1}{2N_1}\cos\frac{(2n_2+1)\pi k_2}{2N_2}$</p></li></ul><h3 id="Wavelet"><a href="#Wavelet" class="headerlink" title="Wavelet"></a>Wavelet</h3><h4 id="Haar-Wavelet"><a href="#Haar-Wavelet" class="headerlink" title="Haar Wavelet"></a>Haar Wavelet</h4><ul><li>Construction: all basis functions have zero mean, that’s why we add (1,1,…,1) vectors.</li><li>use the <strong>mother wavelet</strong> to create the other Haar functions.</li><li>use the scaling function to normalize it.</li></ul><h3 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h3><p>PCA is too sensitive to noise. That is it is only valid for data having the Gaussian distribution.</p><h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h2><h3 id="1-D-signal"><a href="#1-D-signal" class="headerlink" title="1-D signal"></a>1-D signal</h3><h3 id="2-D-signal"><a href="#2-D-signal" class="headerlink" title="2-D signal"></a>2-D signal</h3><ul><li>how to do Fourier/wavelet transform on 2-d signals?</li></ul><h1 id="Overcomplete-Dictionary"><a href="#Overcomplete-Dictionary" class="headerlink" title="Overcomplete Dictionary"></a>Overcomplete Dictionary</h1><h2 id="Key-idea-1"><a href="#Key-idea-1" class="headerlink" title="Key idea"></a>Key idea</h2><p>do sparse coding by using a very large dictionary. Try to find the optimally <strong>sparse</strong> encoding for all the data.</p><ul><li>why to encode sparsely? The advantage of doing so?<ul><li>maybe find clusters? Like, four clusters nodes in 3-D. They are sprayed into four clusters. If we use 4-D vectors to encode these points, the encoded vectors will be quite sparse. For example, in the original 3-D coding, we use 1-256 for each dimension, totally, we need 256*3 bits. But in the 4-D coding, we use 0,1 for each dimension, we need 2*4 bits. That makes sense.</li></ul></li><li>how to do this?<ul><li>pick atoms from <strong>a union</strong> of bases, (not just one set of orthogonal basis), each one responsible for one characteristic.</li></ul></li><li>Compared to the former method, the bases are <strong>no</strong> longer linearly independent. <ul><li>the representation of $x$ in terms of  $u_1,u_2,\cdots, u_l$is <strong>not unique</strong>.</li></ul></li></ul><p>Goal: want to find sparse representation $z$ of $x$​<br>$$<br>z^\ast\in\arg\min_{z\in R^l}|z|_0<br>$$<br>where $Uz=x, U=[u_1|u_2|\cdots|u_n]$ . Here  $|z|_0$ counts the number of non-zero elements.</p><p>This is a NP-hard problem.</p><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><h3 id="Gabor-wavelet"><a href="#Gabor-wavelet" class="headerlink" title="Gabor wavelet"></a>Gabor wavelet</h3><ul><li>have a look of this.</li></ul><h2 id="Coherence"><a href="#Coherence" class="headerlink" title="Coherence"></a>Coherence</h2><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>$$<br>m(U)=\max_{i,j,i\neq j}|u_i^\top u_j|<br>$$</p><p>it measures the linear dependency for a dictionary</p><h3 id="Property"><a href="#Property" class="headerlink" title="Property"></a>Property</h3><ul><li>why a new atom $u$ added to orthogonal B, will lead to the coherence increasing at least $\frac{1}{\sqrt{D}}$</li></ul><h2 id="Reconstruction"><a href="#Reconstruction" class="headerlink" title="Reconstruction"></a>Reconstruction</h2><ul><li>what is the object of signal reconstruction? $X$ or $Z$? To reconstruct the original signal $X$? Or represent $X$ by $Z$? Find $X$ or find $Z$?</li><li>how to solve for the general dictionary?</li></ul><h3 id="Methods-1"><a href="#Methods-1" class="headerlink" title="Methods"></a>Methods</h3><h4 id="Matching-pursuit"><a href="#Matching-pursuit" class="headerlink" title="Matching pursuit"></a>Matching pursuit</h4><ul><li>procedure<ol><li>initialize: residual $r_0\leftarrow x$​ and approximation $\hat{x}_0=0$</li><li>repeat:<ol><li>find $j^\ast=\arg\max_j|\langle r_i, u_j\rangle|$</li><li>compute better approximation$\hat{x}<em>{i+1}\leftarrow \hat{x}<em>i +\langle r_i, u</em>{j^\ast} \rangle u</em>{j^\ast}$​ </li><li>update residual $r_{i+1}\leftarrow r_i - \langle r_i, u_{j^\ast}\rangle u_{j^\ast}$</li></ol></li></ol></li><li>Convergence: is the $\hat{x}_i\to x$ ?<ul><li>Yes, it is. We can prove that by proving $|r_i|_2^2\to 0$</li><li>we can prove that by proving $\frac{|r_{i+1}|_2^2}{|r_i|_2^2}\leq \gamma. \exists\gamma &lt; 1$ </li><li>the last condition can be satisfied when $u$ span $\mathbb{R}^n$</li></ul></li><li>Residual minimization<ul><li>matching pursuit greedily reduces the residual energy at every iteration.</li><li>it can be proved that minimize the residual equals to maximize the parameters with the condition of orthogonal.<ul><li>the orthogonal only aims at the current selected atom. The residual is orthogonal to this atom, but may not be orthogonal to other atoms. The basis atoms don’t need to be orthogonal to each other.</li></ul></li></ul></li></ul><h4 id="Convex-optimization"><a href="#Convex-optimization" class="headerlink" title="Convex optimization"></a>Convex optimization</h4><ul><li>try to find under which condition of U, can this two problem, 0-norm and 1-norm, be equivalent?</li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CN6 Generating function applications</title>
      <link href="/cn06/"/>
      <url>/cn06/</url>
      
        <content type="html"><![CDATA[<h1 id="Aims"><a href="#Aims" class="headerlink" title="Aims"></a>Aims</h1><ul><li>friendship paradox and sampling in networks</li><li>emergence of a giant connected component</li><li>molloy-reed criterion in random networks</li></ul><h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><ul><li>what is special about the generating functions $G_0$ and $G_1$ in <strong>sparse</strong> Erdos-Renyi networks?<ul><li>In sparse Erdos-Renyi networks,  $np$​ is a constant $\lambda$. $P(X=m)=\frac{\lambda^m e^{-\lambda}}{m!}$</li><li>what is $G_0$ and what is $G_1$<ul><li>$G_0$: the generating function of the degree of a node</li><li>$G_1$: the generating function of the degree of a neighbor of a node, not including the link degree 1 between them.</li></ul></li><li>Speciality: $G_0=G_1$</li></ul></li><li>In which case can we calculate the number of nodes at distance $l$ of a randomly chosen node $i$ as $\langle k\rangle ^l$ ?<ul><li>when the degree follows Poisson distribution.</li></ul></li><li>Under which conditions can we use generating functions to study connected components?<ul><li>we use $H_1$ to count the component size of a node in <strong>forward</strong> direction. We don’t count the node that we arrived from.</li></ul></li><li>what is the Molloy-Reed criterion?<ul><li>when the ratio of 2-nd raw moment and 1-st raw moment bigger than 2, the gcc will emerge </li></ul></li><li>what is the condition for the existence of a giant connected component in the $G(n,p)$ model?<ul><li>$np&gt;1$</li></ul></li><li>what is the condition for the existence of a giant connected component in the $G(n,m)$ model?<ul><li>$p = 2m/(n-1)/n$. So, $2m/(n-1)&gt;1$</li></ul></li><li>In an Erdos-Renyi network, what does the Molloy-Reed criterion imply for $G_0’(1)=\langle k\rangle$  and $G_1’(1)=\langle k_n\rangle-1$ <ul><li>$G_1’(1)&gt;1$ </li></ul></li></ul><h1 id="Keys"><a href="#Keys" class="headerlink" title="Keys"></a>Keys</h1><p>giant connected components, $G_0$, $G_1$, Molloy-Reed criterion, self-consistency condition</p><h1 id="Sparse-Erdos-Renyi-network-Poisson-Distribution-Degree"><a href="#Sparse-Erdos-Renyi-network-Poisson-Distribution-Degree" class="headerlink" title="Sparse Erdos-Renyi network: Poisson Distribution Degree"></a>Sparse Erdos-Renyi network: Poisson Distribution Degree</h1><p>Friendship paradox can be interpreted as a <strong>sampling bias</strong>.</p><p>We define $G_1(x)=\frac{G_0’(x)}{G_0’(1)}$ </p><p>In sparse Erdos-Renyi network,<br>$$<br>P(X=m)=\frac{\lambda^m e^{-\lambda}}{m!}<br>$$</p><p>$$<br>G_0(x)=\sum_{i=1} p(i)x^i=\sum_{i=1} \frac{(x\lambda)^i e^{-\lambda}}{i!}<br>$$</p><p>$$<br>=e^{-\lambda}\sum_{i=1} \frac{(x\lambda)^i }{i!}=e^{-\lambda}e^{x\lambda}<br>$$</p><p>$$<br>G_0’(x)=e^{-\lambda}\lambda e^{x\lambda}<br>$$</p><p>$$<br>G_1(x)=\frac{G_0’(x)}{G_0’(1)} = \frac{e^{x\lambda}}{e^\lambda}=G_0(x)<br>$$</p><p>$$<br>\langle k_n\rangle = G_1’(1)+1=G_0’(1)+1=\langle k\rangle + 1<br>$$</p><ul><li>$G_0$ and $G_1$ are identical.</li><li>if we don’t count the edge between the node and its neighbor, they have the same average degree.</li><li>All of the assumption is the degree follows <strong>Poisson Distribution</strong>.</li><li> the generating function $G_0$​​ contains all information about the random topology, which makes them particularly easy to study</li></ul><h1 id="Component-size"><a href="#Component-size" class="headerlink" title="Component size"></a>Component size</h1><h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><p>when does a <strong>giant connected component</strong> arise?</p><p>Exists giant connected component $\Leftrightarrow$​ The average component size $\langle s\rangle$​ diverges with $n\to\infty$</p><p>Speaking of something’s average, of course, we can use the generating function.</p><p>How to find the generating function describing $P(C=s)$ , the probability of a component with size $s$</p><p>Here, the definition of “component” involves “direction”. That is a node’s component doesn’t include its father node.</p><h2 id="Generating-Functions"><a href="#Generating-Functions" class="headerlink" title="Generating Functions"></a>Generating Functions</h2><h3 id="H-1-​"><a href="#H-1-​" class="headerlink" title="$H_1$​"></a>$H_1$​</h3><p>We define $H_1$ as the generating function of the component size that includes a node as some other node’s neighbor.</p><p>$H_1$​ satisfies: the sum of its children’s component size add 1, count itself,  is this node’s component size. Since its children also satisfy themselves as some node’s neighbor. Here, the neighbor is this node. It can also be calculated by $H_1$​. We have<br>$$<br>H_1(x)=xG_1(H_1(x))<br>$$</p><ul><li>Here, we use $G_1$ instead of $G_0$. Because we only count the node’s children, not including its father. The difference of $G_0$ and $G_1$ is <strong>direction</strong>. <ul><li>$G_0$ doesn’t take direction as a count. All the neighbors of  a node are counted.</li><li>$G_1$ indeed considers direction. Its father node won’t be counted, but only its children.</li></ul></li><li>This is also called <strong>self-consistency condition</strong>.</li></ul><h3 id="H-0"><a href="#H-0" class="headerlink" title="$H_0$"></a>$H_0$</h3><p>We define $H_0$ as the generating function of the component size of a node.</p><p>Based on $H_1$​, it is easy to calculate<br>$$<br>H_0=xG_0(H_1(x))<br>$$<br>Hence,<br>$$<br>\langle s\rangle = H_0’(1)<br>$$</p><h3 id="langle-s-rangle"><a href="#langle-s-rangle" class="headerlink" title="$\langle s\rangle$"></a>$\langle s\rangle$</h3><p>We cannot get the exact formula of $H_0$ and $H_1$​, but we can get the value of $\langle x\rangle$.<br>$$<br>\langle s\rangle = H_0’(1)=[G_0(H_1(x))+xG_0’(H_1(x))H_1’(x)]_{x=1}<br>$$</p><p>$$<br>=G_0(H_1(1))+G_0’(H_1(1))H_1’(1)<br>$$</p><p>It is good to know all the generating function is 1 at $x=1$</p><p>So,<br>$$<br>\langle s\rangle =G_0(1)+G_0’(1)H_1’(1)<br>$$<br>We only need to calculate $H_1’(1)$​<br>$$<br>H_1’(x)=G_1(H_1(x))+xG_1’(H_1(x))H_1’(x)<br>$$</p><p>$$<br>H_1’(1)=G_1(H_1(1))+G_1’(H_1(1))H_1’(1) = 1+G_1’(1)H_1’(1)<br>$$</p><p>We can get<br>$$<br>H_1’(1)=\frac{1}{1-G_1’(1)}<br>$$<br>Therefore,<br>$$<br>\langle s\rangle = 1+\frac{G_0’(1)}{1-G_1’(1)}=\frac{\langle k\rangle}{2-\langle k_n\rangle} = \frac{\langle k\rangle}{2-\frac{\langle k^2\rangle}{\langle k\rangle }}<br>$$</p><ul><li>$G_0’(1)$: the average degree $\langle k\rangle$</li><li>$G_0’(1)$: the mean neighbor degree $\langle k_n\rangle -1$</li></ul><h4 id="Emergency-of-the-giant-connected-component"><a href="#Emergency-of-the-giant-connected-component" class="headerlink" title="Emergency of the giant connected component"></a>Emergency of the giant connected component</h4><ul><li><p>$\langle k\rangle \to\infty$, very dense network</p></li><li><p>$\langle k_n\rangle - 1\to 1\Rightarrow \langle k_n\rangle \to 2$, sparse</p><ul><li><p>In sparse Erdos-Renyi model, we have $np\to\infty$ as a fixed number.<br>$$<br>\langle k_n\rangle = \frac{\langle k^2\rangle}{\langle k\rangle}=\frac{np(1+np)}{np}=1+np<br>$$<br>when $np&gt;1$, it has a giant connected component.</p><p>The interpretation: each node needs to be connected-on-average- to at least one other node.</p></li><li><p>Question??? If $np&gt;1$, according to this calculation, the average component size will be less than 0. How to explain???? The definition of component is wired here.</p></li></ul></li></ul><h3 id="Molloy-Reed-Criterion"><a href="#Molloy-Reed-Criterion" class="headerlink" title="Molloy-Reed Criterion"></a>Molloy-Reed Criterion</h3><p>There must be a gcc for<br>$$<br>\frac{\langle k^2\rangle}{\langle k\rangle}&gt;2<br>$$</p><h3 id="Phase-transition-phenomena"><a href="#Phase-transition-phenomena" class="headerlink" title="Phase transition phenomena"></a>Phase transition phenomena</h3><p>At some point, the small change of the parameter will cause an abrupt change of some system’s properties.</p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Complex System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CIL7 Generative Models</title>
      <link href="/cil-7gm/"/>
      <url>/cil-7gm/</url>
      
        <content type="html"><![CDATA[<h1 id="Generative-Models"><a href="#Generative-Models" class="headerlink" title="Generative Models"></a>Generative Models</h1><ul><li>generate what?<ul><li>according to given data, generate new data like them.</li></ul></li><li>methods?<ul><li>variational autoencoders</li><li>generative adversarial network</li></ul></li></ul><h2 id="Deep-Generative-Models"><a href="#Deep-Generative-Models" class="headerlink" title="Deep Generative Models"></a>Deep Generative Models</h2><ul><li>what is deep generative model?<ul><li>Deep means “deep neural network”. The DNN is used to learn a distribution which is as similar as possible to the true data distribution.</li><li>The problem setting is: we want to learn any kind of data distribution using <strong>unsupervised</strong> learning.</li></ul></li><li>what is it relationship with VAE?<ul><li>VAE is one of the most commonly used and efficient approaches of Deep Generative models. </li><li>GAN is another typical example. </li></ul></li></ul><h1 id="VAE-Variational-autoencoders"><a href="#VAE-Variational-autoencoders" class="headerlink" title="VAE: Variational autoencoders"></a>VAE: Variational autoencoders</h1><ul><li><p>what does variational mean?</p><ul><li>alter, or explore variations on <em>data you already have</em>, and not just in a random way either, but in a desired, <em>specific</em> direction. </li><li>don’t expect the exactly same point as the input, but <strong>randomly sample from the latent space</strong>, or generate variations on an input image, from a <strong>continuous</strong> latent space.</li><li>if the latent space is discrete, and I sample a variation from the gaps between points, the decoder will have no idea of this data point. The decoder has no idea how to deal with the region of the latent space.</li></ul></li><li><p>how does it work?</p><ul><li>Design a <strong>continuous</strong>, allowing easily random sampling and interpolating latent space.</li></ul></li><li><p>this is a <strong>latent variable model</strong> ? <a href="https://zhuanlan.zhihu.com/p/21741426">zhihu</a></p><ul><li><p>Speaking of learning latent variable, we use EM algorithm before. There, the latent variable $h$ is a discrete variable, has limited possible numbers. (Considering the clustering problem, usually $h$ denotes whether the variable $x_i$ belongs to the class $c_j$, there are totally $N\times M$  values.) But here, the <strong>key assumption</strong> is that $h$ is <strong>continuous</strong>.  </p></li><li><p>Recap of the mixture clustering problem, there we include latent variable and write the log-likelihood of x according to the latent variable as:<br>$$<br>\begin{align}<br>\log p(x;\theta) &amp; = \log[\sum_{j=1}^K\pi_j p(x;\theta_j)] = \log[\sum_{j=1}^K q_j\frac{\pi_j p(x;\theta_j)}{q_j}] \<br>&amp; \geq \sum_{j=1}^K q_j[\log p(x;\theta_j)+\log\pi_j - \log q_j]\<br>\end{align}<br>$$</p></li><li><p>Here, for continuous latent variable, it should be written as:<br>  $$<br>  \log p(x;\theta)=\log \int p(x,h)\mathrm{d}h = \log \int q(h|x)\frac{p(x,h)}{q(h|x)}\mathrm{d}h<br>  $$<br>  we can follow the former method and rewrite it go get a lower variational bound:<br>  $$<br>  \geq \int q(h|x)[\log p(x|h)p(h)-\log q(h|x)]\mathrm{d}h = B(q,x)<br>  $$<br>  Then, we want to use some simple distribution family to approximate $q(h|x)$, which maximizes $B(q,x)$</p></li><li><p>we can also rewrite $B(q,x)$​ as<br>$$<br>B(q,x)=-D[q(h|x)||p(h)]+\int q(h|x)\log p(x|h)\mathrm{d}h<br>$$</p><ul><li>the first item is KL divergence</li><li>the second item can be viewed as reconstruction error.</li><li>Usually, the prior $p(h)$ is very simple to calculate directly.</li><li>Now, our goal is to find $q(h|x)$ and $p(x|h)$, which maximize the $B(q,x)$</li></ul></li><li><p>What VAE does is not making assumption on $q(h|x)$ but do the variable replacement. Using $f(x,\epsilon)\sim q(h|x)$</p><ul><li>the advantage is that if the variance of $q(\cdot)$ could be large, but we will use its gradient to rectify itself. The error may become larger. But if we use  $\epsilon$ which comes from a stable distribution, the variance of the estimator will reduce a lot.</li></ul></li></ul></li><li><p><a href="https://towardsdatascience.com/deep-generative-models-25ab2821afd3">antoher link</a></p></li></ul><h2 id="Compare-to-linear-autoencoder"><a href="#Compare-to-linear-autoencoder" class="headerlink" title="Compare to linear autoencoder"></a>Compare to linear autoencoder</h2><ul><li>The basic idea is the same as linear autoencoder: representing our data into low-dimensional latent variables, and reconstruct from it to minimize the reconstruction error.</li><li>we can use DNN to realize non-linear.</li><li>Different: the model latent variables are soft regions, i.e. continuous areas, instead of points.</li><li>KL divergence enforces us to use Gaussian prior. Without it, the model would learn $\sigma\to 0$, falling to a normal autoencoder.</li></ul><h2 id="Compare-to-autoencoder-network"><a href="#Compare-to-autoencoder-network" class="headerlink" title="Compare to autoencoder network"></a>Compare to autoencoder network</h2><p><a href="https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf">medium link</a></p><p>Autoencoder:</p><ul><li>encoder: preserve as much as information as possible in limited encoding</li><li>decoder: take the encoding and properly reconstruct it into a “full image”.</li></ul><p>Problem: the fundamental problem with autoencoders is that the latent space may <strong>not be continuous</strong>, or allow easy interpolation. </p><p>Classic autoencoder learns a deterministic function that compresses the data while VAE learn the parameters of a probability distribution representing the data. We can sample from the distribution and generate new input data samples. It is a <strong>generative</strong> model.</p><p>instead of outputing an encoding vector of size n, it outputs two vectors of size n: a vector of means $\mu$ and another vector of standard deviations $\sigma$</p><p>That means, even for the same input, the encoded latent variables may vary a little due to the randomness.</p><p>By varying the encoding of one sample, a latent point is developing into smooth latent spaces on a local scale, that is, for similar samples.</p><h2 id="ELBO"><a href="#ELBO" class="headerlink" title="ELBO"></a>ELBO</h2><p>Evidence Lower BOund.<br>$$<br>\text{ELBO}(\phi,\theta)=\mathbb{E}_{q_\phi} [\log p_\theta(x|z)+\log p(z) - \log q_\phi(z|x)<br>$$</p><p>$$<br>= \mathbb{E}_{q_\phi}[\log p_\theta (x|z)]-KL[q_\phi (z|x)\parallel p(z)]<br>$$</p><ul><li>what is the reconstruction error?<ul><li>The first item reflects the reconstruction error. To maximize ELBO, we want to maximize the first item, which means maximizing the likelihood of the generated data $x_i$.</li><li>This is related to reconstruction quality.</li></ul></li><li>To minimize the KL item, encouraging the posterior distribution to be close to the prior distribution on the latent variable. It works as a regularizer.</li><li>Combining these two objectives, we can achieve the clusters and variation ability.</li></ul><h3 id="KL-divergence"><a href="#KL-divergence" class="headerlink" title="KL divergence"></a>KL divergence</h3><ul><li>what is the function of KL divergence here?<ul><li>make encodings, <em>all</em> of which are as close as possible to each other while still being distinct,</li><li>allowing smooth interpolation, because the lack of holes, </li><li>and enabling the construction of <em>new</em> samples.</li></ul></li></ul><p>The KL divergence between two probability distributions simply measures how much they <em>diverge</em> from each other. Minimizing the KL divergence here means optimizing the probability distribution parameters $\mu$ and $\sigma$) to closely resemble that of the target distribution</p><p>For VAEs, the KL loss is equivalent to the <em>sum</em> of all the KL divergences between the <em>component</em> $X_i\sim \mathcal{N}(\mu, \sigma_i^2)$ in $X$, and the standard normal. It’s minimized when $\mu_i=0,\sigma_i=1$.</p><p>Intuitively, this loss encourages the encoder to distribute all encodings, for all types of inputs, e.g. all MNIST numbers, <strong>evenly around the center of the latent space</strong>. If it tries to “cheat” by clustering them apart into specific regions, away from the origin, it will be penalized.</p><p>A good thing of VAE is that it can learn generative model and inference model at the same time.</p><h2 id="Reparametrization-Trick"><a href="#Reparametrization-Trick" class="headerlink" title="Reparametrization Trick"></a>Reparametrization Trick</h2><p>Replace $z=g_\phi (\epsilon, x)$ , so that we can do Monte Carol sampling and differentiate  $z$ and backpropagation can be used to tune the parameters in the model.</p><p>Using simple $\epsilon, \epsilon\sim f(x,\epsilon)$  to replace $q(h|x)$ .</p><p>Gradient of expectation $\to$ Expectation of gradient $\to$ average of stochastic gradient.</p><h2 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h2><p>The encoder and decoder networks are trained to solve the optimization problem<br>$$<br>\theta^*, \phi^* = \arg\max_{\theta, \phi} L(x^{(i)}, \theta, \phi)<br>$$</p><ul><li>the encoder network (inference step)<ul><li>Maximize $B(q|x)$ with respect to $q(h|x)$, given $p(x|h)$</li><li>optimize the regularizer term, by making the approximate posterior distribution $q_\phi$ as close to the latent variable prior.</li><li>sample a latent sample $z\sim q_\phi$ and pass it to the decoder network.</li></ul></li><li>the decoder network (genera)<ul><li>Maximize $B(q,x)$ with respect to $p(x|h)$ given $q(h|x)$</li><li>produces samples $\hat{x}$ that maximize the reconstruction quality with respect to the original input.</li></ul></li><li>Both terms of ELBO are differentiable, we can use a training method like SGD to train the VAE model end-to-end.</li></ul><h1 id="GAN-Generative-Adversarial-Network"><a href="#GAN-Generative-Adversarial-Network" class="headerlink" title="GAN: Generative Adversarial Network"></a>GAN: Generative Adversarial Network</h1><p>Two components: a generator and a discriminator.<br>$$<br>\min_G\max_D V(D,G)=\mathbb{E}_x [\log D(x)] + \mathbb{E}_z[\log (1-D(G(z)))]<br>$$</p><ul><li>generator: given the labels, generate new false data point and mix them with the real data, try to use a distribution that make the “false” data looks like the real data as large as possible. <ul><li><strong>Minimize</strong> the likelihood of the data: <ul><li>when the data is from the real data set, make the likelihood of the data be real as low as possible: </li><li>when the data is from the fake dataset, make the likelihood of the data be fake as low as possible</li></ul></li></ul></li><li>discriminator: given the data points, try to find the real data and false data as precise as possible. In other words, try to label data as their real label.<ul><li><strong>Maximize</strong> the likelihood.<ul><li>when the data is real, try to discriminate is as real</li><li>when the data is fake, try to discriminate is as fake.</li></ul></li></ul></li></ul><p>This is a saddle-point problem. The objective is opposite in two components.<br>$$<br>\theta^*:=\arg\min_{\theta\in\Theta}{\sup_{\phi\in\Phi}l(\theta,\phi)}<br>$$</p><h2 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h2><p>SGD as a heuristic:<br>$$<br>\theta^{t+1}=\theta^t - \eta\nabla_\theta l(\theta^t, \phi^t)<br>$$</p><p>$$<br>\phi^{t+1} = \phi^t + \eta\nabla_\theta l(\theta^{t+1},\phi^t)<br>$$</p><h2 id="Practical-Considerations"><a href="#Practical-Considerations" class="headerlink" title="Practical Considerations"></a>Practical Considerations</h2><p>Need to balance generator and discriminator: may train some at different speeds.</p><h1 id="VAE-VS-GAN"><a href="#VAE-VS-GAN" class="headerlink" title="VAE VS GAN"></a>VAE VS GAN</h1><h2 id="Quality"><a href="#Quality" class="headerlink" title="Quality"></a>Quality</h2><ul><li>VAE: more blurry<ul><li>caused by pixel-wise factorization and local loss</li><li>high-frequency details are poorly correlated.</li></ul></li><li>GAN: sharper</li></ul><h2 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h2><ul><li>VAE: somewhat easier to train</li><li>GAN: very hard to train</li></ul><h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h2><ul><li>GAN: learn an <strong>implicit</strong> density, can only be used for generating</li><li>VAE: learn an <strong>explicit</strong> density, can generate and encode.</li></ul><h1 id="Auto-regressive-model"><a href="#Auto-regressive-model" class="headerlink" title="Auto-regressive model"></a>Auto-regressive model</h1><p>Generate output one variable at a time.<br>$$<br>p(x_1,\cdots, x_m)=\prod_{t=1}^m p(x_t|x_{1:t-1})<br>$$</p><h2 id="Pixel-CNN"><a href="#Pixel-CNN" class="headerlink" title="Pixel-CNN"></a>Pixel-CNN</h2><p>CNN can only use information about pixels above and to the left of the current pixel</p><p>can be realized by masking a filter.</p><p>Every time a pixel is predicted, it is fed back to the network to predict the next pixel</p><p>Slow process.</p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CIL6 Neural Network</title>
      <link href="/cil-6cnn/"/>
      <url>/cil-6cnn/</url>
      
        <content type="html"><![CDATA[<h1 id="Composition"><a href="#Composition" class="headerlink" title="Composition"></a>Composition</h1><ul><li><p>layer</p><ul><li>neurons/units<ul><li>input</li><li>weight</li><li>activation function</li><li>output $x^{(l)}=\sigma^{(l)}(W^{(l)}x^{(l-1)})$​</li></ul></li></ul></li><li><p>network depth: the feature hierarchy</p></li><li><p>layer width: the number of features</p></li></ul><h2 id="Activation-function"><a href="#Activation-function" class="headerlink" title="Activation function"></a>Activation function</h2><h3 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h3><p>change the linearity to non-linearity</p><h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><p>change the linearity in some way</p><p>simple derivative</p><h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1><h2 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h2><p>Define the training objective, can be chosen by the output type. $y^*$  is the target output, $y$ is the predicted output</p><ul><li>$y^*$​​ is categorical: <strong>cross-entropy loss</strong>:<br>$$<br>l(y^*,y)=-y^* \log y - (1-y^*)\log(1-y)<br>$$</li><li>$y^*$ is numerical: <strong>squared loss</strong>:<br>$$<br>l(y^*,y)=\frac{1}{2}(y^*-y)^2<br>$$</li></ul><h3 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h3><p>to penalize the parameters</p><ul><li>L2 regularization: $L_{\lambda}(X;\theta)=L(X;\theta)+\frac{\lambda}{2}|\theta|_2^2$</li></ul><h2 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h2><h3 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h3><p>different from past SGD, here we also include a step size  $\eta$, because the steepest / original descent is too expensive for large data sets. </p><p>In the past, it should be $\theta\leftarrow (1-\lambda)\theta - \nabla_\theta l(y_t^*, y(x_t, \theta))$</p><p>But with $\eta$​​, it becomes $\theta\leftarrow (1-\eta\lambda)\theta - \eta\nabla_\theta l(y_t^*, y(x_t, \theta))$​​</p><h3 id="Chain-rule"><a href="#Chain-rule" class="headerlink" title="Chain rule"></a>Chain rule</h3><p>$$<br>\frac{\partial x^{(l)}}{\partial x^{(l-n)}} = J^{(l)}\cdot  J^{(l-1)}\cdots  J^{(l-n+1)}\<br>\nabla_{x^{(l)}}^T l = \nabla_y^T l\cdot J^{(L)}\cdots J^{(l+1)}<br>$$</p><h3 id="Weights-influence"><a href="#Weights-influence" class="headerlink" title="Weights influence"></a>Weights influence</h3><p>$$<br>\frac{\partial x_i^{(l)}}{\partial w_{ij}^{(l)}} = \sigma’([w_i^l]^Tx^{(l-1)})x_j^{(l-1)}<br>$$</p><p>is composed of two parts:</p><ul><li>sensitivity</li><li>activation</li></ul><h1 id="Comparison-to-Logistics-Regression"><a href="#Comparison-to-Logistics-Regression" class="headerlink" title="Comparison to Logistics Regression"></a>Comparison to Logistics Regression</h1><p>Logistic Regression:</p><ul><li>linear</li></ul><p>MLP: multi-layer perceptron:</p><ul><li><p>learn intermediate feature representation</p></li><li><p>include non-linearity</p></li></ul><h1 id="Convolutional-Neural-Network"><a href="#Convolutional-Neural-Network" class="headerlink" title="Convolutional Neural Network"></a>Convolutional Neural Network</h1><h2 id="Receptive-field"><a href="#Receptive-field" class="headerlink" title="Receptive field"></a>Receptive field</h2><p>The creative point of convolutional neural network is how it chooses and organizes the input $x^{(l)}$</p><p>This variant in some way complicates the neural network</p><h2 id="Weight-sharing"><a href="#Weight-sharing" class="headerlink" title="Weight sharing"></a>Weight sharing</h2><p>This simplifies the neural network. Neurons share the same weights.</p><p>Weights define a <strong>filter mask</strong>. A filter mask corresponds to a vector of $y$, in CNN, which is called channel.</p><h2 id="Building-blocks"><a href="#Building-blocks" class="headerlink" title="Building blocks"></a>Building blocks</h2><ul><li>convolutional layer</li><li>pooling layer</li><li>fully-connected layer</li></ul><h3 id="Convolutional-layer"><a href="#Convolutional-layer" class="headerlink" title="Convolutional layer"></a>Convolutional layer</h3><p><a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">from Medium</a> The objective of the Convolution Operation is to <strong>extract the high-level features</strong> such as edges, from the input image. ConvNets need not be limited to only one Convolutional Layer. Conventionally,</p><ul><li>the first ConvLayer is  responsible for capturing the Low-Level features such as edges, color,  gradient orientation, etc. </li><li>With added layers, the architecture adapts to the High-Level features as well, giving us a network which has the  wholesome understanding of images in the dataset, similar to how we would.</li></ul><h4 id="Formula"><a href="#Formula" class="headerlink" title="Formula"></a>Formula</h4><p>$$<br>F_{n,m}(x; w)=\sigma(b+\sum_{k=-2}^2\sum_{l=-2}^2w_{k,l}\cdot x_{n+k, m+l})<br>$$</p><h3 id="Pooling-layer"><a href="#Pooling-layer" class="headerlink" title="Pooling layer"></a>Pooling layer</h3><p> the Pooling layer is responsible </p><ul><li>for reducing the spatial size of the Convolved Feature</li><li>to <strong>decrease the computational power required to process the data</strong> through dimensionality reduction.</li><li>useful for <strong>extracting dominant features</strong> which are rotational and positional invariant, thus maintaining the process of effectively training of the model.</li></ul><h4 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h4><ul><li>max pooling</li><li>average pooling</li></ul><h3 id="Fully-connected-layer"><a href="#Fully-connected-layer" class="headerlink" title="Fully-connected layer"></a>Fully-connected layer</h3><p>Fully-Connected layer is a (usually) cheap way </p><ul><li>of learning <strong>non-linear</strong> combinations of the high-level features as represented by the output of the convolutional layer. </li><li>it combines all the output from the previous layer. Different from the convolutional layer, which only uses part of the output from the previous layer.</li></ul><h1 id="Variants"><a href="#Variants" class="headerlink" title="Variants"></a>Variants</h1><h2 id="Deeper-Network"><a href="#Deeper-Network" class="headerlink" title="Deeper Network"></a>Deeper Network</h2><p>the number of layers grows from 10+ to 100+.</p><p>not only use the output from the previous layer but also the input of the previous layer</p><h2 id="Semantic-Segmentation"><a href="#Semantic-Segmentation" class="headerlink" title="Semantic Segmentation"></a>Semantic Segmentation</h2><p>add de-convolutional layers.</p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CN5 Generating function</title>
      <link href="/cn05/"/>
      <url>/cn05/</url>
      
        <content type="html"><![CDATA[<h1 id="Aims"><a href="#Aims" class="headerlink" title="Aims"></a>Aims</h1><ul><li>make statements about the properties of a network if we only know the degree distribution</li><li>properties of generating function</li><li>analyze the friendship paradox</li></ul><h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><ul><li>what is a generating function?<ul><li>a function to encode a sequence of integer probability.</li></ul></li><li>what does the $m$-th power of a generating function $G_0(x)$​ generate?<ul><li><p>$$<br>\langle k^m\rangle<br>$$</p></li><li><p>derivate and multiplied by $x$ and set $x$  as 1.</p></li></ul></li><li>How is the second raw moment of a distribution related to its variance?<ul><li>variance = second RM - first RM</li></ul></li><li>How is the first raw moment of a distribution related to its mean?<ul><li>equal??? Exactly.</li></ul></li><li>What does the composition $G_1(G_0(x)$ generate? </li><li>what is the friendship paradox?<ul><li>the average friends number of your friends is larger than the average friends number of yours.</li></ul></li><li>what practical applications of the friendship paradox can you think of?</li></ul><h1 id="Generating-functions"><a href="#Generating-functions" class="headerlink" title="Generating functions"></a>Generating functions</h1><p>it provide a general tool for us to make <strong>analytical</strong> statements about the <strong>expected properties</strong> of networks generated from a <strong>statistical ensemble</strong> with <strong>arbitrary</strong> degree distributions.</p><h2 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h2><ul><li>it is maybe the most important methodology in the <strong>macroscopic</strong> study of complex networks</li><li>it explains why <strong>degree distributions</strong> are such an important aggregate characteristic of complex networks.</li><li>it is helpful to understand how widely known results about networks are derived</li><li>it will help us  to understand <strong>the limitation of the ensemble perspective</strong>.</li><li>It is a fancy way to <strong>encode a sequence of numbers</strong>. </li></ul><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>Given an integer probability sequence $(p(1), p(2),\cdots, p(n),\cdots)$​​​, where $\sum_i p(i)=1$​​​,<br>$$<br>G_0(x)=\sum_{i=1} p(i)x^i, x\in[0,1]<br>$$</p><ul><li>the probability: the object must be an integer, <ul><li>could be 0, </li><li>could be infinite.</li></ul></li><li>$x$ must in the range from 0 to 1.</li></ul><h2 id="Calculation"><a href="#Calculation" class="headerlink" title="Calculation"></a>Calculation</h2><h3 id="Derivation"><a href="#Derivation" class="headerlink" title="Derivation"></a>Derivation</h3><h4 id="The-probability"><a href="#The-probability" class="headerlink" title="The probability"></a>The probability</h4><p>$P(k)$ is the parameter of $x^k$​​, so we have<br>$$<br>[\frac{1}{k!}\frac{\mathrm{d}^k}{\mathrm{d}x^k}G_0(x)]_{x=0}=P(k)<br>$$</p><ul><li>derivate by $k$ times, to eliminate the items with power less than $k$​.</li><li>set $x$ as 0, to eliminate the items with power larger than $k$.</li><li>divided by $k!$ to eliminate the power influence on the parameter.</li></ul><h4 id="The-average-degree"><a href="#The-average-degree" class="headerlink" title="The average degree"></a>The average degree</h4><p>$$<br>G_0’(1)=[ \sum_{k=0}^\infty k P(k) x^{k-1} ]_{x=1}<br>$$</p><p>$$<br>= \sum_{k=0} kP(k)=\langle k \rangle<br>$$</p><ul><li>take the <strong>first</strong> derivative, to pull down the integer.</li><li>set $x$​ as 1, to eliminate the $x$​’s influence.</li></ul><h4 id="m-th-raw-moment-of-P-k-​"><a href="#m-th-raw-moment-of-P-k-​" class="headerlink" title="$m$-th raw moment of $P(k)$​"></a>$m$-th raw moment of $P(k)$​</h4><p>$$<br>[(x\frac{\mathrm{d}}{\mathrm{d}x})^m G_0(x)]<em>{x=1}= \sum</em>{k=0}^\infty k^m P(k)=\langle k^m\rangle<br>$$</p><ul><li>the $k$ is on the index, so take derivative to pull it as a multiplier. </li><li>multiplied by $x$​ to make up the “$k$”​. Actually, only the first $k-1$​ times matter. The last $x$​ is just for the form unified.</li><li>set $x$ as 1, to keep $P(k)$ while eliminating the $x$’s influence.</li></ul><h3 id="Multiplication"><a href="#Multiplication" class="headerlink" title="Multiplication"></a>Multiplication</h3><p>Suppose $Z=X+Y$,<br>$$<br>G_Z(x)=G_{X+Y}(x)=G_X(x)G_Y(x)<br>$$<br>the distribution of the sum of two random independent variable $X$ and $Y$.</p><p>From the multiplication, we have many variants:</p><h4 id="A-“new”-variable-X"><a href="#A-“new”-variable-X" class="headerlink" title="A “new” variable $X$"></a>A “new” variable $X$</h4><p>$xG_0(x)$ generates distribution of $P(X=k-1)=P(X+1=k)$.</p><p>We can understand by </p><ul><li>we take $G_Y(x)=0+x+0\cdot x^2+\cdots$ . It corresponds to a random variable $Y$, which is always $1$, $P(Y=1)=1$ </li><li>So $xG_0(x)=G_X(x)G_Y(x)$​, means the sum of one variable follows $P_X(x)$ and the other one, which is always 1. </li></ul><p>$\frac{1}{x}G_0(x)$ generates distribution of $P(X=k+1)=P(X-1=k)$</p><p>Similarly, it can be understood by add a random variable, which is always be -1. cause $x^{-1}=\frac{1}{x}$ </p><h4 id="Power"><a href="#Power" class="headerlink" title="Power"></a>Power</h4><p>This is a variant of multiplication.</p><p>m-th power $[G_0(x)]^m$  generates distribution for the <strong>sum</strong> of $m$ independent realizations of random variable $X$, given the distribution of $X$​.</p><p>e.g.<br>$$<br>[G_0(x)]^2=\sum_{i+j=0}^\infty P(i)P(j)x^{i+j}<br>$$</p><p>$$<br>[G_0(x)]^m=\sum_{k_1+k_2+\cdots + k_m=0}^\infty P(k_1)P(k_2)\cdots P(k_m)x^{k_1+k_2+\cdots k_m}<br>$$</p><h3 id="Composition"><a href="#Composition" class="headerlink" title="Composition"></a>Composition</h3><p>$G_1(G_0(x))$​ generates the sum of  a random number  $n_i$​ of variable $X$<br>$$<br>G_1(G_0(x))=\sum_{k=0}P_1(k)[G_0(x)]^k<br>$$</p><ul><li> a random number $n_i$ follows the distribution given by $G_1(x)$</li><li>the variable $X$ follows the distribution given by $G_0(x)$</li></ul><p>Example: we have two dice, one with six sides, and the second one with eight sides.</p><ul><li>We throw the 6-one to decide how many times we throws the 8-one.</li><li>we sum the number of the 8-one.</li><li>we get the distribution of this sum.</li></ul><h2 id="“0”-and-“1”"><a href="#“0”-and-“1”" class="headerlink" title="“0” and “1”"></a>“0” and “1”</h2><ul><li><p>$$<br>G_0(1)=\sum_{k=0}P(k)\cdot 1 = 1<br>$$</p></li><li><p>$$<br>G_0(0)=\sum_{i=1} p(i)0^i=0<br>$$</p></li></ul><h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h2><h3 id="Networks"><a href="#Networks" class="headerlink" title="Networks"></a>Networks</h3><p>$G_0(x)$ generates the <strong>degree distribution</strong>.</p><h1 id="Friendship-paradox"><a href="#Friendship-paradox" class="headerlink" title="Friendship paradox"></a>Friendship paradox</h1><p>Your friends have, on average, more friends than you.</p><p>Mathematically, $\langle k_n\rangle&gt;\langle k\rangle$</p><ul><li><p>$\langle k\rangle$​ can be achieved by $G_0(x)$​, which generates the given degree distribution. $\langle k\rangle=\frac{1}{N}\sum_{i=1}^N k_i$​</p></li><li><p>$\langle k_n\rangle$​ means the average number of node’s neighbors degree. Mathematically, $\langle k_n\rangle=\frac{1}{N}\sum_{i=1}^N\bar{k}_i$​ </p><ul><li>where $\bar{k}_i$​​​​ means how many neighbors on average, does node $i$​​​​’s neighbors have. Mathematically, $\bar{k}<em>i=\frac{1}{k_i} \sum</em>{j\in I_i} d_j$​​​​<ul><li> $I_i$​​​ denotes the set of node $i$​​​’s neighbor.</li></ul></li></ul></li><li><p>Trick: if we can know the degree distribution of a node’s neighbor from the original node distribution, we will solve this problem. That is the probability $P_1(X=k)$  means a neighbor of a node has degree $k$.</p></li></ul><h2 id="The-degree-distribution-of-a-node’s-neighbor"><a href="#The-degree-distribution-of-a-node’s-neighbor" class="headerlink" title="The degree distribution of a node’s neighbor"></a>The degree distribution of a node’s neighbor</h2><p>We define $P_1(X=k)$ as above. This probability means I randomly select a node’s neighbor, the probability of its degree is $k$. </p><ul><li><p>If a node has degree $k$​, it has $k$​ times to be others’ neighbor. So,  $P_1(X=k)\sim k P_0(k)$​. </p></li><li><p>we <strong>normalize</strong> by the sum of $P_1(X=k)$ over $k$​. It is<br>$$<br>\sum_k P_1(k)=\sum kP_0(k)=\langle k\rangle<br>$$</p></li><li><p>So, we get<br>$$<br>P_1(X=k)= \frac{k P_0(k)}{\langle k\rangle}<br>$$</p></li><li><p>We can define $G_1(x)$​ by $P_1(X=k)$​, not including the edge linking these two nodes.<br>$$<br>G_1(x)=\frac{1}{x}\sum_{i=1}P_1(i)x^i=\frac{G_0’(x)}{\langle k\rangle}<br>$$</p></li><li><p>The average degree<br>$$<br>\langle k_n\rangle = 1+G_1’(1)=1+\frac{G_0’’(1)}{G_0’(1)}<br>$$</p><p>$$<br>=\sum_{i=1}iP_1(i)=\sum_{i=1}i^2\frac{P_0(i)}{\langle k\rangle}=\frac{\langle k^2\rangle}{\langle k\rangle}<br>$$</p></li><li><p>The key is the <strong>variance</strong> of the degree sequence!!!</p></li></ul><h2 id="Variant"><a href="#Variant" class="headerlink" title="Variant"></a>Variant</h2><p>Also, we can define $P_2(X=k)=P_1(X=k+1)$. The probability of a degree of a node’s neighbor</p><p>According to the calculation property of generating function, it is easy to get</p><ul><li>$G_2(x)=xG_1(x)=\frac{xG_0’(x)}{\langle k\rangle}$</li></ul><p>Besides, we can define $G_0(G_1(x)$ : the distribution of the number of <strong>second-neighbor</strong>.</p><h2 id="Applications-1"><a href="#Applications-1" class="headerlink" title="Applications"></a>Applications</h2><ul><li>vaccination strategy: Instead of sampling random individuals, we ask them to name a random friend and then offer this friend to receive a vaccination. This simple strategy has a larger impact than the vaccination of a random sample of the population.</li><li>explore topology. Study from the friends to get <strong>upper limit</strong>.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Complex System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CN4 Small-world networks</title>
      <link href="/cn04/"/>
      <url>/cn04/</url>
      
        <content type="html"><![CDATA[<h1 id="Aims"><a href="#Aims" class="headerlink" title="Aims"></a>Aims</h1><ul><li>learn what is the small-world network: small diameter and large clustering coefficient.</li><li>learn how to generate such a network.</li></ul><h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><ul><li><p>show that the diameter of Erdos-Renyi networks scales logarithmically with the network size.</p><ul><li>see below.</li></ul></li><li><p>what is the expected clustering coefficient for $G(n,p)$ microstates?</p><ul><li>$p$</li></ul></li><li><p>what clustering coefficient do you expect in the limit of infinite, sparse random networks?</p><ul><li>0</li></ul></li><li><p>what degree assortativity $r$ do you expect for $G(n,p)$ microstates?</p><ul><li>0</li></ul></li><li><p>describe the construction mechanism of a Watts-Strogatz network.</p><ul><li>build a regular lattice m networks first</li><li> (<strong>no</strong>) for each node, randomly choose $p$ portion edges and rewire them to randomly selected other neighbours.</li><li>for each edge, rewire the source of it with the probability $p$ to a random node.</li></ul></li><li><p>show that the clustering coefficient in a ring lattice where s nearest neighbors are connected is $C=\frac{3s-3}{4s-2}$  </p><ul><li>see below</li></ul></li><li><p>which links represent weak ties in a Watts-Strogatz network?</p><ul><li>the rewired ties to “far” nodes.</li></ul></li><li><p>write down an algorithmic formulation of the Molloy-Reed model, generating networks with a fixed degree distribution.</p></li><li><p>Under what circumstances are random networks with a fixed degree sequence better “null models” than the Erdos-Renyi model?</p><ul><li>see below</li></ul></li></ul><h1 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h1><ul><li>Erdos-Renyi network</li></ul><h1 id="Erdos-Renyi-Network"><a href="#Erdos-Renyi-Network" class="headerlink" title="Erdos-Renyi Network"></a>Erdos-Renyi Network</h1><p>The expected statistical index of ER model. </p><p>We have already know, </p><ul><li>the number of nodes $n$,</li><li>the number of edges $\frac{n^2p}{2}$ (or others) or m</li><li>the mean degree $np$</li><li>the variance of edges $np(1-p)$ </li></ul><h2 id="Clustering-coefficient"><a href="#Clustering-coefficient" class="headerlink" title="Clustering coefficient"></a>Clustering coefficient</h2><p>In $G(n,p)$​ model, since links are independent,<br>$$<br>P[(j,k)\in E|(i,j)\in E,(i,j)\in E]=P[(j,k)\in E]=p=C<br>$$</p><h2 id="Diameter"><a href="#Diameter" class="headerlink" title="Diameter"></a>Diameter</h2><p>The idea is starting from an arbitrary node, how many expected steps will this node reach other nodes?</p><p>Suppose each node has $k$ neighbors, in $l$ steps, it will approximately reach $k+k^2+\cdots k^l$ nodes, totally $\frac{k^{l+1}-1}{k-1}\sim k^l$  nodes (including himself). When $k^l$  equals to $N$ , the total number of nodes, $l\sim\frac{\log N}{\log k}$ </p><h1 id="Small-world-network"><a href="#Small-world-network" class="headerlink" title="Small-world network"></a>Small-world network</h1><h2 id="Stylised-fact"><a href="#Stylised-fact" class="headerlink" title="Stylised fact"></a>Stylised fact</h2><ul><li>small diameters</li><li>high clustering coefficient</li><li>navigable: people are able to choose the “shortest” path that generate the small diameter, even <strong>without</strong> global knowledge.<ul><li>how to do that? </li><li>Estimate the number of the shortest path through the certain person, and choose one with the highest number.</li></ul></li></ul><h3 id="Strong-weak-ties"><a href="#Strong-weak-ties" class="headerlink" title="Strong / weak ties"></a>Strong / weak ties</h3><ul><li><p>strong: within clusters/groups</p></li><li><p>weak: “bridge” clusters/groups</p><p>It is <strong>weak ties</strong> that makes social network navigable.</p></li></ul><h2 id="Detection"><a href="#Detection" class="headerlink" title="Detection"></a>Detection</h2><p>We can judge if a network is a small-world network by randomly generating networks and compare their <strong>diameter and clustering coefficient</strong>.</p><h2 id="Watts-Strogatz-Model"><a href="#Watts-Strogatz-Model" class="headerlink" title="Watts-Strogatz Model"></a>Watts-Strogatz Model</h2><h3 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h3><p>Randomly rewire links in ring lattice network of size $n$.</p><h3 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h3><ul><li>$d$: dimensionality (no deep study)</li><li>$s$: the distance of the farthest neighbor</li><li>$p$: the rewiring probability</li></ul><h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><ol><li>start with regular lattice of dimension $d$ , ring lattice: $d = 1$​</li><li>connect nodes at lattice distance up to $s$, example: $s = 5$​</li><li>rewire source of each link to random node with probability $p$</li></ol><h3 id="Ring-lattice"><a href="#Ring-lattice" class="headerlink" title="Ring lattice"></a>Ring lattice</h3><h4 id="Clustering-coefficient-1"><a href="#Clustering-coefficient-1" class="headerlink" title="Clustering coefficient"></a>Clustering coefficient</h4><p>Assume each node maintains a window with width of $2s+1$ . For each node, it has $2s$ neighbors. For the node with the distance $t,t&lt;s$, its window overlaps with the original node with the size of $2s+1-t$. Among these  $2s+1-t$ nodes, one is the original node and the other is the center of the new window. So, totally the new node is linked to $2s-1-t$ to the old node’s neighbors. </p><p>The clustering coefficient is the number of appearance links $\sum_i\text{overlap}<em>i$​  divided by the total number of possible links $\frac{2s(2s-1)}{2}$ .<br>$$<br>C=\frac{2[\sum</em>{i=1}^s(2s-i-1)]/2}{(2s-1)2s/2}=\frac{3s-3}{4s-2}<br>$$</p><h4 id="Diameter-1"><a href="#Diameter-1" class="headerlink" title="Diameter"></a>Diameter</h4><p>Assume a circle, in one step, a node can reach to the node with $s$ distance from it farthest. The farthest node has $\frac{n}{2}$ steps from it. It totally costs  $\frac{n}{2s}$ steps.</p><p>Therefore, $D\sim \frac{n}{2s}$</p><h4 id="Degree-distribution"><a href="#Degree-distribution" class="headerlink" title="Degree distribution"></a>Degree distribution</h4><p>all the nodes have the same degree.</p><h3 id="Clustering-coefficient-2"><a href="#Clustering-coefficient-2" class="headerlink" title="Clustering coefficient"></a>Clustering coefficient</h3><p> $\frac{C_p}{C_0}$​ drops slowly first and then rapidly</p><h3 id="Diameter-2"><a href="#Diameter-2" class="headerlink" title="Diameter"></a>Diameter</h3><p>$\frac{l_p}{l_0}$​ drops rapidly first and then slowly.</p><h3 id="Small-world-regime"><a href="#Small-world-regime" class="headerlink" title="Small world regime"></a>Small world regime</h3><p>A range of $p$, where  $\frac{l_p}{l_0}\ll 1$and $\frac{C_p}{C_0}\gg 0$</p><h1 id="Fix-degree-sequence-network"><a href="#Fix-degree-sequence-network" class="headerlink" title="Fix degree sequence network"></a>Fix degree sequence network</h1><p>We study degree sequence because we can</p><ul><li><strong>analytically</strong> study expected properties of networks.<ul><li>first of all, the degrees of nodes are one frequent source of heterogeneity in complex systems. We often want to incorporate heterogeneity into our model instead of assuming all the nodes are equal.</li><li>Secondly, the degree sequence allows us to study expected properties of networks beyond simple random models.</li></ul></li><li>understand which of a system’s properties are due to the level of connectivity of nodes rather than due to the actual topology of these connections.</li></ul><h2 id="Molloy-Reed-model"><a href="#Molloy-Reed-model" class="headerlink" title="Molloy-Reed model"></a>Molloy-Reed model</h2><ol><li>create empty network with n nodes</li><li>for each node $i$ generate $d_i$ “link stubs”</li><li>draw pairs of link stubs uniformly at random and connect them until no stubs are left.</li></ol><h2 id="Difference-with-degree-distribution"><a href="#Difference-with-degree-distribution" class="headerlink" title="Difference with degree distribution"></a>Difference with degree distribution</h2><p>Given the degree sequence, the number of edges is given.</p><p>But given the degree distribution, e.g. Poisson degree distribution, the number of edges is still flexible, but the expectation is fixed.</p><h3 id="Poisson-Degree-Distribution"><a href="#Poisson-Degree-Distribution" class="headerlink" title="Poisson Degree Distribution"></a>Poisson Degree Distribution</h3><p>$$<br>p(k)=\frac{\lambda^ke^{-\lambda}}{k!}<br>$$</p><ul><li>$\lambda$ is the mean degree</li><li>it describes the degree distribution of <strong>sparse</strong> random networks</li><li>for large $n$, it is equivalent to statistical ensemble generated by $G(n,p)$ model with $np=\lambda$ </li></ul><h3 id="Zipf-degree-distribution"><a href="#Zipf-degree-distribution" class="headerlink" title="Zipf degree distribution"></a>Zipf degree distribution</h3><p>$$<br>p(k)=k^{-\gamma}\cdot \zeta(\gamma)^{-1}<br>$$</p><ul><li>power law with $\gamma\geq 2$ </li><li>it describes for a <strong>broad degree</strong> distribution, to imitate <strong>scale-free</strong> networks.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Complex System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CIL5 Data Clustering</title>
      <link href="/cil-5mm/"/>
      <url>/cil-5mm/</url>
      
        <content type="html"><![CDATA[<h1 id="Vector-Quantization"><a href="#Vector-Quantization" class="headerlink" title="Vector Quantization"></a>Vector Quantization</h1><p>assign vectors to some groups, denoted by the centroids. Methods: K-means, Mixture Model.</p><h1 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a>K-Means</h1><ul><li>$k$: the number of clusters</li><li>means: the way we get the centroids is by averaging.</li></ul><h2 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h2><p>$$<br>\min_{U,Z}J(U,Z)=\sum_{i=1}^N \sum_{j=1}^K z_{ij}=|x_i-u_j|^2 = |X-UZ^\top|_F^2<br>$$</p><p>Here, we use the <strong>squared</strong> Euclidean distance, not the Euclidean distance.</p><h2 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h2><p>Alternating minimization</p><ul><li>update $Z$, given $U$: the closest $U$</li><li>update $U$, given $Z$: the average of $Z$.</li></ul><h2 id="Practical-considerations"><a href="#Practical-considerations" class="headerlink" title="Practical considerations"></a>Practical considerations</h2><ul><li>Quadratic convergence rate.</li><li>computational cost: $O(nkd)$ per iteration.</li></ul><h2 id="Variant"><a href="#Variant" class="headerlink" title="Variant"></a>Variant</h2><h3 id="initialization-K-Means"><a href="#initialization-K-Means" class="headerlink" title="initialization: K-Means++"></a>initialization: K-Means++</h3><p>Since initialize $U$ and $Z$ matter a lot to the computation cost and final result, this variant try to find a better way to initialize $U$. </p><p><a href="https://en.wikipedia.org/wiki/K-means%2B%2B">wiki</a></p><p>The intuition behind this approach is that <strong>spreading out</strong> the $k$  initial cluster centers is a good thing: </p><ol><li>the first cluster center is chosen uniformly at random from the data points that are being clustered, </li><li>after which each subsequent cluster center is chosen from the remaining data points with probability proportional to its squared distance from the point’s closest existing cluster center.</li></ol><h3 id="sub-training-dataset-Core-set"><a href="#sub-training-dataset-Core-set" class="headerlink" title="sub-training dataset: Core set"></a>sub-training dataset: Core set</h3><p>The idea is our dataset is too big to run the K-Means algorithm. Therefore, we need to extract a sub-sample dataset from it. This method solves how to select the sub-training dataset.</p><ul><li><p>how big should the sub-dataset be?</p><ul><li><p>m is dependent on $\epsilon$-approximation guarantees (with probability $\delta$ for</p><p>$$<br>m\propto \frac{dk\log k+\log 1/\delta}{\epsilon^2}<br>$$</p></li></ul></li><li><p>which nodes should be selected?</p><ul><li><p>randomly selected, according to the probability, which combines the uniform selection and the distance of nodes to centroids.</p><p> $$<br>p_i=\frac{1}{2N}+\frac{D_i^2}{2\sum_{j=1}^N D_j^2}<br> $$</p></li><li><p>why to weight the data points?<a href="https://las.inf.ethz.ch/files/bachem18scalable.pdf">the original paper</a></p><ul><li><p>the weight is to guarantee the expectation of the quantization error on the sample dataset doesn’t change.</p><ul><li>the original vector quantization error is </li></ul><p>$$<br>\phi_{\chi}(Q)=\sum_{x\in \chi}d(x,Q)^2 = \sum_{x\in\chi}q(x)\frac{d(x,Q)^2}{q(x)}<br>$$</p><p>The quantization error can hence be approximated by sampling m points from $\mathcal{X}$ using $q(x)$and assigning them weights inversely proportional to  $q(x)$.  Back to the original dataset, we can assign each data point with the selection probability $\frac{1}{N}$, and weight $1$, we get  $\mathbb{E}(\phi_\chi(Q)=\frac{1}{N}\mathbb{E}(\sum_{x\in\chi}d(x,Q)^2)$</p><ul><li><p>the error on the new dataset $\zeta$ is $\phi_\zeta(Q)=\sum_{x\in\zeta}p(x)w(w)d(x,Q)^2$, </p><p>Set $w(x)=\frac{1}{mp(x)}$</p></li></ul></li></ul></li></ul></li></ul><h1 id="Mixture-Model"><a href="#Mixture-Model" class="headerlink" title="Mixture Model"></a>Mixture Model</h1><h2 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h2><p>Probabilistic clustering. For each data point, it is not absolutely assigned to one cluster but with the probability belonging to one cluster.</p><h2 id="Gaussian-Mixture-Model"><a href="#Gaussian-Mixture-Model" class="headerlink" title="Gaussian Mixture Model"></a>Gaussian Mixture Model</h2><ul><li>mixture: several models mixed together</li><li>gaussian: each model follows the multinomial Gaussian distribution.</li><li>the categorical distribution of $j$ is given ahead and the same for all $x$? Or it is related to  $x_i$, which means should be written as $\pi_{ij}$? How should we know ?<ul><li>Yes. Here $\pi_j$ means $p(z_i=1)$, this is known from our dataset as a whole, not meaning $p(z_{ij}=1|x_i)$ </li><li>So, it only applies when we already know the categories for all $x$</li></ul></li></ul><p>$$<br>p(x;\theta)=\sum_{j=1}^K\pi_j p(x;\mu_j,\Sigma_j)<br>$$</p><p>​     we can understand in this way: The model is composed of different models. For a data point $x$, its probability of generated by this “big” model, is decided by its probability of generated by each “small” model, and the proportion of the “small” model. For example, I know  $x$ is generated by the $j$-th model with probability 1 and 0 to other models, and $j$-th model totally generates $\pi_j\cdot N$ number of points, ($N$ is the size of the dataset), then the probability of  $x$ is generated by the whole model is $1\cdot\pi_j$</p><h3 id="ML-method"><a href="#ML-method" class="headerlink" title="ML method"></a>ML method</h3><p>Maximum likelihood method usually </p><ul><li>makes some general assumption about the distribution. Here: the Gaussian distribution.</li><li>then try to obtain/ “infer” the specifics from the data available.</li></ul><h3 id="Generation-EM-algorithms"><a href="#Generation-EM-algorithms" class="headerlink" title="Generation- EM algorithms"></a>Generation- EM algorithms</h3><p>By <strong>MLE</strong>, we want to get the parameters of $\theta$. Since the objective function has a summation within a log calculation, we should use E-M algorithm and use Jensen’s inequality.</p><ul><li><p>what is the role of $q_j$?</p><ul><li>$q_j$ should exactly be $q_{ij}$, it is related to $x_i$. It means $p(z_{ij}=1|x_i)$ </li></ul></li><li><p>why  we also estimate $\pi_j$? I think it is given ahead, and has no effect on the solution of $\theta$</p><ul><li>Yes, it has no <strong>direct</strong> effect on $\theta$, but has a direct influence on , $qz_{ij}$ thus indirectly influences $\theta$. Therefore, in each step, we also need to optimize $\pi_j$</li></ul></li></ul><h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><p>It is easy to get the inference of latent variable $j$ as $q_{ij}$</p><h1 id="Model-Selection"><a href="#Model-Selection" class="headerlink" title="Model Selection"></a>Model Selection</h1><h2 id="Data-fit"><a href="#Data-fit" class="headerlink" title="Data fit"></a>Data fit</h2><h2 id="Complexity"><a href="#Complexity" class="headerlink" title="Complexity"></a>Complexity</h2><p>can be measured by the number of free parameters.</p><h3 id="AIC"><a href="#AIC" class="headerlink" title="AIC"></a>AIC</h3><p>$$<br>\text{AIC}(\theta|X)=-\log p(X;\theta)+\kappa(\theta)<br>$$</p><h3 id="BIC"><a href="#BIC" class="headerlink" title="BIC"></a>BIC</h3><p>$$<br>\text{BIC}(\theta|X)=-\log p(X;\theta)+\frac{1}{2}\kappa(\theta)\log N<br>$$</p><p>BIC penalizes complexity more than AIC criterion</p><p>A single AIC (BIC) result is meaningless. One has to repeat the analysis for different Ks and compare the differences: the most suitable number of clusters corresponds to the smallest AIC (BIC) value.</p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CN3 Ensemble perspective</title>
      <link href="/cn03/"/>
      <url>/cn03/</url>
      
        <content type="html"><![CDATA[<h1 id="Aims"><a href="#Aims" class="headerlink" title="Aims:"></a>Aims:</h1><ul><li>graph theory: micro-/macro perspective</li><li>ensemble perspective</li><li>random graph models</li><li>empirical examples</li></ul><h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><ul><li><p>For an undirected network, define the degree distribution and the mean degree.</p><ul><li>degree distribution: $P(d_i=n)=\frac{|d_j=n|}{N}$​</li><li>mean degree: $\bar{d}=\frac{\sum_i d_i}{N}$ </li></ul></li><li><p>define the degree assortativity coefficient. What do positive and negative values indicate, what does a zero value mean?</p></li><li><p>what is a stylised fact? Give an example for a real-world network</p></li><li><p>algorithmic formulation for $\frac{G(n,p)}{G(n, m)}$ model</p><ul><li>$G(n,p)$:<ol><li>build $n$ nodes</li><li>for each node $i$, iterate on all the other nodes<ol><li>generate a uniformly distributed random number $t$ between 0 and 1.</li><li>if $t&lt;p$, add an edge between  i and the other node</li></ol></li></ol></li><li>$G(n,m)$ (undirected version):<ol><li>build $n$ nodes</li><li>from $(1, 2, … , \frac{n(n-1)}{2})$​ randomly choose m different numbers.</li><li>link edges between the pairs corresponding to the encoded number.</li></ol></li></ul></li><li><p>what is a statistical ensemble in the context of complex networks? what is macrostate? what is microstate?</p></li><li><p>what is the limiting degree distribution for networks generated by the $G(n,p)$ model?</p><ul><li><p>In $G(n,p)$ model, a node has degree $i$​​​ ‘s probability<br>$$<br>P(d_x=i)=\frac{(n-1)!}{i!(n-1-i)!}p^i(1-p)^{n-1-i}<br>$$</p></li><li><p>this is a binomial distribution. I think the limitation of binomial distribution with $n\to\infty$  is a Poisson distribution. No, it is normal distribution.</p></li></ul></li><li><p>Under what condition does the degree distribution converge to a Poisson distribution?</p><ul><li>inspired by the $G(n,p)$ model: when all the nodes have almost the same degree?</li></ul></li><li><p>What degree assortativity coefficient do you expect for a random network?</p></li></ul><h1 id="Keys"><a href="#Keys" class="headerlink" title="Keys"></a>Keys</h1><ul><li>degree assortativity coefficient,  </li><li>statistical ensemble, </li><li>$\frac{G(n,p)}{G(n,m)}$</li><li>limiting degree distribution</li></ul><h1 id="Statistical-index"><a href="#Statistical-index" class="headerlink" title="Statistical index"></a>Statistical index</h1><h2 id="Degree"><a href="#Degree" class="headerlink" title="Degree"></a>Degree</h2><h3 id="Degree-sequence"><a href="#Degree-sequence" class="headerlink" title="Degree sequence"></a>Degree sequence</h3><ul><li>graphic degree sequence</li></ul><h3 id="Degree-distribution"><a href="#Degree-distribution" class="headerlink" title="Degree distribution"></a>Degree distribution</h3><p>compared to degree sequence: we lose the information of the number of nodes.</p><ul><li>mean degree, can be calculated from degree distribution $\bar{d}=\frac{\sum_id_i}{N}=\sum_{i\in V}k\cdot P(k)$</li></ul><h3 id="Degree-assortativity-coefficient"><a href="#Degree-assortativity-coefficient" class="headerlink" title="Degree assortativity coefficient"></a>Degree assortativity coefficient</h3><p>$$<br>r=\frac{\sum_{ij}(A_{ij}-\frac{d_id_j}{2|E|})d_id_j}{\sum_{ij}(d_i\delta_{ij}-\frac{d_id_j}{2|E|})d_id_j}\in [-1, 1]<br>$$</p><p>$$<br>r=\frac{\sum_{ij}(A_{ij}-\frac{d_id_j}{2|E|})d_id_j}{\sum_id_i^3 -\frac{1}{2|E|}\sum_{ij}(d_id_j)^2}<br>$$</p><ul><li>assortativity: measure something in common.</li><li>degree assortativity: to what extent the nodes are linked to nodes that are similar.</li><li>Positive value (<strong>assortative mixing</strong>): high-degree nodes are<br>preferentially connected to other high-degree nodes and low-degree nodes<br>are preferentially connected to other low-degree nodes</li><li>negative value (<strong>disassortative mixing</strong>): high-degree nodes are<br>preferentially connected to low-degree nodes and vice-versa</li><li>In social networks, assortative mixing is common.</li></ul><h2 id="Triads"><a href="#Triads" class="headerlink" title="Triads"></a>Triads</h2><h3 id="Transitivity"><a href="#Transitivity" class="headerlink" title="Transitivity"></a>Transitivity</h3><p>closed triads</p><h3 id="Clustering-coefficient"><a href="#Clustering-coefficient" class="headerlink" title="Clustering coefficient"></a>Clustering coefficient</h3><p>clustering coefficient can be interpreted as conditional probability, when $A$ and $B$ both link to $C$, the probability of there is an edge between $A$ and $B$.</p><ul><li><p>local clustering coefficient: the node level</p><p>is defined by the number of links between its neighbors normalized by the total possible number of links between its neighbors.</p><ul><li>undirected network: $C_i=\frac{k(i)}{d_i(d_i-1)/2}$ </li></ul></li><li><p>global clustering coefficient: the network level</p><p>average through all the nodes $C_g=\frac{\sum_i C_i}{N}$</p></li></ul><h1 id="Stylised-facts"><a href="#Stylised-facts" class="headerlink" title="Stylised facts"></a>Stylised facts</h1><p>summarize results in a rough way, capturing some broad tendencies and ignoring the individual detail.</p><p>For example, a network has small clustering coefficient, large diameters, broad/narrow degree distribution, assortative/disassortative.</p><ul><li>We can compare to <strong>random networks</strong> to generate some interesting findings!!!</li></ul><h1 id="Micro-Macro-scopic-Perspective"><a href="#Micro-Macro-scopic-Perspective" class="headerlink" title="Micro-/Macro-scopic Perspective"></a>Micro-/Macro-scopic Perspective</h1><ul><li>when we have full knowledge of a system, it is reasonable to take a microscopic perspective.</li><li>when we want to understand why different systems exhibit similar features, we need to take a macroscopic perspective.</li></ul><h2 id="Statistical-ensembles"><a href="#Statistical-ensembles" class="headerlink" title="Statistical ensembles"></a>Statistical ensembles</h2><p>to deal with <strong>lack of</strong> knowledge about <strong>micro</strong>scopic details.</p><p>We use statistical ensembles to find <strong>statistical regularities</strong> of microstates, when given macrostates.</p><h3 id="Random-graph-models"><a href="#Random-graph-models" class="headerlink" title="Random graph models"></a>Random graph models</h3><ul><li>using simple stochastic null models as the reference study networks</li><li>important <strong>baseline</strong> for network analysis and pattern recoginition</li><li>models:<ul><li>Erdos-Renyi model: $\frac{G(n,p)}{G(n,m)}$<ul><li>for $G(n,m)$ model, we can calculate:<ul><li>the mean of degree: $\frac{2m}{n}$</li><li>the variance of degree: <ul><li><p>there are totally $\frac{n(n-1)}{2}$ edges</p></li><li><p>the probability of each edge being selected is: $\frac{2m}{n(n-1)}$​</p></li><li><p>the probability of a node has degree $k$​​ is:<br>$$<br>\frac{(n-1)!}{k!(n-1-k)!}\cdot p^k(1-p)^{n-1-k}<br>$$</p></li><li><p>the variance is: $n\cdot\frac{2m}{n(n-1)}\cdot(1-\frac{2m}{n(n-1)})$​</p></li></ul></li></ul></li><li>for $G(n,p)$ model, we can calculate <ul><li>the probability of one node has degree $i$</li><li>the probability of the network has m edges. (these two are binomial distribution)</li><li>first raw moment: the mean degree: $\langle k\rangle = np$ </li><li>second raw moment $\to$​ the variance of degrees: $\text{Var}(k)=\langle k^2\rangle -\langle k\rangle=np(1-p)$​ </li><li>limiting degree distribution. <ul><li>Fixed $p$, For very large network, it approximates to a <strong>normal distribution</strong>, with mean $np$, variance $np(1-p)$</li><li>Fixed $np$​​. That is when $n$​​ goes to infinity, $p$​​ goes to 0. It approximates to <strong>Poisson distribution</strong>, with $\lambda = \langle k\rangle=np$​ and  $P(k)\sim\frac{\lambda^k e^{-\lambda}}{k!}$​​  </li></ul></li></ul></li></ul></li></ul></li></ul><h2 id="Macroscopic"><a href="#Macroscopic" class="headerlink" title="Macroscopic"></a>Macroscopic</h2><p>we usually study a network based on its aggregate statistics. Lose detailed information allows us to imitate more networks sharing the same statistics and study and compare them.</p><h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><p>Examine the following index of a network</p><ul><li><p>the number of nodes</p></li><li><p>the number of edges</p></li><li><p>the mean degree</p></li><li><p>the diameter of the network</p></li><li><p>the average path length</p></li><li><p>the clustering coefficient</p></li><li><p>the degree assortativity</p></li><li><p>the degree distribution. When the degree distribution is broad and the mean degree is small, it requires more care to interpret the mean degree.</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Complex System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CN2 Network Essentials</title>
      <link href="/cn02/"/>
      <url>/cn02/</url>
      
        <content type="html"><![CDATA[<h1 id="Basic-Knowledge-of-network"><a href="#Basic-Knowledge-of-network" class="headerlink" title="Basic Knowledge of network"></a>Basic Knowledge of network</h1><h2 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h2><ul><li>Define the average shortest path length of a network<ul><li>the sum of the shortest path between every two nodes, </li><li>divided by the number of pairs <ul><li>$n(n-1)$ for directed </li><li>or $\frac{n(n-1)}{2}$ for undirected</li></ul></li></ul></li><li> Why does the k-th power of an adjacency matrix count paths of length $k$?</li><li>according to the definition of matrix power.</li><li>Can you define the betweenness and closeness centrality of a node.<ul><li>betweenness: the number of shortest path through this node.<ul><li>if normalized, divided the number of shortest paths between node $s$ and $t$.</li></ul></li><li>closeness: the average of the its distance to other nodes. Then, <strong>take the inverse</strong>.</li></ul></li><li>Can you construct a network in which the node with highest betweenness centrality is the one with the smallest degree centrality?<ul><li>the node between two fully-connected communities.</li></ul></li><li>Can you explain how we can find the modularity $Q_{opt}$ of a network?<ul><li>searching all the possible community divisions.</li></ul></li><li>How is $Q_{max}$ different from $Q_{opt}$?<ul><li>$Q_{max}$​ is a calculation method working on $Q$ and $C$, but $Q_{opt}$ is a maximize operation on all possible $Q(G,C)$</li></ul></li><li>For a fully connected network with $n$ nodes and no self-loops and a single community $C_1$, can you show that $Q\to 0, n\to\infty$?<ul><li><p>with a single community, we know that<br>$$<br>\delta(c_i, c_j) = 1, Q(G,C)=\frac{1}{2m}\sum_{i,j}(A_{ij}-\frac{d_id_j}{2m})<br>$$</p></li><li><p>the fully connected means $d_i=n-1, m=\frac{n(n-1)}{2}, A_{ij}=1,\forall i\neq j$​ </p></li><li><p>bring all these values we can get<br>$$<br>Q(G, C)= 1 -\frac{1}{2m}\sum_{i,j}\frac{(n-1)(n-1)}{n(n-1)}=1-\frac{1}{n(n-1)}nn\frac{(n-1)}{n}<br>$$</p></li><li><p>Here, there may be some different ideas on if $\sum_{ij}$ include the diagonal objects, that is whether there are totally $n\times n$ elements or $n\times (n-1)$ elements. This is not a big influence.</p></li></ul></li><li>For a network with n nodes, only connected by self-loops (represented by 1-elements on the diagonal) and each node i assigned to its own community $C_i$ , can you show that $Q\to\frac{1}{2}, n\to\infty$ ?<ul><li>with its own community, we know that $\delta(c_i, c_j)=0,\forall i\neq j$​, $Q(G,C)=\frac{1}{2m}\sum_i(A_{ii}-\frac{d_id_i}{2m})$​</li><li>only self-loops means $d_i=2, m=n, A_{ii}=1$ </li><li>bring all these values we can get $Q(G, C)=\frac{1}{2n}\sum_i(1-\frac{4}{2n})=\frac{1}{2}-\frac{2}{n}$ </li><li>Note that the degree of each node is 2, not 1.</li></ul></li></ul><h2 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h2><p>modularity</p><h1 id="Path"><a href="#Path" class="headerlink" title="Path"></a>Path</h1><h2 id="length-of-path"><a href="#length-of-path" class="headerlink" title="length of path"></a>length of path</h2><p>$$<br>\text{len}(n_0, n_1,\cdots, n_l)=l<br>$$</p><h3 id="powers-of-adjacency-matrix"><a href="#powers-of-adjacency-matrix" class="headerlink" title="powers of adjacency matrix"></a>powers of adjacency matrix</h3><p>elements $A_{ij}^k$​  counts paths of (exactly) length $k$​ between $i$  and $j$.</p><h2 id="Distance-of-two-nodes"><a href="#Distance-of-two-nodes" class="headerlink" title="Distance of two nodes"></a>Distance of two nodes</h2><p>the shortest length of path between these two nodes.</p><h2 id="Diameter-of-network"><a href="#Diameter-of-network" class="headerlink" title="Diameter of network"></a>Diameter of network</h2><p>the longest shortest path. </p><p>Use the symbol $\text{diam}(G)$</p><h2 id="Average-Shortest-path-length-of-network"><a href="#Average-Shortest-path-length-of-network" class="headerlink" title="Average Shortest path length of network"></a>Average Shortest path length of network</h2><p>“the typical shortest path” </p><p>use the symbol $\langle l\rangle$</p><h2 id="Connected-Components"><a href="#Connected-Components" class="headerlink" title="Connected Components"></a>Connected Components</h2><p>maximally (means locally) connected subgraphs</p><ul><li>size: the number of nodes</li><li>can be shown by the infinite power of adjacency matrix $A^k, k\to\infty$ <h3 id="largest-connected-component"><a href="#largest-connected-component" class="headerlink" title="largest connected component"></a>largest connected component</h3>the largest subgraph<h4 id="Giant-connected-component"><a href="#Giant-connected-component" class="headerlink" title="Giant connected component"></a>Giant connected component</h4>if the largest connected component contains almost all the nodes $\frac{|V’|}{|V|}\simeq 1$</li></ul><h1 id="Community"><a href="#Community" class="headerlink" title="Community"></a>Community</h1><p>partitions of nodes, can be overlapping. But we only consider non-overlapping partition.</p><p>intuitively, the following two conditions should hold:</p><ul><li>nodes within the same community should be “well-connected” to each other</li><li>nodes in different communities should have few connections.</li></ul><h2 id="Partition-Quality-Q-​"><a href="#Partition-Quality-Q-​" class="headerlink" title="Partition Quality: $Q$​"></a>Partition Quality: $Q$​</h2><p>$$<br>Q(G,C)=\frac{1}{2m}\sum_{i,j}(A_{ij}-\frac{d_id_j}{2m})\delta(c_i, c_j)<br>$$</p><p>two special cases:</p><ul><li>all nodes in a single community: $Q=0$</li><li>each community contains only one node: $Q=0$</li><li>theoretically maximum value $1$.</li></ul><h3 id="Q-opt-​"><a href="#Q-opt-​" class="headerlink" title="$Q_{opt}$​"></a>$Q_{opt}$​</h3><p>$$<br>Q_{opt}=\max_C Q(G,C)<br>$$</p><p>the optimal partition quality. This is a property of a given network $G$. It is called <strong>modularity</strong></p><ul><li>object: $G$</li><li>less than 1, due to two reasons:<ul><li>there is a single link $(b, d)$ that connects nodes in different communities</li><li>there are missing links within both communities (simply because the graph does not have enough links)</li></ul></li></ul><h3 id="Q-max-​"><a href="#Q-max-​" class="headerlink" title="$Q_{max}$​"></a>$Q_{max}$​</h3><p>$$<br>Q_{\max}(G,C)=1-\frac{1}{2m}\sum_{i,j}(\frac{d_id_j}{2m})\delta(c_i, c_j)<br>$$</p><p>“max” here means a calculation method, guided by some max idea for given $G$ and $C$, <strong>not</strong> meaning any maximize process.</p><ul><li>object: $G$ and $C$</li></ul><h3 id="Community-assortativity-coefficient"><a href="#Community-assortativity-coefficient" class="headerlink" title="Community assortativity coefficient"></a>Community assortativity coefficient</h3><p>the ratio of the $Q_{opt}$ with $Q_{\max}$ got by this optimal $C$.</p><ul><li><p>object: $G$.</p></li><li><p>quantify how close the topology is to the strongest possible partitioning, to a range between 0 and 1. This allow us to <strong>judge whether a network exhibits community structure or not</strong>.<br>$$<br>\frac{Q_{opt}(G)}{Q_{\max}(G,\tilde{C})}<br>$$</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Complex System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CIL4 Word Embeddings</title>
      <link href="/cil-4we/"/>
      <url>/cil-4we/</url>
      
        <content type="html"><![CDATA[<h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><p>Using <strong>vector</strong> as the symbol to represent words, which can capture their meaning in some way.</p><ul><li>the advantage of vector representation?</li><li>maybe capture the meaning closeness of words. e.g. similar words have similar vectors.</li><li>how do we know if the embedding is good?<ul><li><p>usually, we use the prediction ability to evaluate the goodness. </p></li><li><p>skip-ram model (distributional context model): a model of prediction. Given a context word, learn the probability distribution of all the vocabularies. Our objective is to maximize:<br>$$<br>L(\theta;w) = \sum_{t=1}^T \sum_{\Delta\in I}\log p_\theta(w^{t+\Delta}|w^{(t)})<br>$$<br>the context is a point, the predicted words are a window.</p></li><li><p>CBOW (continuous bag-of-word model): Contrary to the skip-ram model, given the context words, learn the probability of this word. The context is a window, the predicted word is a point.</p></li></ul></li></ul><h1 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h1><h2 id="Latent-Vector-Model"><a href="#Latent-Vector-Model" class="headerlink" title="Latent Vector Model"></a>Latent Vector Model</h2><p>$$<br>w\mapsto (\vec{x_w},b_w)\in\mathbb{R}^{d+1}<br>$$</p><p>represent a word by a vector and a scalar bias.</p><ul><li>what is the function of bias?<ul><li><p>to make sure that some words are more likely than other words <strong>under all conditioning</strong>. Reflected by the definition of probabilistic:<br>$$<br>\log p_\theta(w|w’)=&lt;x_w, x_{w’}&gt; + b_w+\text{const}(w’)<br>$$</p><ul><li> the const is to guarantee the sum conditioned on $w’$ is 1.</li></ul></li><li><p>it is not necessary but very helpful to have the bias item.</p></li></ul><strong>Inner product</strong> is a natural way to evaluate the similarity of vectors<h3 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h3>$$<br>L(\theta;w)=\sum_{t=1}^T \sum_{\Delta\in I}[\log b_{w(t+\Delta)}+\log &lt;x_{w(t+\Delta)},x_{w(t)}&gt;-\log\sum_{v\in V}\exp[&lt;x_v, x_{w(t)}&gt; + b_v]]<br>$$</li></ul><h3 id="Modification"><a href="#Modification" class="headerlink" title="Modification"></a>Modification</h3><ul><li><p>why to distinguish the main vocabulary and context vocabulary? </p><ul><li><p>if we don’t distinguish, a word as to be predicted and as the context will have the same representation. But the reality isn’t like that. If we use different representation when a word has different roles, it will add the expression ability of the model.</p></li><li><p>symmetric could be a problem. For instance, according to the bayesian rule: </p><p>$$<br>p(w,w’)=p(w|w’)p(w’)=p(w’|w)p(w)<br>$$<br>if $w$ and $w’$ have different probability, the two conditional probabilities also should be different. In other words, these two are not symmetric.</p></li></ul></li><li><p>how to deal with the exponential item?</p><ul><li>see the below models</li></ul></li></ul><h3 id="Negative-sampling"><a href="#Negative-sampling" class="headerlink" title="Negative sampling"></a>Negative sampling</h3><p>This is a method of sampling. It is natural to use sampling when the object is exponentially big. One classic sampling method is MCMC.</p><ul><li><p>sampling: In the maximum likelihood estimation, each time for one context word, we need to update all the other words vectors, represented by the exponential items. This is very time-consuming. Instead, we only update a few words’ vectors. These few words are selected by sampling. </p></li><li><p>negative: all the words not the one we expected are called negative words. </p><ul><li>how to know which word is our expected word? the word itself as the context must be a positive word.</li></ul></li><li><p>how to update the word vectors?</p></li><li><p>what is the relationship between Negative sampling and PMI?</p></li></ul><h2 id="Glove-Global-vectors-for-word-representation"><a href="#Glove-Global-vectors-for-word-representation" class="headerlink" title="Glove: Global vectors for word representation"></a>Glove: Global vectors for word representation</h2><p>  The key idea of GloVe is: </p><ol><li><p>extract a count matrix from the given dataset. </p><ul><li>Each row is a word in the vocabulary</li><li>Each column is a context</li><li>Each entry $n_{ij}$ is the appearance times of the word i in the context $j$</li></ul></li><li><p>construct another matrix from the vector representation of vocabularies and contexts.</p><ul><li>each entry is the inner product of the vocabulary vector and the context vector.</li></ul></li><li><p>update vectors to make these two matrices as close as possible.</p><p>optional: using weight function to weight items with different counts.</p></li></ol><p>  In this way, the vector representation problem is transferred as a matrix factorization problem.</p><p>$$<br>\min_{X,Y}=|M-X^\top Y|_F^2<br>$$</p><ul><li><p>how does GloVe solve the exponential problem?</p><ul><li>it uses the <strong>unnormalized</strong> “probability” instead of the normalized ones to avoid the exponential item. Because the exponential item works for normalization. </li></ul></li></ul><h1 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h1><h2 id="SGD-Stochastic-gradient-descent"><a href="#SGD-Stochastic-gradient-descent" class="headerlink" title="SGD: Stochastic gradient descent"></a>SGD: Stochastic gradient descent</h2><ul><li><p>The objective function: $f(x)=\sum_i f_i(x)$</p></li><li><p>Traditional gradient descent way:</p><p>$$<br>\frac{\partial f}{\partial x}=\sum_i \frac{\partial f_i}{\partial x}<br>$$</p></li><li><p>Stochastic way:</p><p>$$<br>\frac{\partial f}{\partial x}=\frac{\partial f_\gamma}{\partial x}, \gamma\sim\text{Uniform}(1,n)<br>$$<br>Key Idea: </p><ul><li>derivative</li><li>only part of objective</li><li>stochastic each time</li></ul></li></ul><h1 id="Left-Questions"><a href="#Left-Questions" class="headerlink" title="Left Questions"></a>Left Questions</h1><ul><li>the relationship of Negative Sampling and PMI?</li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CN1 Introduction to Complex Network</title>
      <link href="/cn01/"/>
      <url>/cn01/</url>
      
        <content type="html"><![CDATA[<h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><h2 id="Objectives"><a href="#Objectives" class="headerlink" title="Objectives"></a>Objectives</h2><ul><li><p>network perspective on complex systems</p></li><li><p>examples for complex networks</p></li></ul><h2 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h2><ul><li>what does the complex networks perspective add to the study of complex systems?<ul><li>[Try] a more related and global analysis perspective?</li></ul></li><li>What is the difference between the network perspective and the agent-based modeling approach?<ul><li>[Try] network: global, agent-based: local.</li><li>Wrong. See below.</li></ul></li><li>Describe the micro and macro perspective on complex networks. What distinguishes them?<ul><li>[Try] micro: <strong>individual</strong>, on one node/edge, e.g. the degree of one node; macro: <strong>systemic properties</strong>, e.g.  the number of nodes/edges, more general, doesn’t cover the detail of the individual compoenent in the network. The information’s object distinguish them, whether the information is used to describe a single component.</li></ul></li><li>Give two examples for complex systems that can be studied from a network perspective.<ul><li>[Try] academic author citation situation; the spread of virus.</li></ul></li><li>Consider an example for a complex system: what is the micro-and the macro level?<ul><li>[Try] author citation network. micro: the citation number of each paper, macro: the distribution of the citation number.</li></ul></li><li>Define three macroscopic features of networks and use them to classify the example networks of this lecture<ul><li>[Try] the degree distribution, the density, the direction. The component coefficient.</li></ul></li><li>Give two examples for link semantics that result in undirected and directed links.<ul><li>[Try] directed: &lt;a,b&gt;, undirected: (a,b)</li></ul></li></ul><h2 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h2><ul><li>agent-based modeling</li><li>complex network basic conceptions</li><li>network observations</li><li>Micro/Macro perspective</li></ul><h2 id="Agent-based-modeling"><a href="#Agent-based-modeling" class="headerlink" title="Agent-based modeling"></a>Agent-based modeling</h2><table><thead><tr><th></th><th>Agent-based modeling</th><th>network perspective</th></tr></thead><tbody><tr><td>Focus</td><td>Internal dynamics of agents, e.g how agent make decisions</td><td>Topology</td></tr><tr><td>Show Format</td><td>group, mean field, etc</td><td>Nodes and links</td></tr><tr><td>More</td><td>Feedback between agent dynamics and interactions</td><td>dyadic interactions</td></tr></tbody></table><p>There is no hard separation between these two approaches.</p><h2 id="Complex-Systems"><a href="#Complex-Systems" class="headerlink" title="Complex Systems"></a>Complex Systems</h2><ul><li>a large number of <strong>subsystems</strong> -&gt; can be reduced</li><li>agents/subsystems <strong>strongly</strong> interacte with each other.</li></ul><h3 id="complex-network"><a href="#complex-network" class="headerlink" title="complex network"></a>complex network</h3><p>an <strong>abstract graphical</strong> representation of complex system.</p><h2 id="Micro-Macro"><a href="#Micro-Macro" class="headerlink" title="Micro-Macro"></a>Micro-Macro</h2><p>the micro-macro link: relate <strong>microscopic</strong> details of a model to the <strong>macroscopic</strong> features of the system that it will generate (and vice-versa).</p><p>Usage:</p><ul><li>explain large-scale patterns of the system based on microscopic behavior.</li><li>design microscopic behavior to achieve desirable systemic properties.</li></ul><h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><ul><li><p>technology systems: e.g. computer network (Internet), power grid infrastructure</p></li><li><p>social systems: friendship, communication, scientific community</p><table><thead><tr><th>Category</th><th>Nodes</th><th>Links</th><th>Examples</th></tr></thead><tbody><tr><td>Technology system</td><td>engineered artifacts</td><td>transport lines</td><td>computer network (internet), power grid infrastructure</td></tr><tr><td>Social system</td><td>actors</td><td>social ties</td><td>friendship, communication, scientific community, hierarchy relationships</td></tr><tr><td>Information system</td><td>knowledge artifact</td><td>semantic relations</td><td>scholarly citations</td></tr><tr><td>biological system</td><td>biological entities</td><td>biological interactions</td><td>gene regulartory network</td></tr><tr><td>economic system</td><td>actors</td><td>interactions</td><td>financial transaction, trade relation</td></tr></tbody></table></li></ul><h2 id="Obervations-of-network"><a href="#Obervations-of-network" class="headerlink" title="Obervations of network"></a>Obervations of network</h2><table><thead><tr><th>Perspective</th><th>Detail</th></tr></thead><tbody><tr><td>structure</td><td>regular, random, complex</td></tr><tr><td>connectedness</td><td>closely connected, diameter</td></tr><tr><td>heterogeneity</td><td>degree distribution</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph </tag>
            
            <tag> Complex System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CIL3 Topic Model</title>
      <link href="/cil-3tm/"/>
      <url>/cil-3tm/</url>
      
        <content type="html"><![CDATA[<ul><li>Are the topics given ahead, fixed? Means we already have a set of available topics.<ul><li>Yes. Also, in pLSA, all the words and documents are given.</li></ul></li><li>Are the given data regularized? Do they have the same dimension? Or have arbitrary length?<ul><li>Yes, they have the same dimension. We need to pre-process data to achieve this.</li></ul></li><li>what are the approaches to solve this problem?<ul><li>Key idea: Non-negative matrix factorization</li><li>practical method: EM algorithm<h1 id="pLSA-Probabilistic-Latent-Semantic-Analysis"><a href="#pLSA-Probabilistic-Latent-Semantic-Analysis" class="headerlink" title="pLSA: Probabilistic Latent Semantic Analysis"></a>pLSA: Probabilistic Latent Semantic Analysis</h1></li></ul></li><li>where shows <strong>probabilistic</strong>?<ul><li>the probability of $word_j$ in $document_i$ is generated by $topic_z$.</li></ul></li><li>what is the <strong>latent</strong>?<ul><li>the topics are latent variables.</li></ul></li><li>what does the <strong>semantic</strong> mean?<ul><li>semantic means each topic has a fixed vocabulary distribution. This distribution is the semantic of this latent variable.</li></ul></li><li>what is the natural motivation of this model?<ul><li>according to the “word appearance in this article” and all the “topics’ word” distribution pattern, find the “topics of this article”.</li></ul></li><li>how to do pLSA?<ul><li>ideally, using MLE to solve the matrix $V$.</li><li>actually, using EM to solve both $U$ and $V$.</li></ul></li></ul><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>Suppose the word appearance of a document is a probabilistic problem. This is wired, cause once a document is given, all the words are given, the p(word|docum) should be 1. In other words, a document is defined by all the words it includes.<br>We want to calculate this probability by the <strong>conditional probability</strong>, conditioned on the topics. That is how likely this document is under the specific topic? And how likely one word appears under this topic? Then we can get the probability of p(word|docum). p(topic|docum) is what we want to get.</p><h3 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h3><p>$$<br>p(w|d)=\sum_{z=1}^K p(w|z)p(z|d)<br>$$</p><p>$z$ represents topics, $w$ represents words, $d$ represents document.</p><p>We want to maximize the $p(w|d)$ by assigning $p(z|d)$.</p><ul><li>How do we know $p(w|z)$, given ahead?<ul><li>ideally, yes. Actually no. We also need to solve this matrix.</li></ul></li></ul><h3 id="Data-format"><a href="#Data-format" class="headerlink" title="Data format"></a>Data format</h3><p>A matrix $D: M\times N$. $M$ is the total number of different words, $N$ is the total number of documents. $D_ij$ is the occurrences of $w_i$ in document $d_j$ (or transposed)</p><ul><li>in the real-life case, will the M be very large? How should we decide N, how many documents we want to use?</li></ul><p>In a matrix perspective to resay this problem, we </p><ol><li><p>decompose $D$ as $UV$</p></li><li><p>$U$ is given, we try to assign $V$ to maximize the <strong>log-likelihood</strong> of $D$.</p><p>$$<br>\max\sum_{ij=1}x_{ij}\log p(w_i|d_j)<br>$$</p></li></ol><ul><li> $U: M\times T$,  $T$ is the number of topics. This is a given matrix, showing the word distribution of a topic. </li><li>$U_ij$ shows the $word_i$’s appearance <strong>probability</strong> under the $topic_j$, should be non-negative $U_{ij}\geq 0$</li><li>The sum of word distribution under a specific topic should be 1.$\sum_{i=1}^M U_{ij}=1$</li><li>$V: T\times N$. This is the matrix we want to assign. By assigning this matrix, we maximize the log-likelihood of $D$. $V_ij$ shows the <strong>ratio</strong> of the $topic_i$ in $document_j$. Document is a mixture of topics. We assume it composed by different topics.  Also, $V$ should satisfy the <ul><li>non-negative</li><li>sum as 1.</li></ul></li></ul><h2 id="Challenge"><a href="#Challenge" class="headerlink" title="Challenge"></a>Challenge</h2><p>The challenge is $U$ is not given. We have <strong>no prior</strong> knowledge on it. To solve this problem, we </p><ul><li>include one more variable $q_{zij}$, denotes the probability that word j in document i is generated by topic $z$, $\sum_z q_{zij}=1$ </li><li>use <strong>EM</strong> (expectation maximization) method.<ul><li>expectation step, solve $q$.  $q_{zij}=\frac{p(w_i|z)p(z|d_j)}{\sum_{k=1}^T p(w_i|k)p(k|d_j)}$</li><li>maximization step, solve $U$ and $V$. <ul><li>$u_{iz}=\frac{\sum_j x_{ij}q_{zij}}{\sum_i\sum_j x_{ij}q_{zij}}$ the probability of topic $z$ generates word $i$ is the total “number” of word $i$ generated by topic $z$ across all the topics divided by the “number” of all the words generated by topic z across  and topics.</li><li>$v_{zj}=\frac{\sum_i x_{ij}q_{zij}}{\sum_i x_{ij}}$, the ratio of topic $z$ in document $j$ is the number of words generated by topic $z$ in document $j$ divided by all the words in document $j$.</li></ul></li></ul></li></ul><h3 id="remarks"><a href="#remarks" class="headerlink" title="remarks"></a>remarks</h3><ul><li>convergence guaranteed</li><li><strong>not</strong> for the final global optimum</li><li>influenced by the initial value of $U_0$ and $V_0$, right?? Not unique??</li></ul><h1 id="LDA-Latent-Dirichlet-Allocation"><a href="#LDA-Latent-Dirichlet-Allocation" class="headerlink" title="LDA: Latent Dirichlet Allocation"></a>LDA: Latent Dirichlet Allocation</h1><ul><li>what is the different from pLSA<ul><li>Here, we take a different attitude to Word*topic matrix (essence) and Topic*Docum(nusiance) matrix.  But in pLSA, these two matrices have the same level.</li><li>Also, in LDA it is convenient to judge for new documents.</li></ul></li><li>where shows Dirichlet?<ul><li>In Docum*Topic matrix, we assume topics follow a dirichlet distribution given a document.</li><li>In Word*Topic matrix, we assume words follow a dirichlet distribution given a topic.</li></ul></li><li>what does the allocation mean?<ul><li>allocate topics to document by a dirichlet distribution</li></ul></li></ul><p><a href="https://zhuanlan.zhihu.com/p/31470216">zhihu</a></p><h2 id="Dirichlet-Distribution"><a href="#Dirichlet-Distribution" class="headerlink" title="Dirichlet Distribution"></a>Dirichlet Distribution</h2><ul><li>why we use dirichlet distribution here? Any advantage on computation? Or real-life closeness?<ul><li><a href="https://zh.wikipedia.org/wiki/%E7%8B%84%E5%88%A9%E5%85%8B%E9%9B%B7%E5%88%86%E5%B8%83">Dirichlet distribution</a> is used to describe the probability of each class i in totally K classes. It is for k classes continuous variables with the sum 1. It needs k parameters alphas.</li><li>Mwe use this cause it is good for the distribution of “probability”.</li><li>it is the “simplest” <strong>conjugate</strong> distribution. This is very nice!!! It means the prior and posterior are from the same distribution family.<ul><li>Gaussian Distribution is conjugate prior/posterior with respect to Gaussian likelihood.</li><li>with the multinomial likelihood, Dirichlet is the choice!</li></ul></li></ul></li></ul><h2 id="Model-1"><a href="#Model-1" class="headerlink" title="Model"></a>Model</h2><ul><li>how to solve the matrices $U$ and $V$?<ul><li>in LDA, there are two steps: <ul><li>achieve V, many methods:<ul><li>MCMC</li><li>Variational EM</li><li>…</li></ul></li><li>for each new document vector $x = (x_1,x_2,\cdots, x_M)$, the word count across all the possible word, we try to find the topic vector $u=(u_1, u_2, \cdots, u_K)$.</li></ul></li></ul></li></ul><p>Since <strong>vector u</strong> is not fixed, is some way random, we assume it follows a <strong>Dirichlet</strong> distribution, and the posterior <strong>vector x</strong> also follows a <strong>Dirichlet</strong> distribution. Then we apply Bayesian approach to solve <strong>u</strong> according to <strong>v</strong>.</p><h1 id="NMF-Non-Negative-Matrix-Factorization"><a href="#NMF-Non-Negative-Matrix-Factorization" class="headerlink" title="NMF: Non-Negative Matrix Factorization"></a>NMF: Non-Negative Matrix Factorization</h1><ul><li>what is NMF?<ul><li>all the entries of the decomposed matrix are non-negative and L1 normalization.</li></ul></li><li>what is the application situation of NMF?<ul><li>to solve the probabilistic matrix by reducing dimension.<h2 id="Objective-1"><a href="#Objective-1" class="headerlink" title="Objective"></a>Objective</h2></li></ul></li><li>log-likelihood objective when modeling for probability. That is pLSA</li><li>quadratic cost</li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CIL2 Matrix Completion</title>
      <link href="/cil-2mc/"/>
      <url>/cil-2mc/</url>
      
        <content type="html"><![CDATA[<p>There are two direction of consideration to complete the matrix with many missing values:</p><ul><li>statistical models: infer missing entries from observed ones, with k&lt;&lt;m*n parameters</li><li>low rank decomposition: find best approximation with low rank r. Parameter numbers: m<em>r+n</em>r=(m+n)r.</li></ul><h1 id="Objective"><a href="#Objective" class="headerlink" title="Objective"></a>Objective</h1><p>The key problem of this slide is:<br>$$<br>\min_{rank(B)=k}[\sum_{(i,j)\in I}(a_{ij}-b_{ij})^2], I = {(i,j): \text{observed}}<br>$$</p><h2 id="Non-convex"><a href="#Non-convex" class="headerlink" title="Non-convex"></a>Non-convex</h2><p>A non-convex problem can be non-convex on two parts: domain or objective.</p><p>Finding the best approximation matrix $B$ with the rank k is not a convex problem:</p><ul><li>the objective: minimize the frobenius norm is convex</li><li>the searching space: matrix with rank k is not convex. The sum of two matrices with the same rank may have different rank.</li></ul><p>Why we don’t like non-convex problem?</p><ul><li>because non-convex problem usually has higher variance, or leads to local minima, not the global one, depending on the input data.</li></ul><h2 id="Remark-on-SVD"><a href="#Remark-on-SVD" class="headerlink" title="Remark on SVD"></a>Remark on SVD</h2><ul><li>Is SVD the optimal solution of the low-rank approximation even it is a non-convex problem?<ul><li>An answer from <a href="https://mathoverflow.net/questions/32533/is-all-non-convex-optimization-heuristic">mathoverflow</a>: The classical case is the singular value decomposition (SVD) which is non-convex but yet solvable. This is because only the top eigenvector is the global and local optimum and all the other eigenvectors are saddle points (assuming eigen gap). </li></ul></li><li>Why SVD is not enough? <ul><li>Because we have a large amount of unobserved entries! In another way, we want to find a matrix $B$ according to the matrix $A$, but $A$ is not good enough.</li></ul></li></ul><h1 id="Solutions"><a href="#Solutions" class="headerlink" title="Solutions"></a>Solutions</h1><h2 id="Alternating-method"><a href="#Alternating-method" class="headerlink" title="Alternating method"></a>Alternating method</h2><p>This is a general method for non-convex problem with something convex.</p><ul><li>for fixed $U$, $f$ is convex in $V$</li><li>for fixed $V$, $f$ is convex in $U$</li></ul><h2 id="Steps"><a href="#Steps" class="headerlink" title="Steps"></a>Steps</h2><ul><li>$U:=\arg\min_U f(U,V)$</li><li>$u_i=(\sum_{j:(i,j)\in I}v_jv_j^\top+\lambda I_k)^{-1}\sum_{j:(i,j)\in I}a_{ij}v_j$</li><li>$V:=\arg\min_V f(U,V)$</li><li>$v_j = (\sum_{i:(i,j)\in I} u_i u_i^\top+\lambda I_k)^{-1}\sum_{i:(i,j)\in I} a_{ij} u_i$</li><li>repeat until convergence.</li></ul><p>Applied in CF problem:</p><ul><li>given low-dimensional representations for items/users: compute for each user/item <strong>independently</strong> the best representation</li><li>we learn low-dimensional representations of users and items in the same space: R^K.</li></ul><h2 id="Frobenius-Norm-Regularization"><a href="#Frobenius-Norm-Regularization" class="headerlink" title="Frobenius Norm Regularization"></a>Frobenius Norm Regularization</h2><ul><li>Why do we regularize the norm? <ul><li>to penalize the matrices. Preventing entries of $u_i, v_j$ from becoming too large. </li></ul></li><li>What is the consideration/advantage to do this?<ul><li>doing this is not for solving the non-convex problem but making the predicted result more general. Reducing overfitting.</li></ul></li><li>what is the disadvantage of doing this?<ul><li>the objective is no longer convex.</li><li>alternating least squares can be used.</li></ul></li></ul><h2 id="Convex-Relaxation"><a href="#Convex-Relaxation" class="headerlink" title="Convex Relaxation"></a>Convex Relaxation</h2><h3 id="Nuclear-Norm"><a href="#Nuclear-Norm" class="headerlink" title="Nuclear Norm"></a>Nuclear Norm</h3><ul><li><p>what is the definition of nuclear norm?</p><ul><li>$|A|_* = \sum_i\sigma_i$, $\sigma_i$ is the singular value of $A$.</li></ul></li><li><p>what is the property of nuclear norm?</p><ul><li>compared to Frobenius norm: if we define $\sigma(A)=(\sigma_1,\sigma_2,\cdots,\sigma_n)$​</li></ul></li></ul><p>$$<br>|A|_* =\text{trace}(\sqrt{A^*A})=|\sigma(A)|_1<br>$$</p><p>$$<br>|A|_F = \text{trace}(A^*A)=|\sigma(A)|_2<br>$$</p><p>compared to rank, it provides the <strong>tightest</strong> lower <strong>convex  bound</strong> of the rank: $\text{trace}(B)\geq |B|_*, \forall |B|_2\leq 1$ </p><p>Proof:<br>$$<br>|A|_2 =\sigma_\max (A)=\sigma_1<br>$$</p><p> Therefore, if $|A|_2\leq 1$  then $\sigma_i\leq 1,\forall i$ . Thus</p><p>$$<br>\text{rank}(A)=\sharp{\sigma_i &gt; 0}=\sum_{i:\sigma_i &gt;0} 1\geq \sum_{i:\sigma_i &gt;0}\sigma_i = \sum_{i}\sigma_i = |A|_*<br>$$</p><ul><li>does the condition mean we need to standardize $B$ s.t. the 2-norm less than 1.</li><li>convexity. Proof </li></ul><p>Recall, define $f: X\to \mathbb{R}$ is convex if $\forall x, y\in X$</p><p>$$<br>f(\lambda x + (1-\lambda) y)\leq \lambda f(x) + (1-\lambda) f(y), \forall \lambda \in [0,1]<br>$$</p><p>We want to show $\forall \lambda \in [0,1], \forall A,B\in\mathbb{R}^{m\times n}$​<br>$$<br>|\lambda A + (1-\lambda) B|_* \leq \lambda |A |_\ast + (1-\lambda) |B|_\ast<br>$$<br>Write SVD decomposition of left side:  $\lambda A + (1-\lambda )B=U_\lambda D_\lambda V_\lambda ^\top$<br>$$<br>|\lambda A + (1-\lambda) B|_\ast  = \text{trace}(D_\lambda) =\text{trace}[(U_\lambda^\top U_\lambda)D_\lambda (V_\lambda^\top V_\lambda)]\<br>$$</p><p>$$<br>=\text{trace}[U_\lambda^\top (U_\lambda D_\lambda V_\lambda^\top) V_\lambda] =\text{trace}[U_\lambda^\top (\lambda A + (1-\lambda)B) V_\lambda] \<br>$$</p><p>$$<br>  =\lambda \text{trace}(U_\lambda^\top A V_\lambda ) + (1-\lambda )\text{trace}(U_\lambda^\top B V_\lambda)<br>$$</p><p>Thus  $|\lambda A + (1-\lambda) B|_\ast =\lambda \text{trace}(U_\lambda^\top A V_\lambda) + (1-\lambda)\text{trace}(U_\lambda^\top B V_\lambda) $​</p><p>Write SVD decomposition of $A, A=U_AD_AV_A^\top$. Thus,<br>$$<br>\begin{align}<br>      \text{trace}(U_\lambda^\top AV_\lambda) &amp;=\sum_{i=1}^{\min(m,n)}[U_\lambda^\top A V_\lambda]<em>i^i = \sum</em>{i=1}^{\min(m,n)}[U_\lambda^\top U_A D_A V_A^\top V_\lambda]<em>i^i\<br>      &amp; = \sum</em>{i=1}^{\min(m,n)}\sum_{j=1}^{\min(m,n)}[U_\lambda^\top U_A]<em>j^i\sigma_j(A) [V_A^\top V_\lambda]<em>i^j\<br>      &amp; = \sum</em>{j=1}^{\min(m,n)}\sigma_j(A)\sum</em>{i=1}^{\min(m,n)}[U_\lambda^\top U_A]_j^i[V_A^\top V_\lambda]<em>i^j \<br>      &amp; \leq \sum</em>{j=1}^{\min(m,n)}\sigma_j(A)|[U_\lambda^\top U_A]_j|<em>2|[V_A^\top V_\lambda]^j|<em>2 \text{ (Cauchy-Schwartz)} \<br>      &amp; = \sum</em>{j=1}^{\min(m,n)}\sigma_j(A)=|A|</em>* \text{ (Frobenius norm invariant to rotation)}<br>      \end{align}<br>$$</p><ul><li><p>what is the purpose of using nuclear norm here?</p><ul><li>to relax the rank constraint from a non-convex space to a convex space.</li></ul></li><li><p>what benefit does nuclear norm bring to us?</p><ul><li><p>we can reconstruct the original non-convex problem. In fact, there are several ways to reconstruct the problem:</p><ul><li>Exact reconstruction by virtue of Boolean matrix $G$: </li></ul></li></ul></li></ul><p>$$<br>      \min_B|B|_*, s.t. |A-B|_G=0<br>$$</p><ul><li>Approximate reconstruction. Directly relaxing the rank constraint, it enlarges the possible solution space</li></ul><p>$$<br>\min_B|A-B|_G, s.t. |B|_\ast\leq r<br>$$</p><ul><li>Lagrange Formulation</li></ul><p>$$<br>\min_B[\frac{1}{2\tau}|A-B|_G^2 + |B|_\ast]<br>$$</p><h2 id="SVD-Shrinkage-Iterations"><a href="#SVD-Shrinkage-Iterations" class="headerlink" title="SVD Shrinkage Iterations"></a>SVD Shrinkage Iterations</h2><p>$$<br>B_{t+1} = B_t+\eta_t\Pi(A-\text{shrink}_\tau(B_t))<br>$$</p><ul><li><p>what is the basic idea of this method?</p><ul><li>It wants to <ul><li>find a matrix with low Frobenius norm and nuclear norm  $B^*=\arg\min_B[\frac{1}{2\tau}|B|_F^2+|B|_\ast]$​</li><li>while keeping the observed ones being the same. Keep attention to that  $s.t. \Pi(A-B)=0$</li></ul></li><li>include a shrinkage operator</li></ul></li></ul><p>$$<br>B^\ast = \text{shrink}_\tau(A):=\arg\min_B{\frac{1}{2}|A-B|_F^2+\tau|B|_\ast}<br>$$</p><ul><li><p>The solution is  $B^*=UD_\tau V^\top, D_\tau=\text{diag}(\max{0,\sigma_i-\tau})$<br>This substracts a little from the big singular values and make the small ones as 0. </p></li><li><p>iteratively update the $B$.</p></li><li><p>get the limitation of the shrinkage of $B_t$, which is $B^*$ we want.</p></li><li><p>where is this method better than others?</p><ul><li>it constraints the combination of the two norms: Frobenius norm and nuclear norm.</li></ul></li><li><p>how to guarantee the sparsity?</p><ul><li>using the projection. Because the first $B_1$ only has entries on the observed locations, and each time we add a new matrix projected by the Pi, so all the $B$ matrices are sparse and only have entries on the observed locations.</li></ul></li></ul><h2 id="Exact-Matrix-Recovery"><a href="#Exact-Matrix-Recovery" class="headerlink" title="Exact Matrix Recovery"></a>Exact Matrix Recovery</h2><p>This method is more <strong>statistical</strong>.</p><p>$$<br>\min_X\text{rank}(X), s.t. |A-B|_I = 0<br>$$</p><p>The rank function is not convex, also the constraint is very stringent. Therefore, it is a difficult problem.</p><p>Solutions:</p><ul><li><p>using nuclear norm to replace the rank as objective,</p><ul><li>which is not only convex,</li><li>but the largest convex function less than rank (the best)</li></ul></li><li><p>How many entries do we need to guess others? Certain number of known entries reveal the probability of get the right ideal of the whole matrix. The number is almost <strong>linear</strong> to $n$, assuming $m$ is closed to $n$. </p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CIL1 Linear Autoencoder</title>
      <link href="/cil-1la/"/>
      <url>/cil-1la/</url>
      
        <content type="html"><![CDATA[<h1 id="Pre-Questions"><a href="#Pre-Questions" class="headerlink" title="Pre-Questions"></a>Pre-Questions</h1><ol><li><em>What?</em> The framework of linear matrix low rank construction</li><li><em>Problem?</em> To approximate a matrix with low-rank matrix. This is an encoding problem.</li><li><em>Key?</em> Find the encoder $C$ and decoder $D$.</li><li>Formula? $Z = CX, X’ = DZ=DCX$</li><li>Applications? feature engineering, saving storage space.</li><li>Further Development? Non-linear? Supervized, not auto?</li></ol><ul><li>Dimension Reduction</li><li>Linear Autoencoder</li><li>Singular Value Decomposition</li><li>Remarks</li></ul><h1 id="Dimension-Reduction"><a href="#Dimension-Reduction" class="headerlink" title="Dimension Reduction"></a>Dimension Reduction</h1><ul><li><em>Object?</em> A matrix or a data point? what kinds of conditions should this matrix satisfy?<ul><li>A matrix, a series of data points. The data points have the same length (dimension)</li></ul></li><li>How to deal with missing values?<ul><li>delete the data points</li><li>fill up with random values</li></ul></li><li>Methods: select or reconstruct?<ul><li>both, but in linear encoding reconstruction can only be in the <strong>linear</strong> form.</li></ul></li><li>Algorithms? Efficiency?<ul><li>iterative method</li></ul></li><li>Evaluation? what index is used to evaluate the dimension reduction?<ul><li>evaluate the <strong>distance</strong> between matrices before and after encoding. <ul><li>SVD is the best under Frobenius/Euclidean Norm.</li><li>PCA is the best under the Euclidean distance.</li></ul></li></ul></li></ul><p>In general, this is an encoding problem, use less bit to encode the original information while keep the information loss as little as possible.</p><h2 id="Aim"><a href="#Aim" class="headerlink" title="Aim"></a>Aim</h2><p>Work for a group of data points with the same dimension, not for only one data point.</p><h3 id="Mathematical-Description"><a href="#Mathematical-Description" class="headerlink" title="Mathematical Description"></a>Mathematical Description</h3><p>$$<br>\mathbb{R}^{N\times M}\Rightarrow \mathbb{R}^{N\times K}<br>$$</p><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>The methods should be selected according to the to-encode objects.</p><h3 id="Change-Basis-Space"><a href="#Change-Basis-Space" class="headerlink" title="Change Basis/Space"></a>Change Basis/Space</h3><p>The original vector is expressed on one set of units, change the expression units, and express the vector by new units. Take picture for an example, a $100\times 100$ head photo, the original unit is pixel, now we change the units as four layers, a fixed head, the hair contour, part highlight one and part highlight two. Therefore a $100\times 100$ vector in the original space is expressed by $1\times 4$ vector in new space.<br>In another word, the new basis may save a lot of information for the data. Problem: the data points must be similar in some way to make basis useful. </p><h3 id="Linear"><a href="#Linear" class="headerlink" title="Linear"></a>Linear</h3><p>$$<br>Z=C\cdot X, C\in\mathbb{R}^{K\times M}<br>$$</p><h3 id="Non-linear"><a href="#Non-linear" class="headerlink" title="Non-linear"></a>Non-linear</h3><ul><li>what is the limitation and advantage of linear?</li><li>what typical techniques in non-linear form?</li></ul><h3 id="Unsupervised"><a href="#Unsupervised" class="headerlink" title="Unsupervised"></a>Unsupervised</h3><ul><li><p>how to do it?</p><p>That is the source of <strong>auto</strong> of in the name of linear autoencoder.</p></li></ul><h1 id="Linear-Autoencoder"><a href="#Linear-Autoencoder" class="headerlink" title="Linear Autoencoder"></a>Linear Autoencoder</h1><p>Find a decoder matrix $D$ working on $Z$, which makes $DZ$ as close as possible to $X$.</p><h2 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h2><ol><li><p>$$<br>Z=C\cdot X<br>$$</p></li><li><p>$$<br>X’ = D\cdot Z = D\cdot C\cdot X<br>$$</p></li><li><p>Choose $D$ and $C$ to make $X’$ closed to $X$.</p></li></ol><h2 id="Norms"><a href="#Norms" class="headerlink" title="Norms"></a>Norms</h2><p>There are many norms to evaluate how $X’$ is closed to $X$. In the slides, we use Frobenius Norm. </p><ul><li>How about using other norms? </li><li>What is best solution under other norms?</li></ul><h3 id="Frobenius-Norm"><a href="#Frobenius-Norm" class="headerlink" title="Frobenius Norm"></a>Frobenius Norm</h3><ul><li><p>vector: like the traditional norm definition</p></li><li><p>matrix:  generate the definition of vector, the squared root of the sum of the square of each entry.  </p><ul><li><p>In a calculation format $\sqrt{\sum_{ij}a_{ij}^2} = \sqrt{\sum_i \sigma_i^2}$</p></li><li><p>in a matrix format, depends only on singular values of $A$.</p></li></ul><p>$$<br>  |A|_F^2 = \text{trace}(A^* A) = \text{trace}(AA^*)=\sum_i \sigma_i^2<br>$$</p></li></ul><h3 id="p-norm"><a href="#p-norm" class="headerlink" title="p-norm"></a>p-norm</h3><p>$$<br>|A|_p:=\sup{|Ax|_p: |x|_p = 1}, |x|_p:=(\sum_i|x_i|^p)^{1/p}<br>$$</p><h3 id="Spectral-norm-the-matrix-version-of-Euclidean-norm"><a href="#Spectral-norm-the-matrix-version-of-Euclidean-norm" class="headerlink" title="Spectral norm (the matrix version of Euclidean norm)"></a>Spectral norm (the matrix version of Euclidean norm)</h3><p>That is 2-norm, when $p$ is 2.<br>$$<br>|A|_2:=\sup{|Ax|_2:|x|_2=1}=\sigma_1 = \sqrt{\lambda_\max(AA^\top)}<br>$$</p><ul><li>$\sigma$ refers to the singular value.</li></ul><h2 id="Key-Theorem-Eckart-Young-Theorem"><a href="#Key-Theorem-Eckart-Young-Theorem" class="headerlink" title="Key Theorem: Eckart-Young Theorem"></a>Key Theorem: Eckart-Young Theorem</h2><ul><li><p><strong>SVD</strong> is the best approximation matrix with the rank $k$, under the Frobenius Norm (also under the Euclidean norm)</p></li><li><p>the minimum Frobenius (Euclidean) norm loss is the sum of square of singular values from $k+1$.<br>$$<br>J(\theta)=\sum_{l=k+1}\sigma_l^2<br>$$</p></li></ul><h2 id="Singular-Vector-Decomposition"><a href="#Singular-Vector-Decomposition" class="headerlink" title="Singular Vector Decomposition"></a>Singular Vector Decomposition</h2><p>Linear Autoencoder provides a framework, and SVD is one method to get the $D$ and $C$. In SVD, $D = U_k$ and $C=U_k^\top$ . To use SVD, the future to-be-predicted items must have been included in the matrix. No on-the-fly new prediction or no new data points can be added just for prediction, but not being trained.</p><p><strong>Any matrix</strong> can do SVD.</p><h3 id="Formula"><a href="#Formula" class="headerlink" title="Formula"></a>Formula</h3><p>$$<br>X = U\cdot D\cdot V^\top<br>$$</p><ul><li>$U$: orthogonal matrix</li><li>$V$: orthogonal matrix</li><li>$D$: diagonal matrix</li></ul><h3 id="Interpretation"><a href="#Interpretation" class="headerlink" title="Interpretation"></a>Interpretation</h3><ul><li>$U: M\times M$​​, map the $M$​​ objects to $M$​​ classes, the entry $U_{ij}$​​ is the object $i$​​ ‘s value on class $j$​​. </li></ul><ul><li><p>$V: N\times N$​​, map the $N$​​ objects to $N$​​ classes, the entry $V_{ij}$​​ is the object $i$​​ ‘s value on class $j$​​</p></li><li><p>$D: D_{ii}$ express the strength or expression ability of the class $i$ or the strength of each factor.</p></li></ul><h3 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h3><p>Stochastic gradient descending method.</p><ul><li>why to use this method? Any problem of solving the SVD directly?<ul><li>it is used for CF. It optimizes only <strong>over known ratings</strong> (no need to input missing values). It tries to find low rank approximation $Q$ and $P$ for $X$, let<br>$$<br>X=Q\cdot P, X\in\mathbb{R}^{M\times N}, Q\in\mathbb{R}^{M\times K}, P\in\mathbb{R}^{K\times N}<br>$$</li></ul></li></ul><h3 id="Relationships"><a href="#Relationships" class="headerlink" title="Relationships"></a>Relationships</h3><ul><li><p>to linear autoencoder: $C = U_k^\top, D=U_k$ or $C=AU_k^\top, D=U_kA^{-1}$</p></li><li><p>SGD UV forms to the original UDV forms</p><h2 id="Principle-Component-Analysis"><a href="#Principle-Component-Analysis" class="headerlink" title="Principle Component Analysis"></a>Principle Component Analysis</h2></li><li><p>why we use PCA?</p><ul><li>compared to SVD, which aims to minimize the **norm (Frobenius/Euclidean) ** of the whole <strong>difference matrix</strong>  $X-X’$ directly, PCA focuses on the “inner structure” of the matrix $X$, trying to consume the <strong>variance</strong> among $x_i$’s as large as possible.</li></ul></li><li><p>what is the advantage of PCA? </p></li><li><p>what is the basic idea of PCA?</p><ul><li>works on the <strong>variance matrix</strong> $AA^\top\in\mathbb{R}^{M\times M}$, not the original matrix $A\in\mathbb{R}^{M\times N}$.</li><li>minimize <strong>Euclidean distance</strong></li><li>in other words, we want to find the direction where the variance is at the biggest (Therefore, this direction captures the change of the data at most, the data vary less on other directions.)</li><li>important <strong>!!!</strong>: direction of <strong>smallest reconstruction error</strong> &lt;-&gt; direction of <strong>largest data variance</strong> </li></ul></li><li><p>what is relation to the <strong>orthogonal projection</strong>?</p><ul><li>orthogonal projection corresponds to <strong>euclidean</strong> distance, which is the minimization goal of PCA.</li><li>the <strong>eigenvalue</strong> can be interpreted as the <strong>variance</strong> in the dimension specified by the corresponding eigenvector.</li></ul></li></ul><h3 id="Key-Formula"><a href="#Key-Formula" class="headerlink" title="Key Formula"></a>Key Formula</h3><ul><li><p>$&lt;v,u&gt;u=(uu^\top)v$,  means the projection of $v$ to the direction $u$.</p></li><li><p>$(I-uu^\top)v=v-&lt;v,u&gt;u$ means the orthogonal branch of $v$ to $u$.</p></li><li><p>Goal: find<br>  $$<br>  (u,\mu)\to\arg\min[\frac{1}{n}\sum_{i=1}^n]|(I-uu^\top)(x_i-\mu)|^2<br>  $$</p><ol><li>it is easy to get $\mu=\frac{\sum_i x_i}{n}$, that means <strong>to use PCA, we should center the data</strong></li><li>the goal becomes:<br>$$<br>u: \arg\min[\frac{1}{n}\sum_{i=1}^n |(I-uu^\top)x_i’|^2], x_i’=x_i-\frac{1}{n}\sum_{j=1}x_j<br>$$</li><li>Helper formula:<br>$$<br>|v-w|^2 = &lt;v-w, v-w&gt;=|v|^2+|w|^2-2&lt;v,w&gt;<br>$$</li><li>$$\to |I-(uu^\top)x_i|^2=|x_i - uu^\top x_i|^2=|x_i|^2 + |uu\top x_i|^2-2&lt;x_i,uu\top x_i&gt;=x_i^\top x_i+(u^\top u-2)x_i^\top uu^\top x_i$$​</li><li>$$<br>u:\arg\min\frac{1}{n}\sum_{i=1}^n x_ix_i^\top + \frac{1}{n}\sum_{i=1}^n(u^\top u-2)u^\top x_ix_i^\top u<br>$$</li><li>Add the <strong>norm constraint</strong>, </li><li>$$<br>|u|=1, u=\arg\max\frac{1}{n}\sum_{i=1}^nu^\top x_ix_i^\top u=\frac{1}{n}u^\top XX^\top u, X\in\mathbb{R}^{k\times n}<br>$$</li><li>using Lagrange inequation to solve this optimization problem $L(u,\lambda)=u^\top\Sigma u+\lambda&lt;u,u&gt;, \Sigma\in\mathbb{R}^{k\times k}$, we get $\Sigma u = \lambda u$</li></ol></li></ul><h3 id="Calculation"><a href="#Calculation" class="headerlink" title="Calculation"></a>Calculation</h3><ul><li><p>why does it correspond to the eigen-value/vector?</p><ul><li>from the solution process of Lagrange constraint. </li></ul></li><li><p>what is the influence of the magnitude of eigenvalue?</p><ul><li>in the goal:<br>  $$<br>\frac{1}{n}\sum_{i=1}^n|(I-uu^\top)x_i|^2=\frac{1}{n}\sum_{i=1}^n x_ix_i^\top-\frac{1}{n}u^\top XX^\top u=\frac{1}{n}\sum_{i=1}^n x_ix_i^\top-\frac{\lambda}{n}<br>$$</li><li>so, the larger the eigenvalue is, the smaller the goal will be. Also, since all the eigenvalues are non-negative, this goal will become smaller and smaller with more eigenvalues included.</li></ul></li><li><p>is it expensive to do PCA decomposition?</p></li><li><p>The reconstruction error (using Frobenius norm) of PCA $err=\sum_{i=K+1}^M\lambda_i$​ </p><p>Proof:<br>$$<br>\begin{align}</p><p> err &amp; = \frac{1}{N}|\tilde{\bar{X}} - \bar{X}|<em>F^2 = \frac{1}{N}|(U_KU_K^\top - I_d)\bar{X}|<em>F^2\<br>&amp; =\frac{1}{N}\text{trace}[(U_KU_K^\top - I_d)\cdot \bar{X}\bar{X}^\top \cdot (U_K U_K^\top - I_d)^\top] \<br>&amp; = \text{trace}[(U_KU_K^\top - I_d)\cdot \Sigma \cdot (U_K U_K^\top - I_d)]\<br>&amp; = \text{trace}[(U_KU_K^\top - I_d)\cdot U\Lambda U^\top \cdot (U_K U_K^\top - I_d)] \<br>&amp; = \text{trace}[(U_KU_K^\top U - U)\cdot \Lambda \cdot (U^\top U_K U_K^\top - U^\top)] \<br>&amp; = \text{trace}[([U_K; 0] - U)\Lambda([U_K; 0] - U)^\top] \<br>&amp; = \text{trace}(\sum</em>{i=K+1}^D \lambda_i u_i u_i^\top) = \sum</em>{i=K+1}^D \lambda_i\cdot \text{trace}(u_i u_i^\top)\<br>&amp; \overset{\text{unit norm}}{=}\sum_{i=K+1}^D \lambda_i<br>\end{align}<br>$$</p><h3 id="Iterative-View"><a href="#Iterative-View" class="headerlink" title="Iterative View"></a>Iterative View</h3></li></ul><p>This view provides a method to calculate the main direction once at a time, then remove this direction to find the second best direction.</p><ul><li>why the 1st principle eigenvalue of the residual variance matrix is the 2nd principle eigenvalue of the original variance matrix?<ul><li>think of the diagonal format of the matrix, cut the first diagonal entry from the diagonal matrix, the left diagonal matrix corresponds to that of the residual variance matrix. Therefore, the biggest of this new matrix is the “second” (also, could be the same) of the old one.</li></ul></li></ul><h3 id="Matrix-View"><a href="#Matrix-View" class="headerlink" title="Matrix View"></a>Matrix View</h3><p>This view gives the mathematical proof and solution of the problem, but not says how to do the calculation, which may cost a lot.</p><ul><li>are all the eigen-vectors orthogonal to each other?<ul><li>Yes. The orthogonality comes from two part:</li></ul><ol><li>the eigen-vectors with different eigen-values, a <strong>theorem</strong> guarantees they are orthogonal. <em>Theorem</em>: Distinct eigenvalues of <strong>symmetric</strong> matrices have orthogonal eigenvectors. </li><li>the eigen-vectors with the same eigen-value, you can always <strong>do orthogonalization</strong> on them and make them orthogonal.</li></ol></li><li><strong>Spectral Theorem</strong> guarantees the <strong>orthogonal decomposition</strong> for <strong>symmetric</strong> matrix. Matrix is <strong>diagonalizable</strong> by an <strong>orthogonal matrix</strong> if and only if it is <strong>symmetric</strong>. </li></ul><h3 id="relationships"><a href="#relationships" class="headerlink" title="relationships"></a>relationships</h3><ul><li><p>to linear autoencoder: $C=U_k^\top\in\mathbb{R}^{k\times m}, D=U_k\in\mathbb{R}^{m\times k}$,  If all eigenvalues are different, PCA is <strong>unique and interpretable !!</strong></p></li><li><p>from SVD: </p><ul><li><p>Variance matrix:<br>$$<br>A=UDV^\top,\Sigma=AA^\top=UDV^\top VD^\top U^\top=UD^2U^\top=U\Gamma U^\top, \Sigma\in\mathbb{R}^{k\times k}<br>$$</p></li><li><p>Similarity matrix: $A^\top A=V\Lambda V^\top\in\mathbb{R}^{n\times n}$</p></li></ul></li><li><p>to SVD:</p><ul><li><strong>U</strong>: eigenvectors of  $AA^\top$</li><li><strong>V</strong>: eigenvectors of $A^\top A$ <h3 id="Solution-Algorithm"><a href="#Solution-Algorithm" class="headerlink" title="Solution Algorithm"></a>Solution Algorithm</h3></li></ul></li><li><p>power method (for iterative view):</p><ul><li><p>$$<br>v_{t+1}=\frac{Av_t}{|Av_t|},\lim_{t\to\infty}v_t=u_1<br>$$</p></li><li><p>constraint: $&lt;u_1,v_0&gt;\neq 0,\lambda_1&gt;\lambda_j, \forall j&gt;1$ </p></li></ul></li><li><p>from SVD (for matrix view): good for mid-sized problems.</p></li></ul><h3 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h3><ol><li><p>Calculate the empirical mean $\bar{x}=\frac{\sum_{n=1}^N x_n}{N}$.</p></li><li><p>Center the data $\bar{X}=X-M$.</p></li><li><p>Compute the covariance matrix $\Sigma=\frac{1}{N}\bar{X}\bar{X}^\top$</p><p>The difference between the covariance matrix of the $XX^\top$  and  that of $\bar{X}\bar{X}^\top$is<br>$$<br>\bar{X}\bar{X}^\top = XX^\top - MX^\top<br>$$</p></li><li><p>Eigenvalue Decomposition.</p></li><li><p>Model Selection, pick $K\leq D$  and keep the projections associated with the top  $K$ eigenvalues. </p></li><li><p>Transform the data onto the new basis of $K$ dimensions.<br>$$<br>\bar{Z}=U_K^\top\bar{X}<br>$$</p></li><li><p>Reconstruction.</p><ol><li>$\tilde{\bar{X}}=U_K\bar{Z}$​</li><li>$\tilde{X}=\tilde{\bar{X}}+M$</li></ol></li></ol>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Big Data course notes</title>
      <link href="/bd-0course-notes/"/>
      <url>/bd-0course-notes/</url>
      
        <content type="html"><![CDATA[<p>I took the course Big Data in the autumen semester 2018, opened by <a href="http://people.inf.ethz.ch/gfourny/">Dr. Ghislain Fourny</a>, Department Information ETH Zurich. </p><h1 id="Content"><a href="#Content" class="headerlink" title="Content"></a>Content</h1><p>From the course introduction</p><blockquote><p>This course gives an overview of database technologies and of the most  important database design principles that lay the foundations of the Big Data universe. The material is organized along three axes: data in the  large, data in the small, data in the very small.  A broad range of  aspects is covered with a focus on how they fit all together in the big  picture of the Big Data ecosystem.</p></blockquote><ul><li>physical storage: distributed file systems <em>HDFS</em>, object storage <em>S3</em>, key - value stores</li><li>logical storage: document stores <em>MongoDB</em>, column stores <em>HBase</em>, graph databases <em>neo4j</em>, data warehouses <em>ROLAP</em></li><li>data formats and syntaxes <em>XML, JSON, RDF, Turtle, CSV, XBRL, YAML, protocol buffers, Avro</em></li><li>data shapes and models: tables, trees, graphs, cubes</li><li>type systems and schemas: atomic types, structured types :arrays, maps, set - based type systems  ?, * , +</li><li>an overview of functional, declarative programming languages across data shapes <em>SQL, XQuery, JSONiq, Cypher, MDX</em></li><li>the most important query paradigms: selection, projection, joining, grouping, ordering, windowing</li><li>paradigms for parallel processing, two-stage <em>MapReduce</em> and DAG-based <em>Spark</em></li><li>resource management <em>YARN</em></li><li>what a data center is made of and why it matters: racks, nodes, …</li><li>underlying architectures: internal machinery of HDFS, HBase, Spark, neo4j</li><li>optimization techniques: functional and declarative paradigms, query plans, rewrites, indexing</li><li>applications.</li></ul><p>I happened to found all the course videos are avaiable on <a href="https://www.youtube.com/watch?v=4t6BR_fzLR4&amp;list=PLs5KPrcFtb0UHTl_gXR_EYW28m9pD8iYN">YouTube</a>. Take it for free!</p><h1 id="Experience"><a href="#Experience" class="headerlink" title="Experience"></a>Experience</h1><p>From my own experience, this course is very system-style. I didn’t have a strong background on this and made a lot of efforts to learn this course. The lecturer gives many recommended readings almost for each lesson. Reading them benefited me a lot while reading all of them was impossible <span class="github-emoji"><span>😂</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f602.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>. Fortunately, the contents are not very difficult to understant but the course volume is quite big. Almost every week we were exposed to a different technology with many tools, regulations, applications and details. The final exam was more like an Encyclopedia knowledge contest, full of knowledge. Each piece of knowledge was not hard to memorize but the point was there were too much! Frankly speaking, this course is very useful in the practical as well as industrial fields. I have learnt a lot from it. </p><p>I gonna share my course notes here as well as extra reading notes. Enjoy!</p><h1 id="Notes-Content"><a href="#Notes-Content" class="headerlink" title="Notes Content"></a>Notes Content</h1><p><a href="../BD-1Intro/index.html">Introduction</a></p><p><a href="../BD-2DBBasics/index.html">Database Basics</a></p><p> <a href="../BD-3Storage/index.html">Storage</a></p><p><a href="../BD-4FileSystem/index.html">File System</a></p><p><a href="../BD-5ColumnStore/index.html">Wide Columne Store</a></p><p><a href="../BD-6MapReduce/index.html">MapReduce</a></p><p><a href="../BD-7YARN/index.html">YARN</a></p><p><a href="../BD-8Spark/index.html">Spark</a></p><p><a href="../BD-9PerformancLargeScale/index.html">Performance at large scale</a></p><p><a href="../BD-10Syntax/index.html">Syntax</a></p><p><a href="../BD-11DataModel/index.html">Data Model</a></p><p><a href="../BD-12Querying/index.html">Querying</a></p><p><a href="../BD-13DocumentStores/index.html">Document Stores</a></p><p><a href="../BD-15Datawarehousing/index.html">Data Warehousing</a></p>]]></content>
      
      
      <categories>
          
          <category> Sharing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BD13 Document Stores</title>
      <link href="/bd-13documentstores/"/>
      <url>/bd-13documentstores/</url>
      
        <content type="html"><![CDATA[<p>Document stores don’t like joins. </p><h1 id="How-can-we-rebuild-the-stack-with-XML-JSON"><a href="#How-can-we-rebuild-the-stack-with-XML-JSON" class="headerlink" title="How can we rebuild the stack with XML/JSON?"></a>How can we rebuild the stack with XML/JSON?</h1><ul><li>forced the trees into a table. (Schema-based shredding)</li><li>Store the tree by edge: each edge one row. It will be extremely slow to querying, because of plenty of joining.  </li><li>Overall, turning a tree into a table is not a good idea. They have different shapes.</li></ul><h1 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h1><ul><li><strong>validation</strong> after the data was populated, which is not possible in RDMS because RDMS even not allows you to store invalid data.</li><li>A <strong>huge</strong> collection (millions, billions, ..) of <strong>small</strong> trees. </li></ul><h2 id="ETL"><a href="#ETL" class="headerlink" title="ETL"></a>ETL</h2><p>Directly get data from some system, not ETL: <strong>extract, transform, load</strong>.  </p><ul><li>In SQL: the process: first create the table, design the schema, put the columns, put the domains, insert the values. Then, start querying it. Some products still first ETL, then query: MongoDB, Couchbase, Elasticsearch<h3 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison"></a>Comparison</h3>Think the time of reading data is fixed, and the querying time is variable. ETL first takse reading time, then it needs less querying time. But No ETL keeps reading data while querying, so the variable time is much larger</li></ul><h4 id="ETL-1"><a href="#ETL-1" class="headerlink" title="ETL"></a>ETL</h4><ul><li>takse time to load the data first</li><li>faster (querying time less)</li><li>update possible</li><li>proprietary formats</li></ul><h4 id="No-ETL"><a href="#No-ETL" class="headerlink" title="No ETL"></a>No ETL</h4><ul><li>no time lost in loading the data</li><li>slower (to query)</li><li>read-only</li><li>interoperable formats</li><li><h1 id="Abbreviation"><a href="#Abbreviation" class="headerlink" title="Abbreviation"></a>Abbreviation</h1>ETL: extract, transform, load<br>BSON: Binary-JSON </li></ul><h1 id="Indices"><a href="#Indices" class="headerlink" title="Indices"></a>Indices</h1><ul><li>Primary: _id  </li><li>secondary: other fields<h2 id="Hash-indices"><a href="#Hash-indices" class="headerlink" title="Hash indices"></a>Hash indices</h2><h3 id="limitation"><a href="#limitation" class="headerlink" title="limitation"></a>limitation</h3></li><li>no support for range queries</li><li>hash function not perfect in real life</li><li>space requirements for collision avoidance</li></ul><h2 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B Tree"></a>B Tree</h2><p>Different designs: values only on the leaves/on the all nodes, balanced or imbalanced. </p><h2 id="B-Tree-1"><a href="#B-Tree-1" class="headerlink" title="B+ Tree"></a>B+ Tree</h2><ul><li>we can have more children! Disks love block access.</li><li>actual values only at the leaves.</li><li>often have extra leaf pointers (from a leaf to the next leaf with adjacent father)</li><li>#children between <strong>d+1</strong> and <strong>2d+1</strong>, d is the max number of children of the non-leaf nodes. In another way, d is the number of keys. 2 keys mean 3 children.</li></ul><h3 id="Insertion"><a href="#Insertion" class="headerlink" title="Insertion"></a>Insertion</h3><p>Each row of nodes is less than 2d. If it is already 2d and one more node is inserted, the row will be splited into two parts: one with d+1 nodes, the other with d nodes, and generates a new father-node. </p><h3 id="Deletion"><a href="#Deletion" class="headerlink" title="Deletion"></a>Deletion</h3><p>When a row is deleted only left with one node, it will draw its parent down and merge with the other adjacent child row of its parent.</p><h2 id="Query"><a href="#Query" class="headerlink" title="Query"></a>Query</h2><ul><li>without indices: scan/filter in memory</li><li>with indices: prefilter with index, then scan/filter in memory.</li></ul><h2 id="Creation-Index"><a href="#Creation-Index" class="headerlink" title="Creation Index"></a>Creation Index</h2><ul><li>hash: <code>db.**.createIndex({"key":"hash"})</code></li><li>B-tree: <code>db.**.createIndex({"key":1})</code></li><li>compound:<code>db.**.createIndex({"key1":1,"key2":-1})</code> sort order. <strong>prefixes are implied</strong></li></ul><h1 id="Further-Reading"><a href="#Further-Reading" class="headerlink" title="Further Reading"></a>Further Reading</h1><p><a href="https://www.oreilly.com/library/view/mongodb-the-definitive/9781491954454/">MongoDB: The Definitive Guide, 3rd Edition</a> Chapter 3, 4, 5</p><p>My reading notes:</p><div class="row">    <embed src="13MongoDB.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BD14 Graph Database</title>
      <link href="/bd-14graphdb/"/>
      <url>/bd-14graphdb/</url>
      
        <content type="html"><![CDATA[<p>Graph Databases don’t like shards.</p><h1 id="Issues"><a href="#Issues" class="headerlink" title="Issues"></a>Issues</h1><ul><li>if using RDMS: the joins are really expensive, not efficient for relations. We often do <strong>traversal or reverse traversal</strong> in relations.</li><li> To solve that, we use <strong>index-free adjacency</strong></li></ul><h1 id="Ingredients"><a href="#Ingredients" class="headerlink" title="Ingredients"></a>Ingredients</h1><p>nodes, edges, properties, labels</p><h1 id="Graph-databases"><a href="#Graph-databases" class="headerlink" title="Graph databases"></a>Graph databases</h1><ul><li>property graph: Neo4j</li><li>triple stores(RDF): subject, property, object.</li></ul><h1 id="Abbreviation"><a href="#Abbreviation" class="headerlink" title="Abbreviation"></a>Abbreviation</h1><p>IRI: international resource identifier</p><h1 id="Syntax"><a href="#Syntax" class="headerlink" title="Syntax"></a>Syntax</h1><h2 id="RDF-XML"><a href="#RDF-XML" class="headerlink" title="RDF/XML"></a>RDF/XML</h2><ul><li>subject <code>&lt;rdf:Description rdf:about="subject-IRI"&gt;</code></li><li>property: within the subject tags: <code>&lt;rdf:...&gt; &lt;geo:property1&gt; ...&lt;/geo:property1&gt;&lt;/rdf:...&gt;</code></li><li>object: within the property tags: <code>&lt;geo:property1 rdf:resource="object-IRI"/&gt;</code> or <code>&lt;geo:property2&gt;object-value&lt;geo:property2&gt;</code><h2 id="JSON-LD"><a href="#JSON-LD" class="headerlink" title="JSON-LD"></a>JSON-LD</h2><code>{"@id":subject, "rdf:type":subject-type,"property1":"object1","property2":"object2"}</code><h2 id="Turtle"><a href="#Turtle" class="headerlink" title="Turtle"></a>Turtle</h2><code>@prefix sub:IRI. @prefix object:IRI. @prefix prop:IRI sub:self prop:sub-prop object:sub-obj ...</code></li></ul><h1 id="Querying"><a href="#Querying" class="headerlink" title="Querying"></a>Querying</h1><h2 id="Cypher"><a href="#Cypher" class="headerlink" title="Cypher"></a>Cypher</h2><p>Format: <code>(node1)-[:edge-label1]-&gt;(node2)-[:edge-label2]&lt;-(node3)</code>  </p><ul><li>anchoring a label: <code>(node1:label1)</code>  </li><li>filtering a property: <code>(node1 {prop-key: 'prop-value'}</code>  </li><li>combining:  <code>(node1: label1 {prop-key: 'prop-value'}</code>  </li><li>variable repetition: <code>(node1)-[:edge-label1]-&gt;(node2)-[:edge-label2]-&gt;(node1)</code>   </li><li>variable length path: <code>(alpha)-[*1..4]-&gt;(beta)</code>  </li><li>MATCH clause: <code>MATCH (one-query) (WHERE CONDIONS) RETURN gamma</code>  </li><li>CREATE clause: use , to seperate <code>CREATE (),(),()</code></li></ul><h2 id="SPARQL"><a href="#SPARQL" class="headerlink" title="SPARQL"></a>SPARQL</h2><h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><p><strong>No shards</strong><br>Master-slave: Master has the entire graph, in the slaves, only have copies. <strong>Data replication</strong> to avoid data loss(synchronization), to improve performance of scalability(everybody gets to connect to master/slave). </p><h2 id="Write"><a href="#Write" class="headerlink" title="Write"></a>Write</h2><p>how to guarantee the consistency?  </p><ul><li>write to the master</li><li>or to a slave. It is blocked until it makes sure that the master is up-to-date.</li></ul><h2 id="Hardware"><a href="#Hardware" class="headerlink" title="Hardware"></a>Hardware</h2><p>Fixed-size records: serialize the nodes/edges/labels/properties.   </p><ul><li>properties storage: save key-value pairs  </li><li>relationship storage: <ul><li>double links for free iteration</li><li>from an edge view: a pointer to the source(target) node, a pointer to the s/t-previous edge, a pointer to the s/t-next edge.</li></ul></li><li>typical size:  <ul><li>node: 9 bytes</li><li>relationship: 33 bytes</li><li>relationship name: 5 bytes</li><li>property: 33 bytes</li></ul></li></ul><h1 id="Further-Reading"><a href="#Further-Reading" class="headerlink" title="Further Reading"></a>Further Reading</h1><p><a href="https://www.oreilly.com/library/view/graph-databases-2nd/9781491930885/">Graph Databases, 2nd Edition</a> Chapter 1, 2, 3, 4, 6, </p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
            <tag> Graph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BD15 Data Warehousing</title>
      <link href="/bd-15datawarehousing/"/>
      <url>/bd-15datawarehousing/</url>
      
        <content type="html"><![CDATA[<h1 id="The-road-to-analytics"><a href="#The-road-to-analytics" class="headerlink" title="The road to analytics"></a>The road to analytics</h1><ul><li>OLTP: <ul><li>consistent and reliable record-keeping. </li><li>look at detailed individual records (small part of database)</li><li>lots of writes (thousands of people write together, like new customers registering)</li><li>fully interactive (&lt;1s)</li><li>value <strong>Consistency</strong>.</li></ul></li><li>OLAP: web analytics, sales analytics, management support.<ul><li>look at historical summarized consolidated data ( analysis over large part of database)</li><li>lots of reads (even not writing)</li><li>slow interactive, like MapReduce.</li><li>Redundancy, we denormalized everything. </li></ul></li></ul><h1 id="OLAP"><a href="#OLAP" class="headerlink" title="OLAP"></a>OLAP</h1><p>A dataware house is a <strong>subject-oriented, integrated, time-variant, nonvolatile</strong> collection of data in support of management’s <strong>decision-making</strong> process.  </p><ul><li>subject-oriented: customers, sales, products  </li><li>integrated: databases are in hundreds/thousands/or even more. Hard to join these isolated databases. When to analyze ,copy these databases from all over isolated machines in a single machine.</li><li>time-variant</li><li>non-volatile: copy without any update. </li></ul><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p>From different sources -&gt; ETL-&gt; get the derived data -&gt; analyze/report/mine.  </p><h2 id="Data-Model"><a href="#Data-Model" class="headerlink" title="Data Model"></a>Data Model</h2><h3 id="Cubes"><a href="#Cubes" class="headerlink" title="Cubes"></a>Cubes</h3><ul><li><strong>Dimensions</strong>: what the data looks like  </li><li>aggregation: the first thing we can do with data  </li><li>slicing:  take alongside the dimension</li><li>Dicer:  take all of the dimensions: what you want to look into details. Organize the rows and columns.  </li></ul><h2 id="ETHLing"><a href="#ETHLing" class="headerlink" title="ETHLing"></a>ETHLing</h2><ul><li>extract: triggers, gateways, log extraction</li><li>transform: derivation, value transformation, cleaning, filter, split, merge, join  </li><li>load: integrity constraints, sorting, build indices, partition</li></ul><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><ul><li>ROLAP: physically stored in RDMS. Fact table: one value in each row, with multi measure.  <strong>Star schema</strong>. snow-flake schema.</li><li>MOLAP: the physical layer would be the memory-order harddrive.</li></ul><h3 id="Query"><a href="#Query" class="headerlink" title="Query"></a>Query</h3><p>MDX(multi-dimensional expressions): the language for cubes. Actually, a lot of people use SQL to query cubes.  </p><p><strong>GROUPING SETS, ROLLUP, CUBE</strong>: ROLLUP: from left to right.</p><p>A cube is a list of dimensions indexing a list of measures.  </p><ul><li>hierarchies in dimensions: dimension values are organized in hierarchies. MDX does know this hierarchy.</li></ul><h3 id="Statements"><a href="#Statements" class="headerlink" title="Statements"></a>Statements</h3><ul><li>dicing: <code>SELECT DIM1 ON COLUMNS, DIM2 ON ROWS FROM ...</code></li><li>slicing: <code>WHERE</code><h3 id="Syntax-XBRL"><a href="#Syntax-XBRL" class="headerlink" title="Syntax: XBRL"></a>Syntax: XBRL</h3>based on XML  </li></ul><p>The feeling: XML schema can be used to describe graphs, cubes.</p><h1 id="Further-Reading"><a href="#Further-Reading" class="headerlink" title="Further Reading"></a>Further Reading</h1><p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwjh9oGooZ_yAhX-hf0HHXgKDiMQFnoECAQQAw&amp;url=https://people.inf.elte.hu/kiss/DB/ullman_the_complete_book.pdf&amp;usg=AOvVaw1WFUgTOmS2hu3L-bvD7T8U">Database Systems: The Complete Book 2nd Edition</a> Chapter 10.6, 10.7</p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
            <tag> Graph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BD10 Syntax</title>
      <link href="/bd-10syntax/"/>
      <url>/bd-10syntax/</url>
      
        <content type="html"><![CDATA[<h1 id="Use-case"><a href="#Use-case" class="headerlink" title="Use case"></a>Use case</h1><ul><li>Write-intensive: highly <strong>normalized</strong>: avoid update anomalies!</li><li>Read-intensive: highly <strong>denormalized</strong>: avoid joins!</li></ul><h1 id="Denormalizing-road"><a href="#Denormalizing-road" class="headerlink" title="Denormalizing road"></a>Denormalizing road</h1><ul><li>relational database: <strong>homogeneous</strong> collection of <strong>flat</strong> items</li><li>document store(<strong>semi-structured</strong>): <strong>heterogeneous</strong> collection of <strong>arborescent</strong> items.</li></ul><h1 id="Syntax"><a href="#Syntax" class="headerlink" title="Syntax"></a>Syntax</h1><p>One syntax defines a language. If a sentence is <strong>well-formed</strong>, it belongs to this language. Otherwise, it doesn’t.</p><h2 id="XML"><a href="#XML" class="headerlink" title="XML"></a>XML</h2><h3 id="Entities"><a href="#Entities" class="headerlink" title="Entities"></a>Entities</h3><ul><li>element, defined by <code>&lt;element-name&gt;...&lt;/element-name&gt;</code> or <code>&lt;element-name/&gt;</code></li><li>attribute: <ul><li><strong>only</strong> within the brackets, defined like <code>&lt;a attr="value"/&gt;</code>.</li><li>And <strong>only</strong> attributes can appear inside opening element tag. </li><li>two attributes <strong>cannot</strong> have the same name within a single element.</li></ul></li><li>text: <strong>only</strong> between the element tags, e.g. <code>&lt;a&gt;this is text&lt;/a&gt;</code>. <strong>cannot</strong> appear outside of elements.</li><li>comment: <code>&lt;!-- This is a comment --&gt;</code></li><li>processing instructoin: defined by <code>&lt;? ...?&gt;</code>,e.g.<code>&lt;?xml vesion="1.0"?&gt;</code></li><li>CDATA sections: appeared like the text, the format is <code>&lt;![CDATA[ ... ]]&gt;</code></li><li>Document Type: <code>&lt;!DOCTYPE document[(internal subset)]&gt;</code></li><li>(Internal) Entity declarations: <code>&lt;!ENTITY name "value"&gt;</code>, using <code>&amp;name;</code> to get the value.</li><li><strong>External parsed entities</strong>: conditions are relaxed <strong>???: text at top level, multiple elements.</strong>. Defined method: <code>&lt;!ENTITY name SYSTEM "path"&gt;</code></li><li><strong>???External unparsed entities</strong>: allows an entity to appear as the attribute’s value??</li><li></li></ul><h3 id="Entity-References"><a href="#Entity-References" class="headerlink" title="Entity References"></a>Entity References</h3><p>Five: <code>&amp;lt;</code>: &lt;, <code>&amp;gt;</code>: &gt;,  <code>&amp;apos;</code>: ‘, <code>&amp;quot;</code>: “, <code>&amp;amp;</code>: &amp;,  </p><h3 id="Character-References"><a href="#Character-References" class="headerlink" title="Character References"></a>Character References</h3><p>two formats: hex, beginning with <code>&amp;#x</code> and dec, beginning with <code>$#</code> </p><h3 id="Norms"><a href="#Norms" class="headerlink" title="Norms"></a>Norms</h3><h4 id="XML-valid-name"><a href="#XML-valid-name" class="headerlink" title="XML valid name"></a>XML valid name</h4><ul><li><code>a-z,A-Z, :, _</code> are allowed anywhere in a name</li><li><code>0-9, -, .</code> are allowed but not at start.</li><li>other ASCII characters are not allowed in XML names. </li></ul><h4 id="Whitespaces"><a href="#Whitespaces" class="headerlink" title="Whitespaces"></a>Whitespaces</h4><p>whitespace matters!<br>space: <code>#x20;</code>; tabs: <code>#x9;</code>; carriage return: <code>#xD;</code>; newlines: <code>#xA;</code><br>Carriage return is automatically replaced with newline before parsing.</p><p>if in an element declaring that <code>&lt;item xml:space="preserve"&gt;</code>: the space before its sub-elements will not be ignored. By default, such whitespaces are ignored.</p><h4 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h4><ul><li>prefix: anything, can be omitted.</li><li>local name</li><li>namespace, scope: this and within this element<br>using <code>xmlns:prefix-name:namespace</code> to define a prefix, and by <code>prefix:local-name</code> to use QName.<br>If the prefix is omitted, it will define a <strong>default namespace</strong> for this element (and its sub-elements).</li></ul><p>If no namespace is defined, all the elements are in <strong>no namespace</strong>. That means there is no default namespace without definition.  </p><p>Unprefixed attributes are in no namespace even if there is a default namespace in scope.</p><h4 id="Best-practice"><a href="#Best-practice" class="headerlink" title="Best practice"></a>Best practice</h4><ul><li>put all namespace bindings in root element</li><li>Try to keep the same bindings across all documents whenever possible!</li><li>use parsimoniously</li></ul><h2 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h2><h3 id="Elements"><a href="#Elements" class="headerlink" title="Elements"></a>Elements</h3><ul><li>string</li><li>number</li><li>null: Null is invalid.</li><li>boolean: true, false</li><li>array</li><li>object</li></ul><h3 id="Well-formedness"><a href="#Well-formedness" class="headerlink" title="Well-formedness"></a>Well-formedness</h3><h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p>XHTML, YAML (the “Python of JSON”), CSV(comma separated values)</p><h1 id="Further-Reading"><a href="#Further-Reading" class="headerlink" title="Further Reading"></a>Further Reading</h1><p><a href="https://www.oreilly.com/library/view/xml-in-a/0596007647/">XML in a Nutshell</a> Chapter 1, 2, 4, 9</p><p>Thanks Alessandro Stolfo for reading notes</p><div class="row">    <embed src="10-xml-syntax.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BD12 Querying</title>
      <link href="/bd-12querying/"/>
      <url>/bd-12querying/</url>
      
        <content type="html"><![CDATA[<h1 id="XML-Navigation"><a href="#XML-Navigation" class="headerlink" title="XML Navigation"></a>XML Navigation</h1><h2 id="Operator"><a href="#Operator" class="headerlink" title="Operator"></a>Operator</h2><ul><li>slash: <code>/</code></li><li>descendant axis : <code>//</code></li><li>attribute axis: <code>@attr-name</code></li><li>atomization: <code>data(...)</code></li><li>filter: <code>[]</code>, e.g.<code>@code[data(.)="CH"]</code></li><li>parent abbreviation: <code>/..</code></li><li>collections: <code>collection(...)</code><br>Use <code>.</code> to represent the current element</li></ul><h1 id="JSON-Navigation"><a href="#JSON-Navigation" class="headerlink" title="JSON Navigation"></a>JSON Navigation</h1><ul><li>using <code>.</code> as the slash in XML.</li><li><code>.countries</code> is different from <code>.countries[]</code>  </li><li>using <code>$$</code> to represent the current element.</li></ul><h1 id="Construction"><a href="#Construction" class="headerlink" title="Construction"></a>Construction</h1><ul><li>String Escaping<ul><li>JSONiq: using the backslash: <code>\",\n</code> to replace quote, spare space.</li><li>XQuery: using <code>&amp;quot;$#x000a;</code> …</li></ul></li><li>Booleans<ul><li>JSONiq: <code>true, false</code></li><li>XQuery: <code>true(), false()</code></li></ul></li></ul><h1 id="Basic-Operations"><a href="#Basic-Operations" class="headerlink" title="Basic Operations"></a>Basic Operations</h1><ul><li>Atomization: XML only: <code>&lt;a&gt;42&lt;/a&gt;+1=42+1=43</code></li><li>Empty sequence: <code>()+1=()</code></li><li>Cardinality: <code>(3,4)+2</code>: error</li><li>General Comparison: =,&lt;,&gt;,&gt;=,&lt;=, but all the types must be the same</li><li>Value Comparison: le,lt,eq, ne, ge, gt</li><li>logics: conjunction, disjunction, not</li><li>non-booleans<ul><li>false: <code>"", 0, ()</code></li><li>true: <code>"foo", 42, (&lt;foo/&gt;,&lt;bar/&gt;,1,"foo")</code><h1 id="Architecture-of-a-query-processing-engine"><a href="#Architecture-of-a-query-processing-engine" class="headerlink" title="Architecture of a query processing engine"></a>Architecture of a query processing engine</h1></li></ul></li></ul><ol><li>Parsing: from query to abstract syntax tree</li><li>translating: from AST to Expression tree</li><li>Optimization: Expression Tree</li><li>Code Generation: from Expression Tree to Iterator Tree</li></ol><h1 id="Further-Reading"><a href="#Further-Reading" class="headerlink" title="Further Reading"></a>Further Reading</h1><p><a href="https://www.oreilly.com/library/view/xquery-2nd-edition/9781491915080/">XQuery, 2nd Edition</a> Chapter 2, 3, 4, 6, 7, 10, 11, </p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BD7 YARN</title>
      <link href="/bd-7yarn/"/>
      <url>/bd-7yarn/</url>
      
        <content type="html"><![CDATA[<h1 id="JobTracker"><a href="#JobTracker" class="headerlink" title="JobTracker"></a>JobTracker</h1><h2 id="Responsibilities"><a href="#Responsibilities" class="headerlink" title="Responsibilities"></a>Responsibilities</h2><ul><li>Resource Management (<em>RM</em>)</li><li>Scheduling: like ten tasks per machine, who is in charge of reducing (<em>RM</em>)</li><li>Monitoring (<em>NM</em>)</li><li>Job lifecycle: if sth goes wrong/failure, it is to restart.</li><li>Fault-tolerance (<em>AM</em>): it must ensure that the job still goes well, if sth is wrong.</li></ul><h2 id="Issue"><a href="#Issue" class="headerlink" title="Issue"></a>Issue</h2><ol><li>Scalability: the typical version 1 mapreduce can have up to <strong>4,000 nodes</strong>, and up tp <strong>40,000</strong> tasks.</li><li>Bottleneck: only one JobTracker</li><li>Jack of all trades: (the JobTracker is too busy) for scheduling, monitoring and so on.</li><li>Utilization: the task slots are set before the job starts. They all have the same size, static, fixed-size.</li><li>Not fungible: the number of maps and reduces should be decided before the job starts. You may underestimate or overestimate.</li></ol><h1 id="YARN-version-2"><a href="#YARN-version-2" class="headerlink" title="YARN version 2"></a>YARN version 2</h1><p>yet another resource negotiator</p><ul><li>Resource Manager: scheduling, application management</li><li>Application Master: monitoring</li></ul><p>Different from Version 1:  </p><ul><li>separation between scheduling and monitoring  </li><li>scalability  </li><li>availability  </li><li>multi-tenancy</li></ul><p>Number: <strong>10,000</strong> nodes, compared to <strong>4,000</strong> nodes in version 1; <strong>100,000</strong> tasks, compared to <strong>40,000</strong> tasks in version 1.</p><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p>ResourceManager(Master ) -&gt; NodeManager (Slave), including many <strong>container</strong>.</p><p><a href="./pic/0701.png">the process of architecture</a></p><ol><li>client -&gt; ResoureManager: a job request</li><li>RM -&gt; one of NMs: the schedules and <strong>allocates an Application Master from containers</strong>.</li><li>AM -&gt; RM: resources needed. </li><li>RM -&gt; AM: allocated resources.</li><li>AM -&gt; Containers: start tasks, execute monitor</li></ol><h2 id="Resource-Manager"><a href="#Resource-Manager" class="headerlink" title="Resource Manager"></a>Resource Manager</h2><p>responsibilities: cluster utilization, capacity guarantees, fairness, SLAs<br>Pure scheduler, <strong>not</strong> monitor tasks, not restart upon failure, AM restarts that.</p><p>Communication with …  </p><ul><li>clients: client service, admin service: only for administrator.   </li><li>NMs: resource Tracker(how many? where?), liveliness, maintain the nodes list, (NM valid/invalid?)  </li><li>AMs (application masters): application master service(registration, container requests), liveliness, maintain the AM lists and waiting list of applications. There are several AMs at the same time.</li></ul><p>Authentication: using <strong>Token</strong></p><h3 id="Scheduling-strategies-pluggable-scheduler"><a href="#Scheduling-strategies-pluggable-scheduler" class="headerlink" title="Scheduling strategies: pluggable scheduler"></a>Scheduling strategies: pluggable scheduler</h3><ul><li>FIFO</li><li>capacity, the capacities of queues are given before.</li><li>Fair scheduler: steady fair share, instantaneous fair share.<br>How to compute allocations across <strong>multiple resources</strong>? </li><li>Dominant Resource Fairness: compute the dominant ratio of resource for each applications, and use this ratio as the reference to compute the final resource ratios. </li></ul><h4 id="Common-resoures"><a href="#Common-resoures" class="headerlink" title="Common resoures"></a>Common resoures</h4><p>memory (X GB), CPU (Y TB), disk ( W cores, U GHz), network (Z MBps)</p><h2 id="Node-Manager"><a href="#Node-Manager" class="headerlink" title="Node Manager"></a>Node Manager</h2><p>one <strong>per node</strong>.<br>Responsibilities: monitoring and report to RM. It packs resources to containers inside it.</p><h2 id="Application-Master"><a href="#Application-Master" class="headerlink" title="Application Master"></a>Application Master</h2><p>One <strong>per application</strong><br>Responsibilities: fault tolerance</p><p>AM-&gt; RM: negotiates resources<br>AM-&gt; NM: executes and <strong>monitors</strong>: monitors the containers and relaunch the failure ones.</p><h1 id="Abbreviation"><a href="#Abbreviation" class="headerlink" title="Abbreviation"></a>Abbreviation</h1><p>YARN</p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BD6 Map reduce</title>
      <link href="/bd-6mapreduce/"/>
      <url>/bd-6mapreduce/</url>
      
        <content type="html"><![CDATA[<h1 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h1><p>Input data(key-value pairs)  -&gt; split -&gt; Map -&gt; shuffle -&gt; Intermediate data(key-value pairs) -&gt;  reduce -&gt; output data (key-value pairs)</p><h2 id="Shuffle"><a href="#Shuffle" class="headerlink" title="Shuffle"></a>Shuffle</h2><ol><li>put all together</li><li>sort by key</li><li>partition<h1 id="Data-types"><a href="#Data-types" class="headerlink" title="Data types"></a>Data types</h1>it allows: (key type1, value type1)-&gt;(key typeI, value typeI)-&gt;(key typeA,value typeA)<br>most often: (key type1, value type1)-&gt;(key <strong>typeA</strong>, value typeA)-&gt;(key <strong>typeA</strong>,value typeA)  </li></ol><h1 id="Input-output-format"><a href="#Input-output-format" class="headerlink" title="Input/output format"></a>Input/output format</h1><p>table/files</p><ul><li>files: text-&gt;KeyValue-&gt;SequenceFile: Hadoop binary format, stores generic key-values (<code>(keylength, Key, ValueLength, Value)</code><h2 id="InputFormat-class"><a href="#InputFormat-class" class="headerlink" title="InputFormat class"></a>InputFormat class</h2></li><li>Table: DBInput Format (RDBMS), TableInputFormat(HBase);</li><li>FileInputFormat<ul><li>KeyValueTextInputFormat (key-value file)</li><li>SequenceFileInputFormat (Sequence file)</li><li>TextInputFormat</li><li>FixedLengthInputFormat (Text)</li><li>NLineInputFormat<h2 id="OutputFormat-Class"><a href="#OutputFormat-Class" class="headerlink" title="OutputFormat Class"></a>OutputFormat Class</h2></li></ul></li><li>Table: DBOutput Format (RDBMS), TableOutputFormat(HBase);</li><li>FileOutputFormat<ul><li>SequenceFileOutputFormat (Sequence file)</li><li>TextOutputFormat</li><li>MapFileOutputFormat<h1 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h1><h2 id="Combine"><a href="#Combine" class="headerlink" title="Combine"></a>Combine</h2>between map and shuffle. It reduces the amount of shuffling. Combine works on 90% cases. Usually, it is <strong>identical</strong> to reduce function. The <strong>identical</strong> conditions:  </li></ul></li></ul><ol><li>Key/Value types must be identical for reduce input and output.  </li><li>Reduce function must be <strong>commutative</strong> and <strong>associative</strong></li></ol><h1 id="The-Physical-Layer"><a href="#The-Physical-Layer" class="headerlink" title="The Physical Layer"></a>The Physical Layer</h1><p>Possible <strong>storage layer</strong>: Local Filesystem, HDFS, S3, Azure Blob storage<br>Numbers: several <strong>TBs</strong> of data, <strong>1000s</strong> of nodes  </p><h2 id="Infrastructure-version-1"><a href="#Infrastructure-version-1" class="headerlink" title="Infrastructure (version 1)"></a>Infrastructure (version 1)</h2><p>Namenode+JobTracker -&gt; DataNode+TaskTracker: which brings query to data. (Task: Map or Reduce)</p><h2 id="Splits"><a href="#Splits" class="headerlink" title="Splits"></a>Splits</h2><p>InputSplit is only a <strong>logical</strong> concept. An InputSplit may be stored in different blocks on the HDFS.</p><p>1 split = 1 map mask<br>In the physical layer: 1 split = 1 block (128MB), but in the approximation. One DN may have multiple splits to perform.<br>A split is a set of key-value. A block has the exact size, no matter with the content. That means, we may have a key-value pair cut into two blocks, maybe on different machines. <strong>Fine-tuning</strong> to adjust splits to blocks.</p><p>Version 1 and version 2 are two things.</p><h2 id="Shuffling"><a href="#Shuffling" class="headerlink" title="Shuffling"></a>Shuffling</h2><p>can start even before the map phase has finished.</p><h2 id="Reducing"><a href="#Reducing" class="headerlink" title="Reducing"></a>Reducing</h2><p>A reducer starts a new reduce task when the next key in the sorted input data is different than the previous.</p><p><strong>reducer</strong> is different from the <strong>reduce task</strong>. The user decide the number of reducers. Each partition is sent to a reducer. </p><h1 id="Issues"><a href="#Issues" class="headerlink" title="Issues"></a>Issues</h1><ol><li>tight coupling: co-located</li><li>scalability: only one JobTracker.</li></ol><h1 id="Data-locality"><a href="#Data-locality" class="headerlink" title="Data-locality"></a>Data-locality</h1><p>Data locality in MapReduce refers to the ability to move the computation close to where the actual data resides on the node, instead of moving large data to computation. </p><p>How to solve this? See the next chapter.</p><h1 id="Further-Reading"><a href="#Further-Reading" class="headerlink" title="Further Reading"></a>Further Reading</h1><p><a href="https://www.oreilly.com/library/view/hbase-the-definitive/9781449314682/">HBase: The Definitive Guide 1st ed.</a> Chapter 7</p><p><a href="https://www.oreilly.com/library/view/hadoop-the-definitive/9781491901687/">Hadoop: The Definitive Guide 4th ed. </a>Chapter 2, 6, 7, 8</p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BD8 Spark</title>
      <link href="/bd-8spark/"/>
      <url>/bd-8spark/</url>
      
        <content type="html"><![CDATA[<h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><p>It is for full-DAG query processing. Its first-class citizen: RDD.</p><p>8 nodes, 16 cores per node and 128 GB of memory per node.</p><h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><p>HDFS, S3 …<strong>creation</strong> -&gt;RDD, RDD -<strong>Transformation</strong>-&gt;RDD, RDD -<strong>action</strong>-&gt;on screen</p><h2 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h2><ul><li>lineage graph</li><li>lazy evaluation: each action triggers an evaluation</li></ul><h2 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h2><ul><li>on single RDD: filter, map, flatMap, distinct, sample (fraction+seed)</li><li>on two or more RDDs: union, intersection, subtract, cartesian product</li><li>on key-value pair RDDs: reduce <strong>by key</strong>, group <strong>by key</strong>, map values, keys, values, join, subtract by key<h2 id="Actions"><a href="#Actions" class="headerlink" title="Actions"></a>Actions</h2></li><li>collect, count, count by value, take, top, take ordered, take sample, reduce, fold, aggregate, for each  </li><li>on pair RDDs: count by key, lookup</li></ul><h2 id="Physical-layer"><a href="#Physical-layer" class="headerlink" title="Physical layer"></a>Physical layer</h2><p>parallel execution, optimization: avoid expensive network communication, stage.</p><h3 id="Stage"><a href="#Stage" class="headerlink" title="Stage"></a>Stage</h3><p>it is a sequence of parallelizable tasks performed on a single machine.</p><h4 id="Dependency"><a href="#Dependency" class="headerlink" title="Dependency"></a>Dependency</h4><ul><li>narrow dependency: stays on the same machine.</li><li>wide dependency: cannot have a single stage, need to shuffle around. Need the network. </li></ul><h3 id="General-DAG"><a href="#General-DAG" class="headerlink" title="General DAG"></a>General DAG</h3><p>partition the DAG into sub-graphs, which can be computed without the network communication.</p><h2 id="Performance-tuning"><a href="#Performance-tuning" class="headerlink" title="Performance tuning"></a>Performance tuning</h2><ul><li>persisting RDDs</li><li>avoiding a wide dependency: pre-partition according to the keys.</li></ul><h2 id="DataFrames"><a href="#DataFrames" class="headerlink" title="DataFrames"></a>DataFrames</h2><p>easy to do mutual transformation between <strong>RDD</strong> and <strong>DataFrame</strong>.</p><h1 id="Abbreviations"><a href="#Abbreviations" class="headerlink" title="Abbreviations"></a>Abbreviations</h1><p>DAG: directed acyclic graphs<br>RDD: resilient distributed dataset</p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BD9 Performance at large scale</title>
      <link href="/bd-9performanclargescale/"/>
      <url>/bd-9performanclargescale/</url>
      
        <content type="html"><![CDATA[<h1 id="Measurements"><a href="#Measurements" class="headerlink" title="Measurements"></a>Measurements</h1><p>Prefixes: </p><ul><li>mili: $m$, 0.001,3, </li><li>micro: $\mu$, 0.000 001, 6, </li><li>nano: $n$, 9, </li><li>pico: $p$, 12, </li><li>femto: $f$, 15, </li><li>atto: $a$, 18, </li><li>zepto: $z$, 21, </li><li>yocto: $y$, 24</li></ul><h2 id="Speedup"><a href="#Speedup" class="headerlink" title="Speedup"></a>Speedup</h2><ul><li>Amdahl’s law: SpeedUp= $\frac{1}{1-p+p/s}$. Constant problem size.  </li><li>Gustafson’s law: SpeedUp=$1-p+sp$. Constant computing power.</li></ul><h1 id="Tuning"><a href="#Tuning" class="headerlink" title="Tuning"></a>Tuning</h1><ul><li>scale out  </li><li>scale up: memory, disk, CPU, network … <strong>an easy but last resort</strong> </li><li>code:<ul><li>look for large <strong>loops</strong></li><li>avoid exception catching</li><li>avoid polymorphism</li><li>avoid virtual function</li><li>go low level if needed</li></ul></li><li>size of chunks: make the size smaller for liquidity, but not too much for latency issues.</li><li>storage format: syntax VS binary format</li><li>network usage: <ul><li>keep <strong>shuffling</strong> to a minimum</li><li>push down <strong>projection and selection</strong> as close as possible to the source.</li></ul></li><li>architecture</li></ul><h1 id="Tail-latency"><a href="#Tail-latency" class="headerlink" title="Tail latency"></a>Tail latency</h1><h2 id="Causes"><a href="#Causes" class="headerlink" title="Causes"></a>Causes</h2><p>sharing resources, queues, garbage collection, energy management…</p><h2 id="Improvements"><a href="#Improvements" class="headerlink" title="Improvements"></a>Improvements</h2><ul><li>keep the low-level queues short</li><li>break splits and queries further down</li><li>manage background activities</li><li>latency-induced probation: we shut down a machine that is too slow.</li><li>completely drop the last 0.01% that takes too long…</li><li>other measures<h3 id="Hedge-requests"><a href="#Hedge-requests" class="headerlink" title="Hedge requests"></a>Hedge requests</h3>basic idea: <strong>duplicate</strong></li></ul><p>task duplicates, first done wins.</p><h4 id="Deferred-hedge-request"><a href="#Deferred-hedge-request" class="headerlink" title="Deferred hedge request"></a>Deferred hedge request</h4><p>when 95% percentile reached, launch duplicate tasks.</p><h3 id="Tied-request"><a href="#Tied-request" class="headerlink" title="Tied request"></a>Tied request</h3><p>basic idea <strong>cancel request</strong>. A task is duplicated and waiting in several queues. Cancel other requests when one of them starts.</p><h1 id="Further-Reading"><a href="#Further-Reading" class="headerlink" title="Further Reading"></a>Further Reading</h1><p><a href="https://dl.acm.org/doi/10.1145/2723372.2742797">Spark SQL: Relational Data Processing in Spark</a></p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BD4 File system</title>
      <link href="/bd-4filesystem/"/>
      <url>/bd-4filesystem/</url>
      
        <content type="html"><![CDATA[<h1 id="Use-Cases"><a href="#Use-Cases" class="headerlink" title="Use Cases"></a>Use Cases</h1><ul><li><strong>Billions</strong> of <strong>TB</strong> files: the files are relatively small, but the amount is large  <ul><li>Object Storage (technology)</li><li>Key-value Model(model)</li></ul></li><li><strong>Millions</strong> of <strong>PB</strong> files: the files are large, but the amount is relatively small.<ul><li>block(file) storage (technology)</li><li>file system (model)</li></ul></li></ul><h1 id="GoogleFS-GFS"><a href="#GoogleFS-GFS" class="headerlink" title="GoogleFS (GFS)"></a>GoogleFS (GFS)</h1><p> It is the first DFS. It says there are some characteristic and requirements to be realized to design a DFS, which include: fault tolerance, file update model, performance requirements.</p><h2 id="Design-a-DFS"><a href="#Design-a-DFS" class="headerlink" title="Design a DFS"></a>Design a DFS</h2><h3 id="Fault-tolerance"><a href="#Fault-tolerance" class="headerlink" title="Fault tolerance"></a>Fault tolerance</h3><p>Even we know the nodes will fail, the system should continue to work. What to do to realize fault tolerance?</p><ol><li>Monitoring</li><li>Error Detection</li><li>Automatic Recovery<h3 id="File-update-model"><a href="#File-update-model" class="headerlink" title="File update model"></a>File update model</h3>There are two typical models can be used: random access and upsert/append only.<br>For <strong>GB</strong> size files, we choose <strong>append</strong>: immutable, not that flexible.<h3 id="Performance-requirements"><a href="#Performance-requirements" class="headerlink" title="Performance requirements"></a>Performance requirements</h3>Top priority <strong>throughput</strong>, secondary priority: latency.</li></ol><h1 id="The-Model-of-DFS"><a href="#The-Model-of-DFS" class="headerlink" title="The Model of DFS"></a>The Model of DFS</h1><h2 id="Logical-Layer"><a href="#Logical-Layer" class="headerlink" title="Logical Layer"></a>Logical Layer</h2><p>you can choose key-value model or file system</p><h2 id="Physical-Storage"><a href="#Physical-Storage" class="headerlink" title="Physical Storage"></a>Physical Storage</h2><p>Object Storage or Block Storage. The latter, what the hard driver actually does. Files are not stored continuously, but in blocks and achieved as blocks. The hard driver read blocks, not single bits. </p><h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><p>H means Hadoop. Initiated in 2006. Inspired by GFS(2003),  MapReduce (2004), and BigTable (2006).<br>Its primary features: 1. DFS, 2. MapReduce, 3. Wide Column Store(HBase).</p><h2 id="Blocks"><a href="#Blocks" class="headerlink" title="Blocks"></a>Blocks</h2><p>The reason to choose block:</p><ol><li>Files bigger than a disk</li><li>simpler level of abstraction</li></ol><h3 id="Size"><a href="#Size" class="headerlink" title="Size"></a>Size</h3><ul><li>The block in a single file system: <strong>4kb</strong></li><li>The block in Relational Database: <strong>4KB-32KB</strong></li><li>The block in DFS: <strong>64MB-128MB</strong></li></ul><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p>Master-Slave model.</p><ul><li>Master: Namenode</li><li>Slave: Datanode</li></ul><p>From a file view: the file is splited into 128MB chunks. Each chunk is replicated for several times. The chunks are stored in datanodes and the namenode knows where one part of a file is stored. If several clients want to read this file, they request to the namenode, and the namenode will return the files’ location from the datanodes, and the clients go to the corresponding datanode to read. </p><h3 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h3><h4 id="Functions-all-system-side-activity"><a href="#Functions-all-system-side-activity" class="headerlink" title="Functions: all system-side activity"></a>Functions: all system-side activity</h4><ol><li>file namespace + access control</li><li>file to block mapping</li><li>block locations<h4 id="Compositions"><a href="#Compositions" class="headerlink" title="Compositions"></a>Compositions</h4></li></ol><ul><li>Memory: 1. file system hierarchy, 2. file to block mapping, 3. block locations</li><li>Persistent Storage: namespace file + edit log<h3 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h3>Blocks are stored in datanodes, on the local disk. The datanodes know their own hardware, so they can deal with disk failure. Blocks are identified by <strong>BlockID(64bits)</strong>, </li></ul><h2 id="Communication"><a href="#Communication" class="headerlink" title="Communication"></a>Communication</h2><h3 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h3><h4 id="Client-Protocol"><a href="#Client-Protocol" class="headerlink" title="Client Protocol"></a>Client Protocol</h4><p>The <strong>client</strong> send <strong>Metadata operations</strong> to a <strong>namenode</strong>, and the <strong>namenode</strong> return the <strong>DataNode location and Block IDs</strong>.</p><h4 id="DataNode-Protocol"><a href="#DataNode-Protocol" class="headerlink" title="DataNode Protocol"></a>DataNode Protocol</h4><p>The <strong>DataNode</strong>(who always <strong>initiate</strong> connection) register on a <strong>NameNode</strong>. Every <strong>3s</strong>, it sends heartbeat to the namenode; Every <strong>6h</strong>, it sends Block Report to the namenode, as well as “BlockReceived” message.<br>The <strong>NameNode</strong> sends <strong>Block operations</strong> to the DataNode.</p><h4 id="DataTransfer-Protocol"><a href="#DataTransfer-Protocol" class="headerlink" title="DataTransfer Protocol"></a>DataTransfer Protocol</h4><p>Between <strong>Client</strong> and <strong>DataNodes</strong>. They transfer data blocks with each other, streaming.<br>If a client is <strong>writing</strong> data, it will write on one DataNode, and this DataNode replicate the blocks to other DataNodes, using a pipeline.</p><h3 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h3><h4 id="Physical-level"><a href="#Physical-level" class="headerlink" title="Physical level"></a>Physical level</h4><p>In each block, there are two files: metadata file and the data file.<br>Metadata includes checksum, generation stamp and so on.  </p><ul><li>checksum: is calculated when the block is written, and is used to check for data integrity (may be caused by disk errors, network faults, buggy software and so on) when the file is <strong>read</strong> back.</li><li>generation stamp prevents reading stale data.</li></ul><h4 id="functionality"><a href="#functionality" class="headerlink" title="functionality"></a>functionality</h4><ul><li>create/delete directory</li><li>write/append to/read/delete file</li></ul><h3 id="Read-a-file"><a href="#Read-a-file" class="headerlink" title="Read a file"></a>Read a file</h3><ol><li>client -&gt; namenode: asks for a file</li><li>namenode -&gt; client: the block locations, multiple datanodes for each block, sorted by distance.</li><li>datanodes -&gt; client: form an input stream for client to read.</li></ol><h3 id="Write-a-file"><a href="#Write-a-file" class="headerlink" title="Write a file"></a>Write a file</h3><ol><li>client -&gt; namenode: create command.</li><li>A circuit<ol><li>namenode -&gt; client: datanodes for first block.</li><li>client -&gt; datanodes: Client creates a pipeline for streaming data to DataNodes.</li><li>client -&gt; datanode, datanode-&gt;datanode: the client by DataStreamer sends a packet to DN1, DN1 streams to DN2 the same way, and so on. If one node fails the pipeline is recreated with remaining nodes.</li><li>datanodes -&gt; client: Ack message</li><li>Repeat from the beginning: Namenode -&gt; client: datanodes for second, third … nth block.</li></ol></li><li>client -&gt; NameNode: close/release lock.</li><li>DataNodes -&gt; NN: through DataNode Protocol, the NN checks for minimal replication.</li><li>NN -&gt; client: Ack.</li></ol><h2 id="Replicas"><a href="#Replicas" class="headerlink" title="Replicas"></a>Replicas</h2><p>the number of replicas: default 3.</p><p>Considerations: reliability, read/write bandwidth, block distribution</p><p><strong>Distance</strong>: three layers: node, rack, cluster, 1 between them. e.g. from a node to another node on the same/different rack: 2/4.</p><h3 id="Placement"><a href="#Placement" class="headerlink" title="Placement"></a>Placement</h3><ol><li>the same <strong>node</strong> as the client (or random), rack A</li><li>a node in a different <strong>rack</strong>, rack B</li><li>a different node in the same <strong>rack</strong> with 2, rack B</li><li>4 or beyond: random, but if possible: at most one replica per node/at most two replicas per rack.<br>Put on different rack is to make the distribution more evenly.</li></ol><h2 id="Performance-and-Availability"><a href="#Performance-and-Availability" class="headerlink" title="Performance and Availability"></a>Performance and Availability</h2><p>The NameNode is a single node, when it fails, HDFS uses Startup again to solve the problem.</p><h3 id="Startup"><a href="#Startup" class="headerlink" title="Startup"></a>Startup</h3><p>It usually takes <strong>30 minutes</strong>.</p><ol><li>NN read in the persistent storage, and builds the new file system, according to <strong>Namespace life and edit log</strong>.</li><li>The DNs report to the NN, to recover the <strong>Block locations</strong>.<h3 id="Other-strategies"><a href="#Other-strategies" class="headerlink" title="Other strategies"></a>Other strategies</h3></li><li>Checkpoints with secondary NN: SNN composes the old namespace file and edit log as a new namespace file, which will reduces the time in step 1.</li><li>High Availability(HA): Backup Namenodes: maintains the mappings and locations in memory like the namenode, ready to take over it at all times.</li><li>Federated DFS: different sub-directories are organized by different NN, more like the file system.</li></ol><h1 id="GFS-vs-HDFS"><a href="#GFS-vs-HDFS" class="headerlink" title="GFS vs HDFS"></a>GFS vs HDFS</h1><table><thead><tr><th>HDFS</th><th>GFS</th></tr></thead><tbody><tr><td>NameNode</td><td>Master</td></tr><tr><td>DataNode</td><td>ChunkServer</td></tr><tr><td>Block</td><td>Chunk</td></tr><tr><td>FS Image</td><td>Checkpoint image</td></tr><tr><td>Edit log</td><td>Operation log</td></tr></tbody></table><p>Block size: Cloudera HDFS: 128 MB, GFS/Apache HDFS: 64 MB.</p><h1 id="Abbreviations"><a href="#Abbreviations" class="headerlink" title="Abbreviations"></a>Abbreviations</h1><p>DFS</p><h1 id="Further-Reading"><a href="#Further-Reading" class="headerlink" title="Further Reading"></a>Further Reading</h1><p><a href="https://www.oreilly.com/library/view/hadoop-the-definitive/9781491901687/">Hadoop: The Definitive Guide 4th ed.</a> Chapter 3</p><p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwjJotjt6J7yAhUKgP0HHX3RByMQFnoECAQQAw&amp;url=http://storageconference.us/2010/Papers/MSST/Shvachko.pdf&amp;usg=AOvVaw0_YA92FFHsSjh4za3pmHae">The Hadoop Distributed File System</a></p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BD5 Wide Column Store</title>
      <link href="/bd-5columnstore/"/>
      <url>/bd-5columnstore/</url>
      
        <content type="html"><![CDATA[<p>HBase: design to run on a <strong>scalable</strong> cluster of <strong>commodity hardware</strong>, built on <strong>HDFS</strong>. Founding paper: Google’s BigTable.</p><p><strong>Design paradigm of Big Table</strong>: store together what is accessed together, because join is really expensive.</p><h1 id="Columnar-Model-Denormalized"><a href="#Columnar-Model-Denormalized" class="headerlink" title="Columnar Model: Denormalized"></a>Columnar Model: Denormalized</h1><h2 id="Column-oriented-stores"><a href="#Column-oriented-stores" class="headerlink" title="Column-oriented stores"></a>Column-oriented stores</h2><p>also, wide column stores, column-family-oriented stores:<br>Column family: must be know <strong>in advance</strong>, but the columns can be added on the fly.</p><h2 id="Queries"><a href="#Queries" class="headerlink" title="Queries"></a>Queries</h2><p>Get, Put, <strong>Scan</strong>, Delete</p><h1 id="Physical-level"><a href="#Physical-level" class="headerlink" title="Physical-level"></a>Physical-level</h1><h3 id="Regions"><a href="#Regions" class="headerlink" title="Regions"></a>Regions</h3><p>defined by <strong>min-included</strong> rowID and <strong>max-exclued</strong> rowID</p><h3 id="Column-Families"><a href="#Column-Families" class="headerlink" title="Column Families"></a>Column Families</h3><p>stored together, composed as <strong>HFile</strong> on HDFS. </p><h2 id="HFile"><a href="#HFile" class="headerlink" title="HFile"></a>HFile</h2><p>as an SSTable, Only allowed to be written <strong>sequentially</strong> in a single batch.</p><h3 id="Prefix-code"><a href="#Prefix-code" class="headerlink" title="Prefix code"></a>Prefix code</h3><p>keylength+valuelength+key+value</p><p>Advantages: without consideration of separation.</p><p>How to realize prefix code? Save the key/value-length in a given length of bits</p><h4 id="Key"><a href="#Key" class="headerlink" title="Key"></a>Key</h4><p>row length(fixed bits), row(key), column family length, column family, column qualifier, timestamp (for versioning) , key type (for marking as deleted)</p><h3 id="Versioning"><a href="#Versioning" class="headerlink" title="Versioning"></a>Versioning</h3><p>Total order, only integers. How to maintain the total order? HBase guarantees ACID on the <strong>row</strong> level</p><p>Different versions of same cell.</p><h4 id="Blocks"><a href="#Blocks" class="headerlink" title="Blocks"></a>Blocks</h4><p>We read many key-values together, which is called Block ( the default size is 64kb). But the size is not fixed. If we have longer value at the end, which size is larger than block size, we <strong>don’t split</strong> the block, just having a longer block.</p><p>Short summary: Table, into Regions, into Stores, saved into StoreFile, composed of Block<br><a href="./pic/0501.png">on the disk</a></p><h1 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h1><h2 id="In-Memory"><a href="#In-Memory" class="headerlink" title="In Memory"></a>In Memory</h2><ul><li>MemStore: It is the <strong>write</strong> cache. The main role of MemStore is to store new data which has not yet been written to disk.</li><li>LRU BlockCache: it is the <strong>read</strong> cache. The main role of BlockCache is to store the frequently read data in memory. </li><li>Indices of HFiles</li><li>Bloom Filters</li></ul><h3 id="MemStore"><a href="#MemStore" class="headerlink" title="MemStore"></a>MemStore</h3><ul><li>In simple words, before a permanent write, a write buffer where HBase accumulates data in memory is what we call the MemStore.</li><li>While the MemStore fills up, its contents flush to disk to form an HFile.</li><li>It forms a new file on every flush, rather than writing to an existing HFile.</li><li>Basically, for HBase, the HFile is the underlying storage format.</li><li>Per column family, there is one MemStore. It is possible that one column family can have multiple HFiles, but not vice versa.<h3 id="Bloom-Filters"><a href="#Bloom-Filters" class="headerlink" title="Bloom Filters"></a>Bloom Filters</h3>quickly to judge whether an item belongs to a set. It uses several hash functions to realize that. It can be false positive.<h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1>HMaster RegionServer</li></ul><h2 id="Bootstrap"><a href="#Bootstrap" class="headerlink" title="Bootstrap"></a>Bootstrap</h2><ul><li><strong>META table</strong> stores the locations of all the regions in HBase.</li><li><strong>Root table</strong> stores the information of META table. (it is been dropped)<h2 id="HMaster"><a href="#HMaster" class="headerlink" title="HMaster"></a>HMaster</h2></li><li>DDL operations: create table, <strong>not</strong> delete table.</li><li>Assign regions to RegionServers</li><li>Split regions</li><li>handles RegionServer failovers</li></ul><h2 id="Region-Server"><a href="#Region-Server" class="headerlink" title="Region Server"></a>Region Server</h2><ul><li>the data which we manage by Region Server further stores in the Hadoop DataNode. And, all HBase data is stored in HDFS files.</li><li>Region Servers are collocated with the HDFS DataNodes, which also enable <strong>data locality</strong>. </li></ul><h1 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h1><h2 id="Writing-new-cells"><a href="#Writing-new-cells" class="headerlink" title="Writing new cells"></a>Writing new cells</h2><p>HFile(StoreFile) is on the disk.  </p><ol><li>First write cells into WAL(write-ahead-log, It is a file on the distributed file system. ) in MemStore, </li><li>The data to be written is forwarded to MemStore which is actually the RAM of the data node, as soon as the log entry is done. All the data is written in MemStore which is faster than RDBMS</li><li>then sort these cells into a StoreFile.</li><li>Further, ACK (Acknowledgement) is sent to the client as a confirmation of task completed, as soon as writing data is completed.</li></ol><p>When to flush:  </p><ul><li>reaching max MemStore size in a store  </li><li>reaching overall max MemStore size  </li><li>reaching full Write-Ahead Log</li></ul><h2 id="Reading-from-a-Store"><a href="#Reading-from-a-Store" class="headerlink" title="Reading from a Store"></a>Reading from a Store</h2><p>read from <strong>everywhere</strong>! It is efficient, because we have index. Then, take versions.</p><h2 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h2><h3 id="Minor-Compaction"><a href="#Minor-Compaction" class="headerlink" title="Minor Compaction"></a>Minor Compaction</h3><p>When we have a lot of store files, we take them, sort again <strong>in memory</strong> and flush back into a single file.</p><h3 id="Major-Compaction"><a href="#Major-Compaction" class="headerlink" title="Major Compaction"></a>Major Compaction</h3><ul><li>a process of combining the StoreFiles of regions into a single StoreFile, is what we call HBase Major Compaction. </li><li>Also, it deletes remove and expired versions permanently. </li><li>The region will split into new regions after compaction, if the new larger StoreFile is greater than a certain size (defined by property).<h3 id="Trees"><a href="#Trees" class="headerlink" title="Trees"></a>Trees</h3><a href="https://www.jianshu.com/p/06f9f7f41fdb">principles introduction</a><h4 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B+ Tree"></a>B+ Tree</h4>For classical RDBMS. It supports the range query. To reduce <strong>seek</strong> times.<h4 id="LSM-Tree"><a href="#LSM-Tree" class="headerlink" title="LSM Tree"></a>LSM Tree</h4>Log-structured merge tree. <strong>Transfer efficient</strong>, because you only write the entire file sequentially. It is used to minimize the times we need to merge.</li></ul><p>The logs are stored as a small tree in memory. When the tree grows bigger, it will be flushed into the disk. The trees in disk are regularly merged as a bigger one for faster read when the disk does compaction.</p><h1 id="Caching"><a href="#Caching" class="headerlink" title="Caching"></a>Caching</h1><p>To read faster, there are 2 levels of caches: level 1: LRU block cache and level 2: bucket cache. Finally, go to HDFS.</p><p>when not to use caching?</p><ul><li>Batch processing</li><li>random access<h1 id="Best-practice"><a href="#Best-practice" class="headerlink" title="Best practice"></a>Best practice</h1>when to use HBase? The number of rows: <strong>millions</strong>: RDBMS; <strong>Billions</strong>: HBase.</li></ul><h1 id="Spanner"><a href="#Spanner" class="headerlink" title="Spanner"></a>Spanner</h1><p>tries to bring back ACID to Big Data.</p><h2 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h2><ul><li>Timestamp, showed to users.</li><li>Directory: like regions</li><li>tablet: put regions together.</li><li>1,000,000,000,000s of rows. <strong>Trillions of</strong> rows, not fit into a single cluster.</li><li><strong>universemaster</strong> over masters.</li><li>sacrifice higher availability to get <strong>lower latency</strong>.<h2 id="Architecture-1"><a href="#Architecture-1" class="headerlink" title="Architecture"></a>Architecture</h2></li><li>100s of data centers</li><li>1,000,000s of machines</li><li>multiple data centers.<h1 id="Abbreviation"><a href="#Abbreviation" class="headerlink" title="Abbreviation"></a>Abbreviation</h1>LSM Tree: log-structured merge tree.<br>LRU: least recently used.</li></ul><h1 id="Further-Reading"><a href="#Further-Reading" class="headerlink" title="Further Reading"></a>Further Reading</h1><p><a href="https://www.oreilly.com/library/view/hbase-the-definitive/9781449314682/">HBase: The Definitive Guide 1st ed.</a> Chapter 1, 3, 8, 9</p><p><a href="https://www.oreilly.com/library/view/hadoop-the-definitive/9781491901687/">Hadoop: The Definitive Guide 4th ed. </a>Chapter 20</p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BD3 Storage</title>
      <link href="/bd-3storage/"/>
      <url>/bd-3storage/</url>
      
        <content type="html"><![CDATA[<h1 id="Old-Local-File-System"><a href="#Old-Local-File-System" class="headerlink" title="Old Local File System"></a>Old Local File System</h1><p>File = Content + Metadata</p><ol><li>fixed metadata -&gt; fixed Schema</li><li>organized in a hierarchy</li><li>files are stored in blocks</li><li>work in local machine, LAN(local-area network), NAS (network-attached storage), <strong>not in WAN</strong> (wide-area network)</li></ol><h1 id="Object-Storage"><a href="#Object-Storage" class="headerlink" title="Object Storage"></a>Object Storage</h1><ol><li>“Black-box” objects</li><li>Flat and global key-value model</li><li>Flexible metadata</li><li>Commodity hardware</li></ol><h1 id="Data-Center"><a href="#Data-Center" class="headerlink" title="Data Center"></a>Data Center</h1><p>1000-100,000 machines in a data center.<br>RU: rack units</p><h2 id="Per-Server"><a href="#Per-Server" class="headerlink" title="Per Server"></a>Per Server</h2><ol><li>1-14 TB local storage</li><li>16GB-4TB RAM</li><li>1-10 GB/s network bandwidth</li><li>1-100 cores<h2 id="Rack-modular"><a href="#Rack-modular" class="headerlink" title="Rack modular"></a>Rack modular</h2></li></ol><ul><li>servers  </li><li>storage  </li><li>routers<h1 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h1>it is for fault tolerance. We have replications in different regions. Why?  </li><li>optimize latency</li><li>resilient to natural catastrophes</li></ul><h1 id="Amazon-S3"><a href="#Amazon-S3" class="headerlink" title="Amazon S3"></a>Amazon S3</h1><p>This is a key/value model. Key is composed:<br>   Bucket ID + Object ID.  </p><ul><li>Scalability: The max of an object is 5 TB. An account can have 100 buckets (more upon request). </li><li>Durability: loss of 1 in 10^11 objects in a year.</li><li>Availability: 99.99% down 1h/year (SLA: 99%–&gt;4days/year, 99.9%–&gt;9 hours/year, 99.99999%–&gt;4 seconds/year), response time &lt;<strong>10 ms</strong> in 99.9% of the cases</li></ul><h1 id="REST-APIs"><a href="#REST-APIs" class="headerlink" title="REST APIs"></a>REST APIs</h1><p>HTTP protocol: Tim Berners-Lee.<br>REST (<strong>Representational state transfer</strong>) is the HTTP done the right way. How to do the right way?  </p><h2 id="URI"><a href="#URI" class="headerlink" title="URI"></a>URI</h2><p>universal resource identifier: some strings to identify resources. Two sub-kinds: URL(L:located, tell you how to get the resource) and URN (not to tell how)<br>e.g. <code>http://www.mywebsite.ch/api/collection/foo/object/bar?id=foobar#head</code><br>scheme + authority + path + query + fragment</p><h2 id="HTTP-Methods"><a href="#HTTP-Methods" class="headerlink" title="HTTP Methods"></a>HTTP Methods</h2><ul><li>GET: side-effects free</li><li>PUT</li><li>DELETE</li><li>POST: when you want to transfer something really complex.</li></ul><h2 id="Status-Code"><a href="#Status-Code" class="headerlink" title="Status Code"></a>Status Code</h2><p><a href="https://restapitutorial.com/httpstatuscodes.html">REST API tutorial</a></p><h3 id="1-infromational"><a href="#1-infromational" class="headerlink" title="1: infromational"></a>1: infromational</h3><h3 id="2-success"><a href="#2-success" class="headerlink" title="2: success"></a>2: success</h3><ul><li>200: OK, </li><li>201: created,  </li><li>202: Accepted: The request has been accepted for processing, but the processing has not been completed.  </li><li>204: No Content: the server has successfully processed the request, but not returning any content.<h3 id="3-Redirection"><a href="#3-Redirection" class="headerlink" title="3: Redirection"></a>3: Redirection</h3></li><li>300: Multiple choices, </li><li>301: Move permanently: This and all future requests should be directed to the given URI.</li><li>303: See Other: The response to the request can be found under another URI using a GET method. The server has received the data and the redirect should be issued with a separate GET message.<h3 id="4-Client-Error"><a href="#4-Client-Error" class="headerlink" title="4: Client Error"></a>4: Client Error</h3></li><li>400: Bad Request: The request cannot be fulfilled due to bad syntax. General error when fulfilling the request would cause an invalid state. Domain validation errors, missing data, etc. are some examples.  </li><li>401: unauthorized:  Error code response for missing or invalid authentication token.</li><li>403: Forbidden: The request was a legal request, but the server is refusing to respond to it. Unlike a 401 Unauthorized response, authenticating will make no difference.  </li><li>404: Not Found: The requested resource could not be found but may be available again in the future. Subsequent requests by the client are permissible. Used when the requested resource is not found, whether it doesn’t exist or if <strong>there was a 401 or 403</strong> that, for security reasons, the service wants to mask.<h3 id="5-Server-Error"><a href="#5-Server-Error" class="headerlink" title="5: Server Error"></a>5: Server Error</h3></li><li>500: Internal Server Error: The server encountered an unexpected condition which prevented it from fulfilling the request.<h2 id="With-S3"><a href="#With-S3" class="headerlink" title="With S3"></a>With S3</h2><h3 id="URI-1"><a href="#URI-1" class="headerlink" title="URI"></a>URI</h3></li><li>Buckets: <code>http://bucket.s3(-region).amazonaws.com</code></li><li>Objects: <code>http://bucket.s3(-region).amazonaws.com/object-name</code><h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h3>PUT bucket/object; GET bucket/object; DELETE bucket/object</li></ul><p>Is S3 a file system?<br>Yes or No. Because </p><ul><li>in the physical level: the name e.g. “/fruit/apple/red/“ is only object ID, instead of actual path. You only have individual objects.</li><li>in the logical level: it works like a file system.</li></ul><h1 id="Microsoft-Azure-Blob-Storage"><a href="#Microsoft-Azure-Blob-Storage" class="headerlink" title="Microsoft Azure Blob Storage"></a>Microsoft Azure Blob Storage</h1><h2 id="Comparison-with-S3"><a href="#Comparison-with-S3" class="headerlink" title="Comparison with S3"></a>Comparison with S3</h2><table><thead><tr><th>.</th><th>S3</th><th>Azure</th></tr></thead><tbody><tr><td>Object ID</td><td>Bucket+Object</td><td>Account+Partition+Object</td></tr><tr><td>Object API</td><td>Blackbox</td><td>Blocks or pages</td></tr><tr><td>Limit</td><td>5TB</td><td>195GB(blocks) 1TB(pages)</td></tr></tbody></table><h2 id="Storage-Replication"><a href="#Storage-Replication" class="headerlink" title="Storage Replication"></a>Storage Replication</h2><p>intra-stamp replication: synchronous, in the same stream layer<br>inter-stamp replication: asynchronous, between two partition layers</p><h2 id="Location-Services"><a href="#Location-Services" class="headerlink" title="Location Services"></a>Location Services</h2><ol><li>First key goes to DNS with Account name to get the virtual IP  </li><li>Then, take the partition+Object keys to the given IP to get the object.</li></ol><h1 id="Key-Value-store"><a href="#Key-Value-store" class="headerlink" title="Key-Value store"></a>Key-Value store</h1><p>It is different from Key-Value Model, which is in the logical layer. Key-value store actaully means smaller objects and low latency.</p><p>S3 has a large latency, 100-300ms, but a typical database’s latency is 1-9ms. So, we want to make key-object storage work like a database. One realization is DynamoDB:</p><ul><li>smaller objects than S3 (5TB max), only 400KB </li><li>No metadata. In S3, you can associate metadata with your object, but not in the DynamoDB.</li></ul><h2 id="Basic-API"><a href="#Basic-API" class="headerlink" title="Basic API"></a>Basic API</h2><ul><li><code>get(key)</code>: you get the value</li><li><code>put(key, other value)</code></li></ul><h3 id="In-DynamoDB-API"><a href="#In-DynamoDB-API" class="headerlink" title="In DynamoDB API"></a>In DynamoDB API</h3><ul><li><code>get(key)</code>: you get the value and <strong>the context</strong></li><li><code>put(key, context, other value)</code>: you should give the context in put operation.</li></ul><p>Key-value store is a simplification of relational-database:</p><ul><li>simplicity VS more features</li><li>eventual consistency (can have partition tolerance) VS consistency</li><li>performance is much better VS overhead</li><li>scalability VS monolithic( only on a single machine)</li></ul><h2 id="Distributed-Hash-Table"><a href="#Distributed-Hash-Table" class="headerlink" title="Distributed Hash Table:"></a>Distributed Hash Table:</h2><h3 id="logical-ring"><a href="#logical-ring" class="headerlink" title="logical ring"></a>logical ring</h3><ol><li>Each node takes an ID randomly</li><li>Nodes are logically placed on the ring.</li><li>ID stored at the next node (clockwise)</li><li>Adding/removing nodes: only doing with three nodes.</li><li>Nodes Failure: using duplication in 2(N) ranges.</li><li>Searching for a key-value: using finger tables, like binary search.</li></ol><h3 id="Pros"><a href="#Pros" class="headerlink" title="Pros"></a>Pros</h3><ol><li>highly scalable (to the feature 4)</li><li>robust against failure (to the feature 5)</li><li>self organizing (cause picking random numbers)<h3 id="Cons"><a href="#Cons" class="headerlink" title="Cons"></a>Cons</h3></li><li>lookup, not searching.</li><li>data integrity</li><li>security issues</li></ol><h3 id="Tokens"><a href="#Tokens" class="headerlink" title="Tokens"></a>Tokens</h3><p>We use <strong>virtual nodes, which are called tokens</strong>, to solve the issue: heterogenous performance.</p><h2 id="Vector-clocks"><a href="#Vector-clocks" class="headerlink" title="Vector clocks"></a>Vector clocks</h2><p>(<strong>the main point</strong>)</p><h3 id="Purposes-of-using-vector-clocks-in-distributed-systems"><a href="#Purposes-of-using-vector-clocks-in-distributed-systems" class="headerlink" title="Purposes of using vector clocks in distributed systems"></a>Purposes of using vector clocks in distributed systems</h3><ul><li>Generating a partial ordering of events</li><li>Detecting causality violations between events.</li><li><strong>Not for</strong> Keeping different versions of objects.<br>it has the context. <h3 id="mathematical-property"><a href="#mathematical-property" class="headerlink" title="mathematical property:"></a>mathematical property:</h3>it is partial ordered:  </li></ul><ol><li>reflexibility: x - x  </li><li>transitivity</li><li>asymmetric </li></ol><p>The format of context <code>[(coordinatorID, OrderID),(coordinatorID2,...),...]</code></p><p>The coordinator ID: each time, a get/put operation has a coordinator to receive and replicate to all the other nodes.</p><p>Building a key-value store on the top of peer to peer networks.<br>Get operation:<code>get(key)</code> return the value and the context. The coordinator collects all the other nodes values and compare them/ merge them to return. If the contexts are not comparable, it will return several values/contexts.<br>Put operation: <code>put(key,context,value)</code>: given the key, the context and the new value.<br>Synchronization: remove all the past same values, keep the uncomparable values.<br>If the network is partitioned, the system will change the coordinator.</p><h2 id="Merkle-Trees"><a href="#Merkle-Trees" class="headerlink" title="Merkle Trees"></a>Merkle Trees</h2><p>It offers an easy way to see where there is a conflict. The leaf nodes are the hash of data blocks and the non-leaf nodes are the hash of all of its children.</p><h1 id="Design-Principles"><a href="#Design-Principles" class="headerlink" title="Design Principles"></a>Design Principles</h1><ul><li>incremental stability: can add/delete a node</li><li>symmetry: decentralization</li><li>heterogeneity</li></ul><h1 id="How-to-scale-out"><a href="#How-to-scale-out" class="headerlink" title="How to scale out?"></a>How to scale out?</h1><ul><li>simplify the model</li><li>buy cheap hardware</li><li>remove schemas</li></ul><h1 id="Abbrevations"><a href="#Abbrevations" class="headerlink" title="Abbrevations"></a>Abbrevations</h1><p>SLA: service-level-agreement</p><ul><li>RDBMS: relational database </li></ul><h1 id="Further-reading-notes"><a href="#Further-reading-notes" class="headerlink" title="Further reading notes"></a>Further reading notes</h1><p>Thanks my classmate Claudio Andrea Ferrai and  Ruben Marias for reading and organizing the notes.</p><div class="row">    <embed src="03_object_and_keyvalue_storage.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BD11 Data Model</title>
      <link href="/bd-11datamodel/"/>
      <url>/bd-11datamodel/</url>
      
        <content type="html"><![CDATA[<h1 id="Type-System"><a href="#Type-System" class="headerlink" title="Type System"></a>Type System</h1><p>edge vs node labeling: labels are on the edges(JSON)/nodes (XML)</p><h2 id="Shared-properties"><a href="#Shared-properties" class="headerlink" title="Shared properties"></a>Shared properties</h2><ul><li>distinction between atomic types and structured types</li><li>same categories of atomic types</li><li>lists and maps as structured types</li><li>sequence type cardinalities: *(zero or more, repeated),?(zero or one, optional),+(one or more)<h3 id="Atomic-types"><a href="#Atomic-types" class="headerlink" title="Atomic types"></a>Atomic types</h3></li><li>string</li><li>number<ul><li>arbitrary precision decimales and integers</li><li>signed and unsigned integer types</li><li>IEEE 754 standard: float: 32bits, ca 7digits, 10^-37 to 10^37; double: 64bits, ca 15digits, 10^-307 to 10^308</li></ul></li><li>booleans</li><li>dates and times<ul><li>dates: year+month+day</li><li>times: hours+minutes+seconds</li><li>timestamp: date+time</li></ul></li><li>Time interval</li><li>binaries</li><li>null<h3 id="Structured-types"><a href="#Structured-types" class="headerlink" title="Structured types"></a>Structured types</h3></li><li>associative arrays( maps) : JSON object, set of XML attributes</li><li>ordered lists: JSON array, XML element</li></ul><h1 id="Validation"><a href="#Validation" class="headerlink" title="Validation"></a>Validation</h1><p>pipeline: document-&gt;well-formedness-&gt;validation</p><p>PSVI: post-schema-validation infoset: infoset + <strong>types</strong></p><h2 id="DTD-validation"><a href="#DTD-validation" class="headerlink" title="DTD validation"></a>DTD validation</h2><h3 id="Element-type-declaration"><a href="#Element-type-declaration" class="headerlink" title="Element type declaration"></a>Element type declaration</h3><ul><li>empty content: <code>&lt;!ELEMENT name EMPTY&gt;</code></li><li>simple content: only includes text, using <code>#PCDATA</code>, <code>&lt;!ELEMENT name (#PCDATA)&gt;</code></li><li>complex content: meaning including other elements: <code>&lt;!ELEMENT name (sub1/+/*/?,sub2, ...)&gt;</code>, the more advanced:<code>&lt;!ELEMENT name (bar*|(foo|foobar)+)? &gt;</code></li><li>mixed content: includes both other elements and text, e.g. <code>&lt;!ELEMENT name (#PCDATA|foo)*&gt;</code>, or can also use ANY <code>&lt;!ELEMENT name ANY&gt;</code><h3 id="Attribute-List-Declaration"><a href="#Attribute-List-Declaration" class="headerlink" title="Attribute-List Declaration"></a>Attribute-List Declaration</h3>Format: <code>&lt;!ATTLIST ele-name attr-name ATTR-FORMAT CARDINALITY&gt;</code></li><li>attribute format: CDATA, NMTOKEN(s), ID(REFS)</li><li>cardinality: <ul><li>#REQUIRED: must have</li><li>#IMPLIED: can have</li><li>“string”: the value of the attribute, can be omitted.</li><li>#FIXED “string”: must written out, cannot be omitted.</li></ul></li></ul><h1 id="XML-Schema"><a href="#XML-Schema" class="headerlink" title="XML Schema"></a>XML Schema</h1><p>Two files: .xsd: the schema defined file and .xml: the instance file</p><ul><li>.xsd: the definition of an element: <code>&lt;xs:element name="ele-name", type="xs:string/xs:integer/user-defined type..."/&gt;</code></li><li>.xml: within the defined element: using <code>&lt;ele-name xmlns:xsi="..." xsi:schema-location="schema-name.xsd"&gt;</code></li></ul><h2 id="Element-types"><a href="#Element-types" class="headerlink" title="Element types"></a>Element types</h2><h3 id="Simply-types-built-in"><a href="#Simply-types-built-in" class="headerlink" title="Simply types: built-in"></a>Simply types: built-in</h3><ul><li>strings: string, anyURI, QName; </li><li>numbers: decimal, float, double, integer, …; </li><li>booleans: boolean</li><li>dates and times: dateTime, time, date, gYearMonth, gMonthDay, gYear, gMonth, gDay, dateTimeStamp</li><li>time intervals: duration, yearMonthDuration, dayTimeDuration</li><li>Binaries: hexBinary, base64Binary</li><li>NUll<h3 id="User-defined-types"><a href="#User-defined-types" class="headerlink" title="User-defined types"></a>User-defined types</h3><h4 id="Simple-types"><a href="#Simple-types" class="headerlink" title="Simple types"></a>Simple types</h4></li><li>restriction: <code>&lt;xs:restriction base="built-in type"&gt; &lt;xs:length value="3"&gt;...&lt;/xs:restriction&gt;</code></li><li>list: <code>&lt;xs:list itemType="xs:string"/&gt;</code>, instance: <code>&lt;foo&gt;foo bar foobar&lt;/foo&gt;</code></li><li>union: <code>&lt;xs:union memberTypes="xs:integer xs:boolean"/&gt;</code>, instance: <code>&lt;foo&gt;true&lt;foo&gt;</code><h4 id="Complex-types"><a href="#Complex-types" class="headerlink" title="Complex types"></a>Complex types</h4></li><li><strong>empty</strong>: <code>&lt;xs:complexType name="emptyType"&gt;</code></li><li>simple content <strong>??? what is different with the simple type?</strong>: </li><li>complex content: can include sub-elements</li><li>mixed conent: can include both text and sub-elements. <code>&lt;xs:complexType, name="..." mixed="true"&gt;</code><h4 id="Keys"><a href="#Keys" class="headerlink" title="Keys"></a>Keys</h4>XML allows you to make an attribute as a key of the element. the definition is<br><code>&lt;xs:element ...&gt;....&lt;xs:key name="key-name"&gt; &lt;xs:selector xpath="the-aim-element"/&gt;&lt;xs:field xpath="@the-key-attribute"/&gt;&lt;/xs:key&gt;&lt;/xs:element&gt;</code></li></ul><p>How to use? 1. simple type of attributes; 2. named types; 3. anonymous types: defined where to use, without being named.</p><h2 id="Schema-Location"><a href="#Schema-Location" class="headerlink" title="Schema Location"></a>Schema Location</h2><h3 id="without-namespace"><a href="#without-namespace" class="headerlink" title="without namespace"></a>without namespace</h3><p>in the instance file:  <code>&lt;xsi:noNamespaceSchemaLocation="schema.xsd"&gt;</code>. Correspondingly, in the schema file, there is no definition on the namespace.</p><h3 id="With-namespace"><a href="#With-namespace" class="headerlink" title="With namespace"></a>With namespace</h3><p>in the instance file:  <code>&lt;xsi:SchemaLocation="namespace/schema.xsd"&gt;</code>.<br>In the schema file, <code>&lt;xs:schema xmlns:xs="..." targetNamespace="namespace" ...&gt;</code> </p><h2 id="Import-Schema"><a href="#Import-Schema" class="headerlink" title="Import Schema"></a>Import Schema</h2><p>in the .xsd file, we can use types defined in other schema files, by using     <code>&lt;xs:import namespace="other-schema-namespace" schemaLocation="other-schema-name.xsd"/&gt;</code>. To import, we use <code>ref</code>, in the sentence: <code>&lt;xs:element ref="prefix:defined-type" ...&gt;</code></p><h1 id="Other-technologies"><a href="#Other-technologies" class="headerlink" title="Other technologies"></a>Other technologies</h1><p>Avro: It is a language that allows you to define schema, an apache language.<br>Process: </p><ol><li>read the language-independent schema</li><li>compilation the schema and put it in somewhere of the code</li><li>read in the data according to the schema.</li></ol><p>XDM: XPath and XQuery Data Model, JDM: JSONiq Data Model</p><p>XDM: seven kinds of XML Nodes: Document Node, Element node, Attribute node, Text Node, Comment node, Processing instruction node, namespace node.</p><h1 id="Abbreviation"><a href="#Abbreviation" class="headerlink" title="Abbreviation"></a>Abbreviation</h1><p>PSVI: post-schema-validation infoset<br>DTD: document type declaration<br>XDM: XPath and XQuery Data Model<br>JDM: JSONiq Data Model</p><h1 id="Further-Reading"><a href="#Further-Reading" class="headerlink" title="Further Reading"></a>Further Reading</h1><p><a href="https://www.oreilly.com/library/view/xml-in-a/0596007647/">XML in a Nutshell</a> Chapter 3, 17</p><p>Thanks Ruben and Christina for reading notes</p><div class="row">    <embed src="11_DataModels.pdf" width="100%" height="550" type="application/pdf"></div>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BD1 Introduction</title>
      <link href="/bd-1intro/"/>
      <url>/bd-1intro/</url>
      
        <content type="html"><![CDATA[<p>Database prehistory:  </p><ol><li>speaking/singing(expressing information).   </li><li>writing(recording).   </li><li>accounting (processing information)   </li><li>printing (broadcasting in large scale).  </li></ol><p>Database history: 1960s: File system; 1970s: relational era; 1980s: object era; 2000s: NoSQLs  </p><h1 id="3Vs"><a href="#3Vs" class="headerlink" title="3Vs:"></a>3Vs:</h1><p>volume, variety, velocity  </p><h2 id="Volume"><a href="#Volume" class="headerlink" title="Volume"></a>Volume</h2><p><strong>Prefix</strong>: KMGTPEZY:<br>kilo(3 zeros),mega (6 zeros),giga,tera,peta,exa,zetta,yotta.<br>kibi(2^10),mebi(2^20),gibi,tebi,pebi,exbi,zebi,yobi.  </p><h2 id="Variety"><a href="#Variety" class="headerlink" title="Variety"></a>Variety</h2><p>Data shapes: table, tree, graph, cube, text</p><h2 id="Velocity"><a href="#Velocity" class="headerlink" title="Velocity"></a>Velocity</h2><p>Velocity paramount factors: capacity, latency, <strong>throughput</strong>. Rule: logarithmic.<br>From Capacity to throughput: <strong>parallelize</strong>.<br>From throughput to latency: <strong>batch processing</strong>.</p><p>Teacher’s definition: Big Data : technologies to store, manage and analyze data that is too large to fit on a single machine, while accommodating for the issue of growing discrepancy between capacity, throughput and latency.</p><h1 id="Course-Overview"><a href="#Course-Overview" class="headerlink" title="Course Overview"></a>Course Overview</h1><h2 id="Data-in-the-large"><a href="#Data-in-the-large" class="headerlink" title="Data in the large"></a>Data in the large</h2><ul><li>Key-value stores (S3)  </li><li>Distributed file systems (HDFS)  </li><li>Distributed query processing (MapReduce, Spark)  </li><li>Resource management (YARN)  </li><li>Column stores (HBase)  <h2 id="Data-in-the-small"><a href="#Data-in-the-small" class="headerlink" title="Data in the small"></a>Data in the small</h2></li><li>Document stores (MongoDB)  </li><li>Syntax (XML, JSON)  </li><li>Data models, Schemas, Querying  </li><li>Data in the very small  </li><li>Data warehouses (OLAP, ROLAP, XBRL)  </li><li>Graph databases (RDF)  </li></ul><p>Learn from the past: data independence: logical data model and physical storage are independent.</p><p>Data Model: 1. what data looks like; 2. what you can do with that.  </p><p>Overall architecture: language/model/compute/storage.</p><h2 id="The-stack"><a href="#The-stack" class="headerlink" title="The stack"></a>The stack</h2><p>from bottom to the top</p><h3 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h3><p>local file system, NFS, GFS, HDFS, S3, Azure Blob Storage</p><h3 id="Encoding"><a href="#Encoding" class="headerlink" title="Encoding"></a>Encoding</h3><p>ASCII, ISO-8859-1, UTF-8, BSON(<strong>???</strong>)</p><h3 id="Syntax"><a href="#Syntax" class="headerlink" title="Syntax"></a>Syntax</h3><p>Text, CSV, XML, JSON, RDF/XML, Turtle, XBRL</p><h3 id="Data-Models"><a href="#Data-Models" class="headerlink" title="Data Models"></a>Data Models</h3><p>Table: relational model<br>Tress: XML Infoset, XDM<br>Graphs: RDF<br>Cubes: OLAP</p><h3 id="Validation"><a href="#Validation" class="headerlink" title="Validation"></a>Validation</h3><p>XML Schema, JSON Schema, Relational schemas, XBRL taxonomies</p><h3 id="Processing"><a href="#Processing" class="headerlink" title="Processing"></a>Processing</h3><p>two-phase: MapReduce<br>DAG(<strong>???</strong>)-driven: Tez, Spark, Flink, Ray<br>Elastic computing: EC2</p><h3 id="Indexing"><a href="#Indexing" class="headerlink" title="Indexing"></a>Indexing</h3><p>key-value stores, hash indices, B-Trees, geographical indices(<strong>???</strong>), spatial indicies(<strong>???</strong>)</p><h3 id="Data-Stores"><a href="#Data-Stores" class="headerlink" title="Data Stores"></a>Data Stores</h3><p>RDBMS, MongoDB, CouchBase, Elastic Search, Hive, HBase, MarkLogic, Cassandra.</p><h3 id="Querying"><a href="#Querying" class="headerlink" title="Querying"></a>Querying</h3><p>SQL,XQuery,JSONiq, N1QL, MDX, SPARQL, REST APIs</p><h3 id="UI"><a href="#UI" class="headerlink" title="UI"></a>UI</h3><p>Excel, Access, Tableau …</p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BD2 Database Basics</title>
      <link href="/bd-2dbbasics/"/>
      <url>/bd-2dbbasics/</url>
      
        <content type="html"><![CDATA[<h1 id="Table-equivalent-Concepts"><a href="#Table-equivalent-Concepts" class="headerlink" title="Table equivalent Concepts"></a>Table equivalent Concepts</h1><p>table,collection<br>attribute,column,field,property<br>row,business object,item,entity,<strong>document</strong>,record<br>primary key,row ID,name  </p><h1 id="Relational-Algebra"><a href="#Relational-Algebra" class="headerlink" title="Relational Algebra"></a>Relational Algebra</h1><p>From the set theory definition: <strong>relation</strong> is a subset of sets cartesian product.</p><h2 id="Queries"><a href="#Queries" class="headerlink" title="Queries"></a>Queries</h2><h3 id="Set-queries"><a href="#Set-queries" class="headerlink" title="Set queries"></a>Set queries</h3><p>union, intersection,  substraction  </p><h3 id="Renaming-queries"><a href="#Renaming-queries" class="headerlink" title="Renaming queries"></a>Renaming queries</h3><p>relation renaming,  attribute renaming</p><h3 id="Filter-queries"><a href="#Filter-queries" class="headerlink" title="Filter queries"></a>Filter queries</h3><p>selection (to row),projection(to column)</p><h3 id="Binary-queries"><a href="#Binary-queries" class="headerlink" title="Binary queries"></a>Binary queries</h3><p>cartesian product (each to each, e.g. n cartesian with m, get nm items) ,natural product,<strong>theta product</strong>(???)</p><h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p>grouping, sorting</p><h1 id="Normal-Forms"><a href="#Normal-Forms" class="headerlink" title="Normal Forms"></a>Normal Forms</h1><p>to reduce redundancy  </p><h2 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency"></a>Consistency</h2><p>update, delete, insert anomaly</p><h2 id="1st-normal-NF1"><a href="#1st-normal-NF1" class="headerlink" title="1st normal (NF1)"></a>1st normal (NF1)</h2><p>get the key, no inserted tables. only atomic values</p><h2 id="2nd-normal-NF2"><a href="#2nd-normal-NF2" class="headerlink" title="2nd normal (NF2)"></a>2nd normal (NF2)</h2><p>the whole key: non-key attributes do not depend on a strict subset of the key</p><h2 id="3rd-normal-NF3"><a href="#3rd-normal-NF3" class="headerlink" title="3rd normal (NF3)"></a>3rd normal (NF3)</h2><p>nothing but the key: non-key attributes do not depend on other non-key attributes.</p><h2 id="BCNF-Boyce-Codd-Normal-Form-3-5NF"><a href="#BCNF-Boyce-Codd-Normal-Form-3-5NF" class="headerlink" title="BCNF (Boyce-Codd Normal Form) (3.5NF)"></a>BCNF (Boyce-Codd Normal Form) (3.5NF)</h2><p>attributes do not depend on other non-key attributes. A slightly stronger version of 3NF.</p><h1 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h1><p>SQL was initially developed at IBM by Donald D. Chamberlin and Raymond F. Boyce in the early 1970s.<br>SQL: structured english query language.</p><h2 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h2><ul><li>Declarative: set-based  </li><li>Functional: the output is still relation.</li></ul><h2 id="Queries-in-SQL"><a href="#Queries-in-SQL" class="headerlink" title="Queries in SQL"></a>Queries in SQL</h2><p><strong>duplicate elimination</strong> union(<code>A union B</code> ), intersection(<code>A intersect B</code>),  substraction (<code>A except B</code>)<br>relation renaming,  attribute renaming (<code>as</code>)<br>selection (<code>where</code>),projection(<code>select ... </code>)<br>cartesian product (each to each, e.g. n cartesian with m, get nm items) ,natural product,<strong>theta product</strong>(???), joining (<code>...left/right/full outer join ... on ...</code>), natural join: <code>natural full outer join ... on ...</code>, is <code>outer</code> not <code>out</code><br>grouping (<code>group by</code>), sorting (<code>order by (asc/desc/null first)</code>)<br>aggregation operators (<code>max/min/sum/avg/count</code>), post-aggregation selection(<code>having: having count(*)&gt;2</code>)  </p><p><strong>where vs. having</strong>: where: before grouping; having: after grouping.</p><h1 id="Terminology"><a href="#Terminology" class="headerlink" title="Terminology"></a>Terminology</h1><p>Schema: DDL: Data Definition language (create table/scheme, or drop it)<br>Data: DML: Data manipulation language (query, insert or remove rows)<br>CRUD: create, read, update, delete</p><h2 id="Language-landscape"><a href="#Language-landscape" class="headerlink" title="Language landscape"></a>Language landscape</h2><p>Software Engineering: proto-imperative-language -&gt; imperative language (JAVA)<br>-&gt; Databases: proto-declarative language(Apache Spark) -&gt; functional/declarative language (SPARQL)<br>-&gt; AI: proto-here-is-an-example language (Tensorflow) -&gt; here-is-an-example language (bonsai)</p><h1 id="Transaction"><a href="#Transaction" class="headerlink" title="Transaction"></a>Transaction</h1><h2 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h2><p>old time</p><h3 id="Atomicity"><a href="#Atomicity" class="headerlink" title="Atomicity"></a>Atomicity</h3><p>Either the entire transaction is applied, or none of it.</p><h3 id="Consistency-1"><a href="#Consistency-1" class="headerlink" title="Consistency"></a>Consistency</h3><p>After a transaction, a database is in a consistent state again.</p><h3 id="Isolation"><a href="#Isolation" class="headerlink" title="Isolation"></a>Isolation</h3><p>A transaction feels like nobody else is <strong>writing</strong> to the database.</p><h3 id="Durability"><a href="#Durability" class="headerlink" title="Durability"></a>Durability</h3><p>Update made don’t disappear again.</p><h2 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h2><p>new era</p><h3 id="Consistency-2"><a href="#Consistency-2" class="headerlink" title="Consistency"></a>Consistency</h3><p>atomic: all the nodes see the same data.</p><h3 id="Availability"><a href="#Availability" class="headerlink" title="Availability"></a>Availability</h3><p>a database can be accessed at all times.</p><h3 id="Partition-tolerance"><a href="#Partition-tolerance" class="headerlink" title="Partition tolerance"></a>Partition tolerance</h3><p>the database continue to function even if the network gets partitioned.</p><p>which holds for DynamoDB? availability and partition tolerance, not consistency.</p><h1 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h1><p>optimize for writing intensive: <strong>OLTP</strong>: OnLineTransactionProcessing<br>optimize for reading intensive: <strong>OLAP</strong>: OnLineAnalyticalProcessing</p><h1 id="Abbreviations"><a href="#Abbreviations" class="headerlink" title="Abbreviations"></a>Abbreviations</h1><p>CRUD, ACID, CAP, OLTP, OLAP, SQL, DDL, DML</p>]]></content>
      
      
      <categories>
          
          <category> Learning Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System </tag>
            
            <tag> Big Data </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
